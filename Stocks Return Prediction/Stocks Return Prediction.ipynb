{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:40:00.559317700Z",
     "start_time": "2025-07-28T06:39:22.796338Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 已加载原始训练数据 ---\n",
      "\n",
      "--- 数据基本信息 (info) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4644139 entries, 1598 to 4642592\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   code    object \n",
      " 1   date    int64  \n",
      " 2   f_0     float64\n",
      " 3   f_1     float64\n",
      " 4   f_2     float64\n",
      " 5   f_3     float64\n",
      " 6   f_4     float64\n",
      " 7   f_5     float64\n",
      " 8   f_6     float64\n",
      " 9   f_7     float64\n",
      " 10  f_8     float64\n",
      " 11  f_9     float64\n",
      " 12  f_10    float64\n",
      " 13  f_11    float64\n",
      " 14  f_12    float64\n",
      " 15  f_13    float64\n",
      " 16  f_14    float64\n",
      " 17  f_15    float64\n",
      " 18  f_16    float64\n",
      " 19  f_17    object \n",
      " 20  f_18    float64\n",
      " 21  f_19    float64\n",
      " 22  f_20    float64\n",
      " 23  f_21    float64\n",
      " 24  f_22    float64\n",
      " 25  f_23    float64\n",
      " 26  f_24    float64\n",
      " 27  f_25    float64\n",
      " 28  f_26    float64\n",
      " 29  f_27    float64\n",
      " 30  y       float64\n",
      "dtypes: float64(28), int64(1), object(2)\n",
      "memory usage: 1.1+ GB\n",
      "\n",
      "--- 数据统计摘要 (describe) ---\n",
      "               date           f_0           f_1           f_2           f_3  \\\n",
      "count  4.644139e+06  4.638044e+06  4.644139e+06  4.644139e+06  4.644139e+06   \n",
      "mean   9.248427e+02  6.447229e+00  2.073167e+00  1.000649e+00  1.755668e+08   \n",
      "std    4.920624e+02  1.174674e+02  6.189697e-01  3.164521e-02  4.260257e+08   \n",
      "min    0.000000e+00  3.112000e-01  7.638000e-01  7.105590e-01  7.075000e+03   \n",
      "25%    5.040000e+02  1.928100e+00  1.600000e+00  9.863650e-01  3.029213e+07   \n",
      "50%    9.800000e+02  3.036500e+00  2.030500e+00  1.000000e+00  7.085575e+07   \n",
      "75%    1.357000e+03  4.961300e+00  2.500000e+00  1.014193e+00  1.719832e+08   \n",
      "max    1.690000e+03  1.907730e+04  4.500000e+00  1.085852e+01  6.794128e+10   \n",
      "\n",
      "                f_4           f_5           f_6           f_7           f_8  \\\n",
      "count  4.642889e+06  4.644139e+06  4.644139e+06  4.644139e+06  4.642893e+06   \n",
      "mean   1.004429e+00  4.265614e+00  9.803916e-01  1.086264e+01  1.002891e+00   \n",
      "std    3.468250e+00  1.011206e+00  2.376783e-02  2.474064e+00  1.619904e+00   \n",
      "min   -8.954691e+02  1.835776e+00  7.105590e-01  8.000000e+00 -5.474717e+00   \n",
      "25%    1.000000e+00  3.567390e+00  9.729457e-01  8.500000e+00  1.000000e+00   \n",
      "50%    1.000000e+00  4.104121e+00  9.860685e-01  1.040000e+01  1.000000e+00   \n",
      "75%    1.000000e+00  4.786933e+00  9.938888e-01  1.330000e+01  1.000000e+00   \n",
      "max    7.043168e+03  1.022635e+01  8.226688e+00  1.610000e+01  3.250824e+03   \n",
      "\n",
      "       ...          f_19          f_20          f_21          f_22  \\\n",
      "count  ...  4.644139e+06  4.156066e+06  4.644139e+06  4.644139e+06   \n",
      "mean   ...  1.000463e+00  1.412523e+02  3.490994e+00  9.979761e+00   \n",
      "std    ...  2.389589e-02  2.992587e+03  4.437357e-01  6.964476e+00   \n",
      "min    ...  7.776594e-01  1.225800e+00  2.640100e+00  4.000000e-01   \n",
      "25%    ...  9.894434e-01  2.440850e+01  3.167500e+00  3.900000e+00   \n",
      "50%    ...  9.999749e-01  4.230140e+01  3.484100e+00  8.500000e+00   \n",
      "75%    ...  1.010657e+00  7.944750e+01  3.693900e+00  1.500000e+01   \n",
      "max    ...  9.925838e+00  6.614396e+05  4.722200e+00  2.540000e+01   \n",
      "\n",
      "               f_23          f_24          f_25          f_26          f_27  \\\n",
      "count  4.643837e+06  4.109536e+06  4.644139e+06  4.642636e+06  4.644139e+06   \n",
      "mean   3.570550e-02 -1.490278e-02  1.402133e+01  1.120633e+01  9.987580e-01   \n",
      "std    3.991390e+00  4.176611e+00  2.836953e+00  5.446467e+02  1.585519e-02   \n",
      "min   -7.085976e+02 -5.739492e+00  1.025973e+01  1.850000e-02  7.637752e-01   \n",
      "25%    3.196098e-02 -7.915853e-01  1.176127e+01  1.643800e+00  9.946914e-01   \n",
      "50%    7.280300e-02 -2.009970e-01  1.300000e+01  3.441400e+00  1.000000e+00   \n",
      "75%    1.172330e-01  6.751719e-01  1.641103e+01  7.169600e+00  1.002640e+00   \n",
      "max    2.183440e+02  1.239097e+03  1.910000e+01  1.762208e+05  8.998392e+00   \n",
      "\n",
      "                  y  \n",
      "count  4.644139e+06  \n",
      "mean   5.621635e-03  \n",
      "std    9.766208e-02  \n",
      "min   -6.126091e-01  \n",
      "25%   -4.223676e-02  \n",
      "50%    1.949318e-03  \n",
      "75%    4.835084e-02  \n",
      "max    1.728492e+00  \n",
      "\n",
      "[8 rows x 29 columns]\n",
      "\n",
      "--- 分析目标变量 y 的分布 ---\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "# === 1. 导入库和数据初步检视 ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 设置绘图风格\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.size'] = 16\n",
    "# --- 加载原始数据 (非转换过的) ---\n",
    "# 假设 train_df 和 test_df 仍在内存中。\n",
    "# 如果不在，需要先运行数据加载脚本。\n",
    "try:\n",
    "    DATA_PATH = './stocks-return-prediction'\n",
    "    train_df = pd.read_pickle(os.path.join(DATA_PATH, 'train_data9.pkl'))\n",
    "    print(\"--- 已加载原始训练数据 ---\")\n",
    "except (NameError, FileNotFoundError):\n",
    "    print(\"--- 未找到原始数据，请先运行数据加载脚本 ---\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\n--- 数据基本信息 (info) ---\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\n--- 数据统计摘要 (describe) ---\")\n",
    "# .describe() 对于理解特征的尺度和分布至关重要\n",
    "print(train_df.describe())\n",
    "\n",
    "\n",
    "# === 2. 目标变量 `y` 分布分析 ===\n",
    "print(\"\\n--- 分析目标变量 y 的分布 ---\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(train_df['y'], bins=100, kde=True)\n",
    "plt.title('目标变量 (y) 的分布', fontsize=16)\n",
    "plt.xlabel('y (收益率)', fontsize=12)\n",
    "plt.ylabel('频数', fontsize=12)\n",
    "# 检查峰度和偏度\n",
    "skewness = train_df['y'].skew()\n",
    "kurtosis = train_df['y'].kurt()\n",
    "plt.text(0.05, 0.9, f'偏度 (Skewness): {skewness:.2f}\\n峰度 (Kurtosis): {kurtosis:.2f}',\n",
    "         transform=plt.gca().transAxes, bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5))\n",
    "plt.show()\n",
    "\n",
    "print(\"分析: 目标变量呈现出典型的金融收益率分布：尖峰厚尾（高kurtosis），意味着极端事件（大涨大跌）比正态分布更常见。这解释了为什么基于排序的Rank IC是比RMSE更鲁棒的评估指标。\")\n",
    "\n",
    "\n",
    "# === 3. 特征 `f_0` ~ `f_27` 分布分析 ===\n",
    "print(\"\\n--- 分析特征 f_0 ~ f_27 的分布 ---\")\n",
    "features_to_plot = [f'f_{i}' for i in range(28)]\n",
    "train_df[features_to_plot].hist(bins=50, figsize=(20, 15))\n",
    "plt.suptitle('所有原始特征的分布', fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n",
    "\n",
    "print(\"分析: 从特征分布来看，大部分特征近似于正态分布，但尺度（scale）各不相同。有些特征（如f_1, f_15）的偏度较大。这表明对某些特征进行标准化或归一化可能对某些模型有益。\")\n",
    "\n",
    "\n",
    "# === 4. 相关性分析 ===\n",
    "print(\"\\n--- 相关性分析 ---\")\n",
    "\n",
    "# (1) 特征与目标 `y` 的相关性\n",
    "feature_cols = [f'f_{i}' for i in range(28)]\n",
    "correlations = train_df[feature_cols + ['y']].corr()['y'].drop('y')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlations.sort_values().plot(kind='barh')\n",
    "plt.title('原始特征与目标y的斯皮尔曼相关系数', fontsize=16)\n",
    "plt.xlabel('相关系数', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "print(\"分析: 可以看到，不同特征与目标y的相关性有正有负，且强度不一。这为特征选择提供了初步依据。我们可以优先考虑那些相关性绝对值较高的特征进行更复杂的衍生。\")\n",
    "\n",
    "# (2) 特征与特征之间的相关性\n",
    "corr_matrix = train_df[feature_cols].corr()\n",
    "plt.figure(figsize=(18, 15))\n",
    "sns.heatmap(corr_matrix, cmap='viridis', annot=False)\n",
    "plt.title('特征相关性热力图', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "print(\"分析: 热力图显示特征之间存在一定的相关性结构（一些小方块）。这意味着存在信息冗余。我们可以通过PCA降维，或者创建特征之间的比率、差值来提取更有效的信息。\")\n",
    "\n",
    "\n",
    "# === 5. 时间序列分析 ===\n",
    "print(\"\\n--- 时间序列分析 ---\")\n",
    "# 按日期计算平均收益率\n",
    "mean_y_by_date = train_df.groupby('date')['y'].mean()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "mean_y_by_date.plot()\n",
    "plt.title('每日平均目标收益率 (y) 的时间序列', fontsize=16)\n",
    "plt.xlabel('日期', fontsize=12)\n",
    "plt.ylabel('平均收益率', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "print(\"分析: 市场存在明显的波动性聚集现象，即某些时段市场整体波动较大。这表明，计算波动率相关的特征（如滚动标准差）可能会非常有效。\")\n",
    "\n",
    "\n",
    "# === 6. 新的特征工程思路与实现 ===\n",
    "print(\"\\n--- 基于EDA的高级特征工程策略 ---\")\n",
    "print(\"\"\"\n",
    "1.  **特征交互 (Interaction Features):**\n",
    "    既然特征之间存在相关性，那么它们的组合可能包含新的信息。\n",
    "    例如，可以创建特征的比率 (f_a / f_b) 或差值 (f_a - f_b)。这在量化中很常见，\n",
    "    比如用一个动量因子除以一个波动率因子。\n",
    "\n",
    "2.  **横截面排名 (Cross-Sectional Ranking):**\n",
    "    这是量化策略中非常强大的一招！它不是看一个特征的绝对值，而是看它在\n",
    "    当天所有股票中所处的相对位置。这可以消除市场的系统性影响，并使特征更稳定。\n",
    "    我们可以创建一个自定义转换器来实现它。\n",
    "\n",
    "3.  **更丰富的滚动特征 (Richer Rolling Features):**\n",
    "    除了均值和标准差，我们还可以计算滚动窗口内的偏度(skew)和峰度(kurtosis)，\n",
    "    这可以捕捉到近期收益分布形态的变化。\n",
    "\n",
    "4.  **日期相关特征 (Date-based Features):**\n",
    "    虽然在这个比赛中可能作用有限，但有时从日期中提取星期几(dayofweek)\n",
    "    或月份(month)等信息可能会捕捉到微弱的周期性效应。\n",
    "\"\"\")\n",
    "\n",
    "# --- 示例：实现横截面排名转换器 ---\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CrossSectionalRank(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_rank):\n",
    "        self.features_to_rank = features_to_rank\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        print(\"正在生成横截面排名特征...\")\n",
    "        for feature in self.features_to_rank:\n",
    "            # 按日期分组，然后在每个组内对特征进行排名，并归一化到[-0.5, 0.5]\n",
    "            X_copy[f'{feature}_rank'] = X_copy.groupby('date')[feature].rank(pct=True) - 0.5\n",
    "        return X_copy\n",
    "\n",
    "# --- 如何在你的Pipeline中使用它 ---\n",
    "print(\"\\n--- 如何将新特征整合到Pipeline中 ---\")\n",
    "print(\"\"\"\n",
    "# from feature_engineering_pipeline import feature_engineering_pipeline, LagFeatureGenerator, RollingWindowFeatureGenerator\n",
    "\n",
    "# # 假设我们想对f_0到f_4进行排名\n",
    "# features_to_process = [f'f_{i}' for i in range(5)]\n",
    "\n",
    "# new_feature_pipeline = Pipeline(steps=[\n",
    "#     ('lag_features', LagFeatureGenerator(features_to_lag=features_to_process, lag_periods=[1, 2, 3])),\n",
    "#     ('rolling_features', RollingWindowFeatureGenerator(features_to_roll=features_to_process, window_sizes=[5, 10], aggregations=['mean', 'std'])),\n",
    "#     ('rank_features', CrossSectionalRank(features_to_rank=features_to_process)) # <-- 在这里加入新步骤\n",
    "# ])\n",
    "\n",
    "# print(\"新的特征工程管道:\")\n",
    "# print(new_feature_pipeline)\n",
    "\n",
    "# # 然后用这个新的pipeline去转换数据\n",
    "# # all_df_transformed = new_feature_pipeline.transform(all_df)\n",
    "\"\"\")"
   ],
   "id": "c6d0b3b70340efe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T10:13:06.111317Z",
     "start_time": "2025-07-28T10:08:23.868022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -特征工程管道 -*-\n",
    "\"\"\"\n",
    "特征工程管道 (v3 - Polars并行加速版)\n",
    "\n",
    "说明:\n",
    "本脚本是v2版本的性能优化版。我们引入了Polars库来并行处理\n",
    "计算密集型的特征工程步骤（滚动窗口和横截面排名），从而\n",
    "充分利用多核CPU，大幅提升处理速度。\n",
    "\n",
    "核心改动：\n",
    "1. 在转换器内部，将Pandas DataFrame转换为Polars DataFrame。\n",
    "2. 使用Polars强大的表达式API进行并行计算。\n",
    "3. 将计算结果转换回Pandas DataFrame，以保持与Scikit-learn管道的兼容性。\n",
    "\n",
    "请先安装Polars:\n",
    "pip install polars\n",
    "\"\"\"\n",
    "\n",
    "# === 1. 导入库和加载数据 ===\n",
    "import pandas as pd\n",
    "import polars as pl # 导入Polars\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- 加载原始数据 ---\n",
    "try:\n",
    "    DATA_PATH = './stocks-return-prediction'\n",
    "    train_df = pd.read_pickle(os.path.join(DATA_PATH, 'train_data9.pkl'))\n",
    "    test_df = pd.read_pickle(os.path.join(DATA_PATH, 'test_data9.pkl'))\n",
    "    print(\"--- 成功加载原始训练和测试数据 ---\")\n",
    "except (NameError, FileNotFoundError):\n",
    "    print(\"--- 未找到原始数据，请先运行数据加载脚本 ---\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# === 2. 定义性能优化的特征转换器 (使用Polars) ===\n",
    "print(\"\\n--- 正在定义使用Polars加速的特征转换器 ---\")\n",
    "\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    一个用于数据清洗和内存优化的转换器，包含：\n",
    "    1. 将指定列转换为数值类型。\n",
    "    2. 将所有float64列降级为float32。\n",
    "    3. 使用中位数填充所有列的NaN值。\n",
    "    \"\"\"\n",
    "    def __init__(self, object_cols_to_numeric=None):\n",
    "        self.object_cols_to_numeric = object_cols_to_numeric\n",
    "        self.medians = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_temp = X.copy()\n",
    "        if self.object_cols_to_numeric:\n",
    "            for col in self.object_cols_to_numeric:\n",
    "                X_temp[col] = pd.to_numeric(X_temp[col], errors='coerce')\n",
    "\n",
    "        # 降级精度\n",
    "        float_cols = [c for c in X_temp.columns if X_temp[c].dtype == 'float64']\n",
    "        for col in float_cols:\n",
    "            X_temp[col] = X_temp[col].astype('float32')\n",
    "\n",
    "        self.medians = X_temp.median(numeric_only=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        print(\"正在执行数据清洗和内存优化...\")\n",
    "        if self.object_cols_to_numeric:\n",
    "            for col in self.object_cols_to_numeric:\n",
    "                X_copy[col] = pd.to_numeric(X_copy[col], errors='coerce')\n",
    "\n",
    "        float_cols = [c for c in X_copy.columns if X_copy[c].dtype == 'float64']\n",
    "        if float_cols:\n",
    "            print(f\"正在转换 {len(float_cols)} 个浮点列为float32...\")\n",
    "            for col in float_cols:\n",
    "                X_copy[col] = X_copy[col].astype('float32')\n",
    "\n",
    "        X_copy.fillna(self.medians.astype('float32'), inplace=True)\n",
    "        return X_copy\n",
    "\n",
    "class FeatureInteraction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, interaction_pairs):\n",
    "        self.interaction_pairs = interaction_pairs\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        print(\"正在生成特征交互项...\")\n",
    "        for f1, f2, op in self.interaction_pairs:\n",
    "            if op == 'ratio':\n",
    "                new_col = (X_copy[f1] / (X_copy[f2] + 1e-6)).astype('float32')\n",
    "                X_copy[f\"{f1}_div_{f2}\"] = new_col\n",
    "            elif op == 'diff':\n",
    "                new_col = (X_copy[f1] - X_copy[f2]).astype('float32')\n",
    "                X_copy[f\"{f1}_sub_{f2}\"] = new_col\n",
    "        return X_copy\n",
    "\n",
    "class PolarsLagFeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_lag, lag_periods):\n",
    "        self.features_to_lag = features_to_lag\n",
    "        self.lag_periods = lag_periods\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        print(\"正在生成滞后特征 (Polars)...\")\n",
    "        pl_df = pl.from_pandas(X).sort(['code', 'date'])\n",
    "\n",
    "        lag_expressions = []\n",
    "        for feature in self.features_to_lag:\n",
    "            for lag in self.lag_periods:\n",
    "                expr = pl.col(feature).shift(lag).over('code').cast(pl.Float32).alias(f\"{feature}_lag_{lag}\")\n",
    "                lag_expressions.append(expr)\n",
    "\n",
    "        pl_df = pl_df.with_columns(lag_expressions)\n",
    "        return pl_df.to_pandas()\n",
    "\n",
    "class PandasRollingWindowFeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_roll, window_sizes, aggregations):\n",
    "        self.features_to_roll = features_to_roll\n",
    "        self.window_sizes = window_sizes\n",
    "        self.aggregations = aggregations\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        print(\"正在生成滚动窗口特征 (Pandas - 稳定模式)...\")\n",
    "        grouped = X_copy.groupby('code')\n",
    "        for feature in self.features_to_roll:\n",
    "            for window in self.window_sizes:\n",
    "                for agg in self.aggregations:\n",
    "                    new_col_name = f\"{feature}_rol_{window}_{agg}\"\n",
    "                    rolling_feature = grouped[feature].transform(\n",
    "                        lambda s: s.rolling(window, min_periods=1).agg(agg)\n",
    "                    ).astype('float32')\n",
    "                    X_copy[new_col_name] = rolling_feature\n",
    "        return X_copy\n",
    "\n",
    "class PolarsCrossSectionalRank(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_rank):\n",
    "        self.features_to_rank = features_to_rank\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        print(\"正在生成横截面排名特征 (Polars)...\")\n",
    "        pl_df = pl.from_pandas(X).sort(['date', 'code'])\n",
    "\n",
    "        rank_expressions = []\n",
    "        for feature in self.features_to_rank:\n",
    "            expr = ((pl.col(feature).rank(method='ordinal').over('date') - 1) /\n",
    "                    (pl.col(feature).count().over('date') - 1) - 0.5) \\\n",
    "                   .cast(pl.Float32).alias(f\"{feature}_rank\")\n",
    "            rank_expressions.append(expr)\n",
    "\n",
    "        pl_df = pl_df.with_columns(rank_expressions)\n",
    "        return pl_df.to_pandas()\n",
    "\n",
    "\n",
    "# === 3. 创建并配置新的并行化特征工程管道 ===\n",
    "print(\"\\n--- 正在创建Polars并行化特征工程管道 ---\")\n",
    "\n",
    "features_for_deep_eng = [\n",
    "    'f_7', 'f_27', 'f_6', 'f_19', 'f_9',\n",
    "    'f_15', 'f_16', 'f_11', 'f_5', 'f_22'\n",
    "]\n",
    "interaction_pairs = [\n",
    "    ('f_7', 'f_15', 'ratio'), ('f_27', 'f_16', 'ratio'), ('f_6', 'f_11', 'diff')\n",
    "]\n",
    "\n",
    "feature_engineering_pipeline_v3 = Pipeline(steps=[\n",
    "    ('cleaner', DataCleaner(object_cols_to_numeric=['f_17'])),\n",
    "    ('lag_features', PolarsLagFeatureGenerator(features_to_lag=features_for_deep_eng, lag_periods=[1, 2, 3])),\n",
    "    ('rolling_features', PandasRollingWindowFeatureGenerator(\n",
    "        features_to_roll=features_for_deep_eng,\n",
    "        window_sizes=[5, 10, 20],\n",
    "        aggregations=['mean', 'std']\n",
    "    )),\n",
    "    ('rank_features', PolarsCrossSectionalRank(features_to_rank=features_for_deep_eng)),\n",
    "    ('interaction_features', FeatureInteraction(interaction_pairs=interaction_pairs)),\n",
    "])\n",
    "\n",
    "print(\"混合动力管道创建成功:\")\n",
    "print(feature_engineering_pipeline_v3)\n",
    "\n",
    "\n",
    "# === 4. 应用新管道到数据 ===\n",
    "print(\"\\n--- 正在应用新管道转换数据 ---\")\n",
    "\n",
    "all_df = pd.concat([train_df.drop('y', axis=1), test_df], ignore_index=True)\n",
    "train_len = len(train_df) # 在删除前获取长度\n",
    "y_original = train_df['y'].copy() # 提前保存y值\n",
    "del train_df, test_df\n",
    "gc.collect()\n",
    "\n",
    "all_df_transformed = feature_engineering_pipeline_v3.fit_transform(all_df)\n",
    "del all_df\n",
    "gc.collect()\n",
    "\n",
    "# 后续处理保持不变\n",
    "all_df_transformed.fillna(0, inplace=True)\n",
    "\n",
    "train_transformed_df = all_df_transformed.iloc[:train_len].copy()\n",
    "test_transformed_df = all_df_transformed.iloc[train_len:].copy()\n",
    "del all_df_transformed\n",
    "gc.collect()\n",
    "\n",
    "print(\"正在对齐y值...\")\n",
    "train_transformed_df['y'] = y_original.astype('float32').values\n",
    "del y_original\n",
    "gc.collect()\n",
    "\n",
    "print(\"数据转换完成。\")\n",
    "\n",
    "\n",
    "# === 5. 查看转换后的数据 ===\n",
    "print(\"\\n--- 查看转换后的训练数据 ---\")\n",
    "print(f\"转换后训练数据形状: {train_transformed_df.shape}\")\n",
    "print(train_transformed_df.info())\n"
   ],
   "id": "70e2250650d21542",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 成功加载原始训练和测试数据 ---\n",
      "\n",
      "--- 正在定义使用Polars加速的特征转换器 ---\n",
      "\n",
      "--- 正在创建Polars并行化特征工程管道 ---\n",
      "混合动力管道创建成功:\n",
      "Pipeline(steps=[('cleaner', DataCleaner(object_cols_to_numeric=['f_17'])),\n",
      "                ('lag_features',\n",
      "                 PolarsLagFeatureGenerator(features_to_lag=['f_7', 'f_27',\n",
      "                                                            'f_6', 'f_19',\n",
      "                                                            'f_9', 'f_15',\n",
      "                                                            'f_16', 'f_11',\n",
      "                                                            'f_5', 'f_22'],\n",
      "                                           lag_periods=[1, 2, 3])),\n",
      "                ('rolling_features',\n",
      "                 PandasRollingWindowFeatureGenerator(aggregations=['mean',\n",
      "                                                                   'std'],\n",
      "                                                     features_to_roll=['f_7',\n",
      "                                                                       'f_27',\n",
      "                                                                       'f_6',\n",
      "                                                                       'f_19',\n",
      "                                                                       'f_9',\n",
      "                                                                       'f_15',\n",
      "                                                                       'f_16',\n",
      "                                                                       'f_11',\n",
      "                                                                       'f_5',\n",
      "                                                                       'f_22'],\n",
      "                                                     window_sizes=[5, 10, 20])),\n",
      "                ('rank_features',\n",
      "                 PolarsCrossSectionalRank(features_to_rank=['f_7', 'f_27',\n",
      "                                                            'f_6', 'f_19',\n",
      "                                                            'f_9', 'f_15',\n",
      "                                                            'f_16', 'f_11',\n",
      "                                                            'f_5', 'f_22'])),\n",
      "                ('interaction_features',\n",
      "                 FeatureInteraction(interaction_pairs=[('f_7', 'f_15', 'ratio'),\n",
      "                                                       ('f_27', 'f_16',\n",
      "                                                        'ratio'),\n",
      "                                                       ('f_6', 'f_11',\n",
      "                                                        'diff')]))])\n",
      "\n",
      "--- 正在应用新管道转换数据 ---\n",
      "正在执行数据清洗和内存优化...\n",
      "正在转换 27 个浮点列为float32...\n",
      "正在生成滞后特征 (Polars)...\n",
      "正在生成滚动窗口特征 (Pandas - 稳定模式)...\n",
      "正在生成横截面排名特征 (Polars)...\n",
      "正在生成特征交互项...\n",
      "正在对齐y值...\n",
      "数据转换完成。\n",
      "\n",
      "--- 查看转换后的训练数据 ---\n",
      "转换后训练数据形状: (4644139, 134)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4644139 entries, 0 to 4644138\n",
      "Columns: 134 entries, code to y\n",
      "dtypes: float32(131), int64(2), object(1)\n",
      "memory usage: 2.4+ GB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T15:09:06.199750Z",
     "start_time": "2025-07-28T14:26:37.387979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10.5 模型训练管道 (v6 - 本地CPU最终版)\n",
    "\"\"\"\n",
    "模型训练管道 (v6 - 本地CPU最终版)\n",
    "\n",
    "说明:\n",
    "本脚本是为在本地计算机上运行而优化的最终版本。它不再进行超参数搜索，\n",
    "而是直接使用我们已经找到的最优参数来训练模型并生成提交文件。\n",
    "\n",
    "核心策略:\n",
    "1.  **本地路径适配**: 所有文件路径均已更新为本地项目结构。\n",
    "2.  **纯CPU训练**: 所有模型均配置为在CPU上运行，并会自动利用所有可用的CPU核心。\n",
    "3.  **核心特征工程**: 坚持使用已被验证为最高效的截面排名 (Cross-Sectional Ranking)。\n",
    "4.  **固化最优参数**: 直接使用LGBM, XGBoost, CatBoost的最优参数进行训练。\n",
    "5.  **内存管理**: 保留了所有内存优化和错误处理的最佳实践。\n",
    "\"\"\"\n",
    "\n",
    "# === 1. 导入库和准备数据 ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import os\n",
    "import gc\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "import traceback\n",
    "import optuna\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# === 2. 核心特征工程与数据准备 ===\n",
    "print(\"--- 正在加载数据并执行截面排名特征工程 ---\")\n",
    "\n",
    "def preprocess_and_rank(df):\n",
    "    \"\"\"对原始DataFrame进行清洗和截面排名 (最稳定版本)\"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ['code', 'date']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    float_cols = [c for c in df.columns if df[c].dtype == 'float64']\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype('float32')\n",
    "\n",
    "    pl_df = pl.from_pandas(df)\n",
    "    feature_cols = [col for col in df.columns if col.startswith('f_')]\n",
    "\n",
    "    pl_df = pl_df.with_columns([\n",
    "        (\n",
    "            (pl.col(feature).rank(method='ordinal').over('date') - 1) /\n",
    "            (pl.col(feature).count().over('date') - 1)\n",
    "        ).alias(feature)\n",
    "        for feature in feature_cols\n",
    "    ])\n",
    "\n",
    "    final_df = pl_df.to_pandas()\n",
    "    final_df.fillna(0.5, inplace=True)\n",
    "    return final_df\n",
    "\n",
    "try:\n",
    "    # *** 本地路径适配 ***\n",
    "    DATA_PATH = './stocks-return-prediction'\n",
    "    train_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'train_data9.pkl'))\n",
    "    test_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'test_data9.pkl'))\n",
    "\n",
    "    train_processed_df = preprocess_and_rank(train_df_raw.copy())\n",
    "    test_processed_df = preprocess_and_rank(test_df_raw.copy())\n",
    "\n",
    "    original_test_df_identifiers = test_df_raw[['code', 'date']].copy()\n",
    "\n",
    "    del train_df_raw, test_df_raw\n",
    "    gc.collect()\n",
    "    print(\"截面排名特征工程完成。\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"!!!!!!!! 数据加载或特征工程失败 !!!!!!!!\")\n",
    "    print(f\"错误类型: {type(e).__name__}\")\n",
    "    print(f\"错误信息: {e}\")\n",
    "    traceback.print_exc()\n",
    "    exit()\n",
    "\n",
    "# --- 定义特征列和目标列 ---\n",
    "features = [f'f_{i}' for i in range(28)]\n",
    "target = 'y'\n",
    "print(f\"使用的特征数量: {len(features)}\")\n",
    "\n",
    "\n",
    "# === 3. 定义评估指标 (Rank IC) - Polars加速版 ===\n",
    "def calculate_rank_ic_polars(y_true, y_pred, dates):\n",
    "    df = pl.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'date': dates})\n",
    "    daily_ic = df.group_by('date', maintain_order=True).agg(\n",
    "        pl.corr('y_true', 'y_pred', method='spearman').fill_nan(0.0).alias('ic')\n",
    "    )\n",
    "    return daily_ic['ic'].mean()\n",
    "\n",
    "\n",
    "# === 4. 创建时间序列验证集 (带每日抽样) ===\n",
    "print(\"\\n--- 创建时间序列训练/验证集 ---\")\n",
    "unique_dates = sorted(train_processed_df['date'].unique())\n",
    "split_date = unique_dates[-300]\n",
    "\n",
    "train_split_df = train_processed_df[train_processed_df['date'] < split_date]\n",
    "val_split_df = train_processed_df[train_processed_df['date'] >= split_date]\n",
    "\n",
    "# *** NEW: Sample from each date for hyperparameter tuning ***\n",
    "print(f\"为加速调优，将在每个日期随机抽取最多200条数据。\")\n",
    "X_train_sample = train_split_df.groupby('date').apply(\n",
    "    lambda x: x.sample(n=min(len(x), 1000), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "y_train_sample = X_train_sample[target]\n",
    "X_train_sample = X_train_sample[features]\n",
    "\n",
    "X_val = val_split_df[features]\n",
    "y_val = val_split_df[target]\n",
    "val_dates_for_ic = val_split_df['date']\n",
    "\n",
    "print(f\"调优训练集大小: {X_train_sample.shape}, 验证集大小: {X_val.shape}\")\n",
    "\n",
    "\n",
    "# === 5. 使用Optuna进行超参数调优 ===\n",
    "def objective(trial, model_name):\n",
    "    n_jobs_per_trial = -1\n",
    "    if model_name == 'lgbm':\n",
    "        params = { 'random_state': 42, 'n_jobs': n_jobs_per_trial, 'verbose': -1, 'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1), 'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100), 'num_leaves': trial.suggest_int('num_leaves', 20, 150), 'max_depth': trial.suggest_int('max_depth', 5, 15), 'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0), 'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0) }\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "    elif model_name == 'xgb':\n",
    "        params = { 'random_state': 42, 'n_jobs': n_jobs_per_trial, 'tree_method': 'hist', 'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100), 'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05), 'max_depth': trial.suggest_int('max_depth', 3, 8) }\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "    elif model_name == 'catboost':\n",
    "        params = { 'thread_count': n_jobs_per_trial, 'random_seed': 42, 'verbose': 0, 'allow_writing_files': False, 'iterations': trial.suggest_int('iterations', 200, 1000, step=100), 'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05), 'depth': trial.suggest_int('depth', 4, 10) }\n",
    "        model = cb.CatBoostRegressor(**params)\n",
    "\n",
    "    model.fit(X_train_sample, y_train_sample)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return calculate_rank_ic_polars(y_val, y_pred, val_dates_for_ic)\n",
    "\n",
    "# --- 运行调优 ---\n",
    "models_to_tune = ['lgbm', 'xgb', 'catboost']\n",
    "best_params_all = {}\n",
    "N_TRIALS = 15\n",
    "N_JOBS_OPTUNA = -1\n",
    "\n",
    "print(f\"\\n--- 开始对 {len(models_to_tune)} 个模型进行并行化超参数调优 (每个模型 {N_TRIALS} 次试验) ---\")\n",
    "for model_name in tqdm(models_to_tune, desc=\"Overall Tuning Progress\"):\n",
    "    print(f\"\\n--- 正在调优: {model_name.upper()} ---\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    with parallel_backend('loky', n_jobs=N_JOBS_OPTUNA):\n",
    "        study.optimize(lambda trial: objective(trial, model_name), n_trials=N_TRIALS, n_jobs=N_JOBS_OPTUNA, show_progress_bar=True)\n",
    "    best_params_all[model_name] = study.best_params\n",
    "    print(f\"调优完成。最优Rank IC: {study.best_value:.6f}\")\n",
    "    print(f\"最优参数: {study.best_params}\")\n",
    "\n",
    "\n",
    "# === 6. 训练最终模型并进行集成预测 ===\n",
    "print(\"\\n--- 使用最优参数在完整数据上训练最终模型 ---\")\n",
    "full_train_df = train_processed_df[train_processed_df['date'] < split_date]\n",
    "\n",
    "print(f\"完整训练数据过大 ({len(full_train_df)} 行), 将在每个日期随机抽取最多1000条数据进行最终训练。\")\n",
    "final_train_df = full_train_df.groupby('date').apply(\n",
    "    lambda x: x.sample(n=min(len(x), 1000), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "print(f\"采样后的最终训练集大小为 {len(final_train_df)} 行。\")\n",
    "\n",
    "X_full_train = final_train_df[features]\n",
    "y_full_train = final_train_df[target]\n",
    "X_test = test_processed_df[features]\n",
    "\n",
    "del train_processed_df, test_processed_df, full_train_df, final_train_df\n",
    "gc.collect()\n",
    "\n",
    "predictions = []\n",
    "final_models_order = ['lgbm', 'xgb', 'catboost']\n",
    "for model_name in tqdm(final_models_order, desc=\"Final Model Training\"):\n",
    "    if model_name not in best_params_all:\n",
    "        continue\n",
    "\n",
    "    params = best_params_all[model_name]\n",
    "    print(f\"正在训练最终的 {model_name.upper()} 模型...\")\n",
    "    try:\n",
    "        if model_name == 'lgbm':\n",
    "            params.update({'random_state': 42, 'n_jobs': -1, 'verbose': -1})\n",
    "            model = lgb.LGBMRegressor(**params)\n",
    "        elif model_name == 'xgb':\n",
    "            params.update({'random_state': 42, 'n_jobs': -1, 'tree_method': 'hist'})\n",
    "            model = xgb.XGBRegressor(**params)\n",
    "        elif model_name == 'catboost':\n",
    "            params.update({'thread_count': -1, 'random_seed': 42, 'verbose': 0, 'allow_writing_files': False})\n",
    "            model = cb.CatBoostRegressor(**params)\n",
    "\n",
    "        model.fit(X_full_train, y_full_train)\n",
    "        predictions.append(model.predict(X_test))\n",
    "        print(f\"{model_name.upper()} 预测完成。\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!!!!!!! 训练模型 {model_name.upper()} 失败: {e} !!!!!!!!\")\n",
    "        print(\"本次集成将跳过该模型。\")\n",
    "\n",
    "\n",
    "# === 7. 生成提交文件 ===\n",
    "if not predictions:\n",
    "    print(\"所有模型训练均失败，无法生成提交文件。\")\n",
    "else:\n",
    "    ensemble_prediction = np.mean(predictions, axis=0)\n",
    "    print(\"\\n集成预测完成。\")\n",
    "    print(\"\\n--- 正在生成提交文件 ---\")\n",
    "\n",
    "    submission_df = original_test_df_identifiers.copy()\n",
    "    submission_df['y_pred'] = ensemble_prediction\n",
    "\n",
    "    submission_df['id'] = range(len(submission_df))\n",
    "\n",
    "    submission_df = submission_df[['id', 'code', 'date', 'y_pred']]\n",
    "\n",
    "    submission_file = 'submission.csv'\n",
    "    submission_df.to_csv(submission_file, index=False)\n",
    "    print(f\"提交文件 '{submission_file}' 已生成。\")\n",
    "    print(submission_df.head())"
   ],
   "id": "bb402681d0f14356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在加载数据并执行截面排名特征工程 ---\n",
      "截面排名特征工程完成。\n",
      "使用的特征数量: 28\n",
      "\n",
      "--- 创建时间序列训练/验证集 ---\n",
      "为加速调优，将在每个日期随机抽取最多200条数据。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_35084\\1584234994.py:106: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  X_train_sample = train_split_df.groupby('date').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调优训练集大小: (1391000, 28), 验证集大小: (1048233, 28)\n",
      "\n",
      "--- 开始对 3 个模型进行并行化超参数调优 (每个模型 15 次试验) ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Overall Tuning Progress:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92a8c52d82564b14ac693fa8f0d1a5c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 正在调优: LGBM ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4190b8f55fea4ae2bafc5cff6043c384"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调优完成。最优Rank IC: 0.116930\n",
      "最优参数: {'learning_rate': 0.04596139206940063, 'n_estimators': 200, 'num_leaves': 21, 'max_depth': 6, 'feature_fraction': 0.6955973740152936, 'bagging_fraction': 0.5835145377028257}\n",
      "\n",
      "--- 正在调优: XGB ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0c241b9b64b42508dfaae0c7fc855a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调优完成。最优Rank IC: 0.116576\n",
      "最优参数: {'n_estimators': 400, 'learning_rate': 0.02911348329537932, 'max_depth': 4}\n",
      "\n",
      "--- 正在调优: CATBOOST ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b95b13e1d8c46239a524362365c31d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调优完成。最优Rank IC: 0.117536\n",
      "最优参数: {'iterations': 500, 'learning_rate': 0.042015955854694455, 'depth': 4}\n",
      "\n",
      "--- 使用最优参数在完整数据上训练最终模型 ---\n",
      "完整训练数据过大 (3595906 行), 将在每个日期随机抽取最多1000条数据进行最终训练。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_35084\\1584234994.py:158: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_train_df = full_train_df.groupby('date').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "采样后的最终训练集大小为 1391000 行。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Final Model Training:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbbf210a5ed24335bbc88d8ae966e219"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在训练最终的 LGBM 模型...\n",
      "LGBM 预测完成。\n",
      "正在训练最终的 XGB 模型...\n",
      "XGB 预测完成。\n",
      "正在训练最终的 CATBOOST 模型...\n",
      "CATBOOST 预测完成。\n",
      "\n",
      "集成预测完成。\n",
      "\n",
      "--- 正在生成提交文件 ---\n",
      "提交文件 'submission.csv' 已生成。\n",
      "         id    code  date    y_pred\n",
      "4647483   0  s_2554  1691 -0.002699\n",
      "4646572   1  s_1612  1691  0.002016\n",
      "4646612   2  s_1911  1691  0.002158\n",
      "4646498   3   s_814  1691 -0.002218\n",
      "4647458   4   s_325  1691 -0.000881\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T12:49:38.737799Z",
     "start_time": "2025-07-29T12:10:13.618689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 9.2 === 模型训练管道 v12.1 (最终索引修复版) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import gc\n",
    "import polars as pl\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn & Scikit-optimize Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. 评估指标与评分函数 ---\n",
    "\n",
    "def calculate_rank_ic_polars(y_true, y_pred, dates):\n",
    "    \"\"\"使用Polars高效计算Rank IC\"\"\"\n",
    "    if isinstance(y_true, pd.Series): y_true = y_true.to_numpy()\n",
    "    if isinstance(y_pred, pd.Series): y_pred = y_pred.to_numpy()\n",
    "    if isinstance(dates, pd.Series): dates = dates.to_numpy()\n",
    "\n",
    "    df = pl.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'date': dates})\n",
    "    daily_ic = df.group_by('date', maintain_order=True).agg(\n",
    "        pl.corr('y_true', 'y_pred', method='spearman').fill_nan(0.0).alias('ic')\n",
    "    )\n",
    "    return daily_ic['ic'].mean()\n",
    "\n",
    "class RankICScorer:\n",
    "    \"\"\"(v1.2) 一个与scikit-learn兼容的自定义评分器 (最终索引修复版)\"\"\"\n",
    "    def __init__(self, dates: pd.Series):\n",
    "        # 核心修复: 移除 reset_index，保留原始索引以进行正确的匹配\n",
    "        self.dates = dates\n",
    "\n",
    "    def __call__(self, estimator, X, y_true) -> float:\n",
    "        y_pred = estimator.predict(X)\n",
    "        # 现在 y_true.index 可以正确地在 self.dates.index 中找到匹配项\n",
    "        fold_dates = self.dates.loc[y_true.index]\n",
    "        rank_ic = calculate_rank_ic_polars(y_true, y_pred, fold_dates)\n",
    "        print(f\"[RankICScorer] Fold Rank IC = {rank_ic:.6f}\")\n",
    "        return rank_ic if np.isfinite(rank_ic) else 0.0\n",
    "\n",
    "# --- 2. 初始截面排名 (保持不变) ---\n",
    "def preprocess_and_rank(df):\n",
    "    \"\"\"初始预处理，使用Polars进行截面排名\"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ['code', 'date']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    float_cols = [c for c in df.columns if df[c].dtype == 'float64']\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    pl_df = pl.from_pandas(df)\n",
    "    feature_cols = [col for col in df.columns if col.startswith('f_')]\n",
    "    pl_df = pl_df.with_columns([\n",
    "        ((pl.col(feature).rank(method='ordinal').over('date') - 1) / (pl.col(feature).count().over('date') - 1)).alias(feature)\n",
    "        for feature in feature_cols\n",
    "    ])\n",
    "    final_df = pl_df.to_pandas()\n",
    "    final_df.fillna(0.5, inplace=True)\n",
    "    return final_df\n",
    "\n",
    "# --- 3. 定义Pipeline组件 ---\n",
    "\n",
    "class FeatureEngineeringTransformerPolars(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"(v4.5) 高级特征工程 (Polars最终修复版).\"\"\"\n",
    "    def __init__(self):\n",
    "        self.base_price_features = [f'f_{i}' for i in [0, 3, 6, 9, 12, 15, 18, 21, 24]]\n",
    "        self.base_size_features = [f'f_{i}' for i in [1, 4, 7, 10, 13, 16, 19, 22, 25]]\n",
    "        self.base_features = self.base_price_features + self.base_size_features\n",
    "\n",
    "    def fit(self, X, y=None): return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        pl_X = pl.from_pandas(X)\n",
    "\n",
    "        value_expressions = [(pl.col(p_col) * pl.col(s_col)).alias(f'value_{p_col}') for p_col, s_col in zip(self.base_price_features, self.base_size_features)]\n",
    "        pl_X = pl_X.with_columns(value_expressions)\n",
    "\n",
    "        vwap_value_cols = [f'value_f_{i}' for i in [0, 3, 6, 9, 12, 15, 18, 21, 24]]\n",
    "        sum_sizes = pl.sum_horizontal(pl.col(c) for c in self.base_size_features)\n",
    "        pl_X = pl_X.with_columns(\n",
    "            (pl.sum_horizontal(pl.col(c) for c in vwap_value_cols) / pl.when(sum_sizes == 0).then(None).otherwise(sum_sizes)).alias('vwap')\n",
    "        )\n",
    "\n",
    "        final_expressions = [(pl.col('f_0') / pl.when(pl.col('vwap') == 0).then(None).otherwise(pl.col('vwap')) - 1).alias('price_to_vwap_ratio')]\n",
    "\n",
    "        for window in [5, 10, 21]:\n",
    "            final_expressions.append(pl.col('f_0').rolling_std(window, min_periods=int(window*0.8)).over('code').alias(f'volatility_{window}'))\n",
    "        for window in [1, 2, 5, 10]:\n",
    "            shifted_price = pl.col('f_0').shift(window).over('code')\n",
    "            final_expressions.append((pl.col('f_0') / pl.when(shifted_price == 0).then(None).otherwise(shifted_price) - 1).alias(f'momentum_{window}'))\n",
    "        for col in self.base_features:\n",
    "            final_expressions.append((pl.col(col) - pl.col(col).mean().over('date')).alias(f'{col}_market_diff'))\n",
    "\n",
    "        X_with_features = pl_X.with_columns(final_expressions)\n",
    "\n",
    "        X_filled = X_with_features.fill_nan(0).fill_null(0)\n",
    "\n",
    "        float_cols = [c.name for c in X_filled if c.dtype in pl.FLOAT_DTYPES]\n",
    "        X_cleaned = X_filled.with_columns([\n",
    "            pl.when(pl.col(c).is_infinite()).then(pl.lit(0.0)).otherwise(pl.col(c)).alias(c)\n",
    "            for c in float_cols\n",
    "        ])\n",
    "\n",
    "        X_pd = X_cleaned.to_pandas()\n",
    "        X_pd.index = X.index # 确保原始索引被保留\n",
    "\n",
    "        feature_cols = [c for c in X_pd.columns if X_pd[c].dtype in [np.float32, np.float64]]\n",
    "        return X_pd[feature_cols]\n",
    "\n",
    "# --- 4. 主执行流程 ---\n",
    "def main():\n",
    "    print(\"--- 正在加载数据 ---\")\n",
    "    DATA_PATH = './stocks-return-prediction'\n",
    "    train_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'train_data9.pkl'))\n",
    "    test_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'test_data9.pkl'))\n",
    "\n",
    "    print(\"\\n--- 1. 初始预处理 ---\")\n",
    "    train_df = preprocess_and_rank(train_df_raw.copy())\n",
    "    test_df = preprocess_and_rank(test_df_raw.copy())\n",
    "    train_df.sort_values(by=['date', 'code'], inplace=True, ignore_index=True)\n",
    "    test_df.sort_values(by=['date', 'code'], inplace=True, ignore_index=True)\n",
    "\n",
    "    print(\"\\n--- 2. 使用稳健时间窗口划分数据 ---\")\n",
    "    unique_dates = sorted(train_df['date'].unique())\n",
    "    val_start_date = unique_dates[-100]\n",
    "    search_start_date = unique_dates[-300]\n",
    "\n",
    "    val_df = train_df[train_df['date'] >= val_start_date]\n",
    "    search_df = train_df[(train_df['date'] >= search_start_date) & (train_df['date'] < val_start_date)]\n",
    "    feat_sel_df = train_df[train_df['date'] < search_start_date]\n",
    "\n",
    "    print(f\"特征筛选集: {feat_sel_df['date'].min()} - {feat_sel_df['date'].max()} ({feat_sel_df['date'].nunique()} 天)\")\n",
    "    print(f\"超参数搜索集: {search_df['date'].min()} - {search_df['date'].max()} ({search_df['date'].nunique()} 天)\")\n",
    "    print(f\"最终验证集: {val_df['date'].min()} - {val_df['date'].max()} ({val_df['date'].nunique()} 天)\")\n",
    "\n",
    "    del train_df_raw\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"\\n--- 3. 开始特征筛选 ---\")\n",
    "    feature_generator = FeatureEngineeringTransformerPolars()\n",
    "    print(\"为筛选生成所有高级特征...\")\n",
    "    X_eng_all = feature_generator.transform(feat_sel_df.drop(columns=['y']))\n",
    "    y_eng_all = feat_sel_df['y']\n",
    "\n",
    "    print(\"训练基础XGBoost模型以评估特征重要性...\")\n",
    "    selector_model = xgb.XGBRegressor(random_state=42, tree_method='gpu_hist', n_jobs=1)\n",
    "    selector_model.fit(X_eng_all, y_eng_all)\n",
    "\n",
    "    importances = pd.Series(selector_model.feature_importances_, index=X_eng_all.columns)\n",
    "    TOP_100_FEATURES = importances.nlargest(100).index.tolist()\n",
    "\n",
    "    print(f\"特征筛选完成，选出最重要的100个特征。\")\n",
    "    del X_eng_all, y_eng_all, selector_model, importances\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"\\n--- 4. 对所有数据进行一次性特征工程 ---\")\n",
    "    final_train_df = pd.concat([feat_sel_df, search_df])\n",
    "\n",
    "    print(\"处理最终训练集...\")\n",
    "    X_train_final = feature_generator.transform(final_train_df.drop(columns=['y']))[TOP_100_FEATURES]\n",
    "    y_train_final = final_train_df['y']\n",
    "\n",
    "    print(\"处理验证集...\")\n",
    "    X_val_final = feature_generator.transform(val_df.drop(columns=['y']))[TOP_100_FEATURES]\n",
    "    y_val_final = val_df['y']\n",
    "    val_dates_final = val_df['date']\n",
    "\n",
    "    print(\"处理测试集...\")\n",
    "    X_test_final = feature_generator.transform(test_df)[TOP_100_FEATURES]\n",
    "\n",
    "    del feat_sel_df, final_train_df, val_df, train_df\n",
    "    gc.collect()\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', xgb.XGBRegressor(random_state=42, tree_method='gpu_hist', n_jobs=1))\n",
    "    ])\n",
    "\n",
    "    search_spaces = {\n",
    "        'model__n_estimators': (500, 2000),\n",
    "        'model__learning_rate': (0.005, 0.05, 'log-uniform'),\n",
    "        'model__max_depth': (3, 8),\n",
    "        'model__subsample': (0.6, 1.0, 'uniform'),\n",
    "        'model__colsample_bytree': (0.6, 1.0, 'uniform'),\n",
    "        'model__gamma': (0.0, 1.0, 'uniform'),\n",
    "        'model__min_child_weight': (1, 30),\n",
    "        'model__reg_alpha': (1e-2, 1.0, 'log-uniform'),\n",
    "        'model__reg_lambda': (1e-2, 1.0, 'log-uniform'),\n",
    "    }\n",
    "\n",
    "    X_search = feature_generator.transform(search_df.drop(columns=['y']))[TOP_100_FEATURES]\n",
    "    y_search = search_df['y']\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rank_ic_scorer = RankICScorer(dates=search_df['date'])\n",
    "\n",
    "    search = BayesSearchCV(\n",
    "        estimator=pipeline,\n",
    "        search_spaces=search_spaces,\n",
    "        n_iter=30,\n",
    "        scoring=rank_ic_scorer,\n",
    "        cv=tscv,\n",
    "        random_state=42,\n",
    "        n_jobs=1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- 5. 开始使用贝叶斯优化进行超参数搜索 (数据量: {len(X_search)}) ---\")\n",
    "    search.fit(X_search, y_search)\n",
    "\n",
    "    print(\"\\n--- 超参数搜索完成 ---\")\n",
    "    print(f\"最佳参数: {search.best_params_}\")\n",
    "    print(f\"最佳交叉验证得分 (Rank IC): {search.best_score_:.6f}\")\n",
    "\n",
    "    best_pipeline = search.best_estimator_\n",
    "\n",
    "    print(\"\\n--- 6. 在所有历史数据上训练最终模型 ---\")\n",
    "    best_pipeline.fit(X_train_final, y_train_final)\n",
    "    print(\"最终模型训练完成。\")\n",
    "\n",
    "    print(\"\\n--- 7. 在独立验证集上评估最终模型 ---\")\n",
    "    y_pred_val = best_pipeline.predict(X_val_final)\n",
    "    final_rank_ic = calculate_rank_ic_polars(y_val_final, y_pred_val, val_dates_final)\n",
    "    print(f\"\\n独立验证集上的最终Rank IC: {final_rank_ic:.6f}\")\n",
    "\n",
    "    print(\"\\n--- 8. 生成最终提交文件 ---\")\n",
    "    predictions = best_pipeline.predict(X_test_final)\n",
    "\n",
    "    submission_df = test_df[['code', 'date']].copy()\n",
    "    submission_df['y_pred'] = predictions\n",
    "    submission_df.reset_index(inplace=True)\n",
    "    submission_df.rename(columns={'index': 'id'}, inplace=True)\n",
    "\n",
    "    submission_df = submission_df[['id', 'code', 'date', 'y_pred']]\n",
    "    submission_df.to_csv('submission_pipeline_v12.1.csv', index=False)\n",
    "    print(\"提交文件 'submission_pipeline_v12.1.csv' 已生成.\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "13a4ec46f6baaabf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在加载数据 ---\n",
      "\n",
      "--- 1. 初始预处理 ---\n",
      "\n",
      "--- 2. 使用稳健时间窗口划分数据 ---\n",
      "特征筛选集: 0 - 1390 (1391 天)\n",
      "超参数搜索集: 1391 - 1590 (200 天)\n",
      "最终验证集: 1591 - 1690 (100 天)\n",
      "\n",
      "--- 3. 开始特征筛选 ---\n",
      "为筛选生成所有高级特征...\n",
      "训练基础XGBoost模型以评估特征重要性...\n",
      "特征筛选完成，选出最重要的100个特征。\n",
      "\n",
      "--- 4. 对所有数据进行一次性特征工程 ---\n",
      "处理最终训练集...\n",
      "处理验证集...\n",
      "处理测试集...\n",
      "\n",
      "--- 5. 开始使用贝叶斯优化进行超参数搜索 (数据量: 693510) ---\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.058763\n",
      "[CV] END model__colsample_bytree=0.7640415835413256, model__gamma=0.7277257431773251, model__learning_rate=0.04283886967006358, model__max_depth=5, model__min_child_weight=20, model__n_estimators=1121, model__reg_alpha=0.050334141977735516, model__reg_lambda=0.30130647758680273, model__subsample=0.7217853244146024; total time=  10.6s\n",
      "[RankICScorer] Fold Rank IC = 0.078366\n",
      "[CV] END model__colsample_bytree=0.7640415835413256, model__gamma=0.7277257431773251, model__learning_rate=0.04283886967006358, model__max_depth=5, model__min_child_weight=20, model__n_estimators=1121, model__reg_alpha=0.050334141977735516, model__reg_lambda=0.30130647758680273, model__subsample=0.7217853244146024; total time=  15.6s\n",
      "[RankICScorer] Fold Rank IC = 0.077393\n",
      "[CV] END model__colsample_bytree=0.7640415835413256, model__gamma=0.7277257431773251, model__learning_rate=0.04283886967006358, model__max_depth=5, model__min_child_weight=20, model__n_estimators=1121, model__reg_alpha=0.050334141977735516, model__reg_lambda=0.30130647758680273, model__subsample=0.7217853244146024; total time=  20.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.056591\n",
      "[CV] END model__colsample_bytree=0.9349553422213137, model__gamma=0.8833152773808622, model__learning_rate=0.010054954604718277, model__max_depth=8, model__min_child_weight=26, model__n_estimators=593, model__reg_alpha=0.018906758484967926, model__reg_lambda=0.05095359082904493, model__subsample=0.8542916407516681; total time=  10.5s\n",
      "[RankICScorer] Fold Rank IC = 0.085067\n",
      "[CV] END model__colsample_bytree=0.9349553422213137, model__gamma=0.8833152773808622, model__learning_rate=0.010054954604718277, model__max_depth=8, model__min_child_weight=26, model__n_estimators=593, model__reg_alpha=0.018906758484967926, model__reg_lambda=0.05095359082904493, model__subsample=0.8542916407516681; total time=  14.8s\n",
      "[RankICScorer] Fold Rank IC = 0.078325\n",
      "[CV] END model__colsample_bytree=0.9349553422213137, model__gamma=0.8833152773808622, model__learning_rate=0.010054954604718277, model__max_depth=8, model__min_child_weight=26, model__n_estimators=593, model__reg_alpha=0.018906758484967926, model__reg_lambda=0.05095359082904493, model__subsample=0.8542916407516681; total time=  20.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.058048\n",
      "[CV] END model__colsample_bytree=0.7779330049204607, model__gamma=0.9187225216693771, model__learning_rate=0.006365450758349532, model__max_depth=5, model__min_child_weight=6, model__n_estimators=1180, model__reg_alpha=0.020459551449165617, model__reg_lambda=0.31849679224816907, model__subsample=0.8229361692135205; total time=  13.6s\n",
      "[RankICScorer] Fold Rank IC = 0.081010\n",
      "[CV] END model__colsample_bytree=0.7779330049204607, model__gamma=0.9187225216693771, model__learning_rate=0.006365450758349532, model__max_depth=5, model__min_child_weight=6, model__n_estimators=1180, model__reg_alpha=0.020459551449165617, model__reg_lambda=0.31849679224816907, model__subsample=0.8229361692135205; total time=  20.3s\n",
      "[RankICScorer] Fold Rank IC = 0.075243\n",
      "[CV] END model__colsample_bytree=0.7779330049204607, model__gamma=0.9187225216693771, model__learning_rate=0.006365450758349532, model__max_depth=5, model__min_child_weight=6, model__n_estimators=1180, model__reg_alpha=0.020459551449165617, model__reg_lambda=0.31849679224816907, model__subsample=0.8229361692135205; total time=  23.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.060572\n",
      "[CV] END model__colsample_bytree=0.9249583953429453, model__gamma=0.1718715613965607, model__learning_rate=0.019816049655691, model__max_depth=7, model__min_child_weight=16, model__n_estimators=643, model__reg_alpha=0.32478881572932794, model__reg_lambda=0.5562380663209309, model__subsample=0.9647715446027535; total time=  10.3s\n",
      "[RankICScorer] Fold Rank IC = 0.074499\n",
      "[CV] END model__colsample_bytree=0.9249583953429453, model__gamma=0.1718715613965607, model__learning_rate=0.019816049655691, model__max_depth=7, model__min_child_weight=16, model__n_estimators=643, model__reg_alpha=0.32478881572932794, model__reg_lambda=0.5562380663209309, model__subsample=0.9647715446027535; total time=  15.3s\n",
      "[RankICScorer] Fold Rank IC = 0.090754\n",
      "[CV] END model__colsample_bytree=0.9249583953429453, model__gamma=0.1718715613965607, model__learning_rate=0.019816049655691, model__max_depth=7, model__min_child_weight=16, model__n_estimators=643, model__reg_alpha=0.32478881572932794, model__reg_lambda=0.5562380663209309, model__subsample=0.9647715446027535; total time=  20.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.058161\n",
      "[CV] END model__colsample_bytree=0.9198213766428692, model__gamma=0.43802918644092337, model__learning_rate=0.016810872002582168, model__max_depth=7, model__min_child_weight=27, model__n_estimators=1576, model__reg_alpha=0.07052711923416698, model__reg_lambda=0.199787449871348, model__subsample=0.7412335382111885; total time=  14.5s\n",
      "[RankICScorer] Fold Rank IC = 0.085057\n",
      "[CV] END model__colsample_bytree=0.9198213766428692, model__gamma=0.43802918644092337, model__learning_rate=0.016810872002582168, model__max_depth=7, model__min_child_weight=27, model__n_estimators=1576, model__reg_alpha=0.07052711923416698, model__reg_lambda=0.199787449871348, model__subsample=0.7412335382111885; total time=  19.3s\n",
      "[RankICScorer] Fold Rank IC = 0.088668\n",
      "[CV] END model__colsample_bytree=0.9198213766428692, model__gamma=0.43802918644092337, model__learning_rate=0.016810872002582168, model__max_depth=7, model__min_child_weight=27, model__n_estimators=1576, model__reg_alpha=0.07052711923416698, model__reg_lambda=0.199787449871348, model__subsample=0.7412335382111885; total time=  25.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.055132\n",
      "[CV] END model__colsample_bytree=0.8936112071942273, model__gamma=0.9393697376027718, model__learning_rate=0.007287476763095815, model__max_depth=4, model__min_child_weight=24, model__n_estimators=1059, model__reg_alpha=0.08280356368997302, model__reg_lambda=0.1173627616370271, model__subsample=0.9141135748569983; total time=  11.5s\n",
      "[RankICScorer] Fold Rank IC = 0.078328\n",
      "[CV] END model__colsample_bytree=0.8936112071942273, model__gamma=0.9393697376027718, model__learning_rate=0.007287476763095815, model__max_depth=4, model__min_child_weight=24, model__n_estimators=1059, model__reg_alpha=0.08280356368997302, model__reg_lambda=0.1173627616370271, model__subsample=0.9141135748569983; total time=  16.3s\n",
      "[RankICScorer] Fold Rank IC = 0.074805\n",
      "[CV] END model__colsample_bytree=0.8936112071942273, model__gamma=0.9393697376027718, model__learning_rate=0.007287476763095815, model__max_depth=4, model__min_child_weight=24, model__n_estimators=1059, model__reg_alpha=0.08280356368997302, model__reg_lambda=0.1173627616370271, model__subsample=0.9141135748569983; total time=  21.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.056872\n",
      "[CV] END model__colsample_bytree=0.8468317434009265, model__gamma=0.7753643788278826, model__learning_rate=0.01142859746175277, model__max_depth=7, model__min_child_weight=18, model__n_estimators=1392, model__reg_alpha=0.19840609953878058, model__reg_lambda=0.06984980079758242, model__subsample=0.8935529941075223; total time=  13.4s\n",
      "[RankICScorer] Fold Rank IC = 0.085176\n",
      "[CV] END model__colsample_bytree=0.8468317434009265, model__gamma=0.7753643788278826, model__learning_rate=0.01142859746175277, model__max_depth=7, model__min_child_weight=18, model__n_estimators=1392, model__reg_alpha=0.19840609953878058, model__reg_lambda=0.06984980079758242, model__subsample=0.8935529941075223; total time=  17.9s\n",
      "[RankICScorer] Fold Rank IC = 0.081622\n",
      "[CV] END model__colsample_bytree=0.8468317434009265, model__gamma=0.7753643788278826, model__learning_rate=0.01142859746175277, model__max_depth=7, model__min_child_weight=18, model__n_estimators=1392, model__reg_alpha=0.19840609953878058, model__reg_lambda=0.06984980079758242, model__subsample=0.8935529941075223; total time=  23.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.056862\n",
      "[CV] END model__colsample_bytree=0.817361227076125, model__gamma=0.9200092264373164, model__learning_rate=0.015683273202615675, model__max_depth=7, model__min_child_weight=10, model__n_estimators=577, model__reg_alpha=0.13853375477422647, model__reg_lambda=0.011261653741801549, model__subsample=0.7542918363938659; total time=   8.8s\n",
      "[RankICScorer] Fold Rank IC = 0.085713\n",
      "[CV] END model__colsample_bytree=0.817361227076125, model__gamma=0.9200092264373164, model__learning_rate=0.015683273202615675, model__max_depth=7, model__min_child_weight=10, model__n_estimators=577, model__reg_alpha=0.13853375477422647, model__reg_lambda=0.011261653741801549, model__subsample=0.7542918363938659; total time=  14.1s\n",
      "[RankICScorer] Fold Rank IC = 0.075450\n",
      "[CV] END model__colsample_bytree=0.817361227076125, model__gamma=0.9200092264373164, model__learning_rate=0.015683273202615675, model__max_depth=7, model__min_child_weight=10, model__n_estimators=577, model__reg_alpha=0.13853375477422647, model__reg_lambda=0.011261653741801549, model__subsample=0.7542918363938659; total time=  17.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.056194\n",
      "[CV] END model__colsample_bytree=0.9821911945239713, model__gamma=0.700621444621366, model__learning_rate=0.037206766845782564, model__max_depth=5, model__min_child_weight=12, model__n_estimators=817, model__reg_alpha=0.01000281188632158, model__reg_lambda=0.05512783985900912, model__subsample=0.8377515654365543; total time=   9.4s\n",
      "[RankICScorer] Fold Rank IC = 0.074909\n",
      "[CV] END model__colsample_bytree=0.9821911945239713, model__gamma=0.700621444621366, model__learning_rate=0.037206766845782564, model__max_depth=5, model__min_child_weight=12, model__n_estimators=817, model__reg_alpha=0.01000281188632158, model__reg_lambda=0.05512783985900912, model__subsample=0.8377515654365543; total time=  15.0s\n",
      "[RankICScorer] Fold Rank IC = 0.080207\n",
      "[CV] END model__colsample_bytree=0.9821911945239713, model__gamma=0.700621444621366, model__learning_rate=0.037206766845782564, model__max_depth=5, model__min_child_weight=12, model__n_estimators=817, model__reg_alpha=0.01000281188632158, model__reg_lambda=0.05512783985900912, model__subsample=0.8377515654365543; total time=  18.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.059132\n",
      "[CV] END model__colsample_bytree=0.6014521229018973, model__gamma=0.8178300196637516, model__learning_rate=0.027558320631972947, model__max_depth=4, model__min_child_weight=18, model__n_estimators=912, model__reg_alpha=0.04223559458393248, model__reg_lambda=0.02019245732342464, model__subsample=0.9575352244210078; total time=   8.9s\n",
      "[RankICScorer] Fold Rank IC = 0.077015\n",
      "[CV] END model__colsample_bytree=0.6014521229018973, model__gamma=0.8178300196637516, model__learning_rate=0.027558320631972947, model__max_depth=4, model__min_child_weight=18, model__n_estimators=912, model__reg_alpha=0.04223559458393248, model__reg_lambda=0.02019245732342464, model__subsample=0.9575352244210078; total time=  12.3s\n",
      "[RankICScorer] Fold Rank IC = 0.078768\n",
      "[CV] END model__colsample_bytree=0.6014521229018973, model__gamma=0.8178300196637516, model__learning_rate=0.027558320631972947, model__max_depth=4, model__min_child_weight=18, model__n_estimators=912, model__reg_alpha=0.04223559458393248, model__reg_lambda=0.02019245732342464, model__subsample=0.9575352244210078; total time=  16.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.074339\n",
      "[CV] END model__colsample_bytree=0.6264581104589747, model__gamma=0.05267587338389869, model__learning_rate=0.027257299022505465, model__max_depth=8, model__min_child_weight=2, model__n_estimators=1994, model__reg_alpha=0.16273909495032066, model__reg_lambda=0.023781303738996767, model__subsample=0.6077655995683064; total time=  16.9s\n",
      "[RankICScorer] Fold Rank IC = 0.077256\n",
      "[CV] END model__colsample_bytree=0.6264581104589747, model__gamma=0.05267587338389869, model__learning_rate=0.027257299022505465, model__max_depth=8, model__min_child_weight=2, model__n_estimators=1994, model__reg_alpha=0.16273909495032066, model__reg_lambda=0.023781303738996767, model__subsample=0.6077655995683064; total time=  28.4s\n",
      "[RankICScorer] Fold Rank IC = 0.087900\n",
      "[CV] END model__colsample_bytree=0.6264581104589747, model__gamma=0.05267587338389869, model__learning_rate=0.027257299022505465, model__max_depth=8, model__min_child_weight=2, model__n_estimators=1994, model__reg_alpha=0.16273909495032066, model__reg_lambda=0.023781303738996767, model__subsample=0.6077655995683064; total time=  37.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.071277\n",
      "[CV] END model__colsample_bytree=0.6259148797595746, model__gamma=0.02289280795768345, model__learning_rate=0.00625377424167693, model__max_depth=3, model__min_child_weight=23, model__n_estimators=1937, model__reg_alpha=0.07157252564716682, model__reg_lambda=0.06328572224819459, model__subsample=0.7048143682278493; total time=  20.1s\n",
      "[RankICScorer] Fold Rank IC = 0.082567\n",
      "[CV] END model__colsample_bytree=0.6259148797595746, model__gamma=0.02289280795768345, model__learning_rate=0.00625377424167693, model__max_depth=3, model__min_child_weight=23, model__n_estimators=1937, model__reg_alpha=0.07157252564716682, model__reg_lambda=0.06328572224819459, model__subsample=0.7048143682278493; total time=  23.1s\n",
      "[RankICScorer] Fold Rank IC = 0.087946\n",
      "[CV] END model__colsample_bytree=0.6259148797595746, model__gamma=0.02289280795768345, model__learning_rate=0.00625377424167693, model__max_depth=3, model__min_child_weight=23, model__n_estimators=1937, model__reg_alpha=0.07157252564716682, model__reg_lambda=0.06328572224819459, model__subsample=0.7048143682278493; total time=  28.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.054783\n",
      "[CV] END model__colsample_bytree=0.9857565180529345, model__gamma=0.8839553621921727, model__learning_rate=0.011782268351286108, model__max_depth=4, model__min_child_weight=23, model__n_estimators=1995, model__reg_alpha=0.03651977347645203, model__reg_lambda=0.17729418958551174, model__subsample=0.7055073624694539; total time=  14.0s\n",
      "[RankICScorer] Fold Rank IC = 0.079229\n",
      "[CV] END model__colsample_bytree=0.9857565180529345, model__gamma=0.8839553621921727, model__learning_rate=0.011782268351286108, model__max_depth=4, model__min_child_weight=23, model__n_estimators=1995, model__reg_alpha=0.03651977347645203, model__reg_lambda=0.17729418958551174, model__subsample=0.7055073624694539; total time=  18.7s\n",
      "[RankICScorer] Fold Rank IC = 0.073164\n",
      "[CV] END model__colsample_bytree=0.9857565180529345, model__gamma=0.8839553621921727, model__learning_rate=0.011782268351286108, model__max_depth=4, model__min_child_weight=23, model__n_estimators=1995, model__reg_alpha=0.03651977347645203, model__reg_lambda=0.17729418958551174, model__subsample=0.7055073624694539; total time=  24.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.061060\n",
      "[CV] END model__colsample_bytree=0.6110887571180424, model__gamma=0.3037404530482796, model__learning_rate=0.005222240102375501, model__max_depth=8, model__min_child_weight=17, model__n_estimators=858, model__reg_alpha=0.2203037051166955, model__reg_lambda=0.10772953895034848, model__subsample=0.8273954202517926; total time=  15.3s\n",
      "[RankICScorer] Fold Rank IC = 0.082070\n",
      "[CV] END model__colsample_bytree=0.6110887571180424, model__gamma=0.3037404530482796, model__learning_rate=0.005222240102375501, model__max_depth=8, model__min_child_weight=17, model__n_estimators=858, model__reg_alpha=0.2203037051166955, model__reg_lambda=0.10772953895034848, model__subsample=0.8273954202517926; total time=  20.1s\n",
      "[RankICScorer] Fold Rank IC = 0.088263\n",
      "[CV] END model__colsample_bytree=0.6110887571180424, model__gamma=0.3037404530482796, model__learning_rate=0.005222240102375501, model__max_depth=8, model__min_child_weight=17, model__n_estimators=858, model__reg_alpha=0.2203037051166955, model__reg_lambda=0.10772953895034848, model__subsample=0.8273954202517926; total time=  26.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.058378\n",
      "[CV] END model__colsample_bytree=0.661256729932868, model__gamma=0.02316356230200645, model__learning_rate=0.008871035025042233, model__max_depth=3, model__min_child_weight=4, model__n_estimators=521, model__reg_alpha=0.012234525788186573, model__reg_lambda=0.8345229968451172, model__subsample=0.9602096829685066; total time=   8.0s\n",
      "[RankICScorer] Fold Rank IC = 0.077709\n",
      "[CV] END model__colsample_bytree=0.661256729932868, model__gamma=0.02316356230200645, model__learning_rate=0.008871035025042233, model__max_depth=3, model__min_child_weight=4, model__n_estimators=521, model__reg_alpha=0.012234525788186573, model__reg_lambda=0.8345229968451172, model__subsample=0.9602096829685066; total time=  11.2s\n",
      "[RankICScorer] Fold Rank IC = 0.073804\n",
      "[CV] END model__colsample_bytree=0.661256729932868, model__gamma=0.02316356230200645, model__learning_rate=0.008871035025042233, model__max_depth=3, model__min_child_weight=4, model__n_estimators=521, model__reg_alpha=0.012234525788186573, model__reg_lambda=0.8345229968451172, model__subsample=0.9602096829685066; total time=  14.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.080396\n",
      "[CV] END model__colsample_bytree=0.9729253280476635, model__gamma=0.01796397397467742, model__learning_rate=0.04361796116335706, model__max_depth=4, model__min_child_weight=6, model__n_estimators=1965, model__reg_alpha=0.12321022034675617, model__reg_lambda=0.24435062763364138, model__subsample=0.7059254258627541; total time=  21.4s\n",
      "[RankICScorer] Fold Rank IC = 0.073067\n",
      "[CV] END model__colsample_bytree=0.9729253280476635, model__gamma=0.01796397397467742, model__learning_rate=0.04361796116335706, model__max_depth=4, model__min_child_weight=6, model__n_estimators=1965, model__reg_alpha=0.12321022034675617, model__reg_lambda=0.24435062763364138, model__subsample=0.7059254258627541; total time=  25.7s\n",
      "[RankICScorer] Fold Rank IC = 0.088493\n",
      "[CV] END model__colsample_bytree=0.9729253280476635, model__gamma=0.01796397397467742, model__learning_rate=0.04361796116335706, model__max_depth=4, model__min_child_weight=6, model__n_estimators=1965, model__reg_alpha=0.12321022034675617, model__reg_lambda=0.24435062763364138, model__subsample=0.7059254258627541; total time=  31.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.076263\n",
      "[CV] END model__colsample_bytree=0.9428833146242777, model__gamma=0.01675469030673127, model__learning_rate=0.0059706616153974166, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1846, model__reg_alpha=0.18778246862033132, model__reg_lambda=0.08657942097066035, model__subsample=0.9741935392039771; total time=  40.4s\n",
      "[RankICScorer] Fold Rank IC = 0.075275\n",
      "[CV] END model__colsample_bytree=0.9428833146242777, model__gamma=0.01675469030673127, model__learning_rate=0.0059706616153974166, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1846, model__reg_alpha=0.18778246862033132, model__reg_lambda=0.08657942097066035, model__subsample=0.9741935392039771; total time=  53.8s\n",
      "[RankICScorer] Fold Rank IC = 0.091459\n",
      "[CV] END model__colsample_bytree=0.9428833146242777, model__gamma=0.01675469030673127, model__learning_rate=0.0059706616153974166, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1846, model__reg_alpha=0.18778246862033132, model__reg_lambda=0.08657942097066035, model__subsample=0.9741935392039771; total time= 1.0min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.063447\n",
      "[CV] END model__colsample_bytree=0.6045226001261937, model__gamma=0.27450735718828806, model__learning_rate=0.030402128337864747, model__max_depth=6, model__min_child_weight=29, model__n_estimators=1975, model__reg_alpha=0.15715866585142355, model__reg_lambda=0.05732854719567205, model__subsample=0.9734159526784273; total time=  14.3s\n",
      "[RankICScorer] Fold Rank IC = 0.079651\n",
      "[CV] END model__colsample_bytree=0.6045226001261937, model__gamma=0.27450735718828806, model__learning_rate=0.030402128337864747, model__max_depth=6, model__min_child_weight=29, model__n_estimators=1975, model__reg_alpha=0.15715866585142355, model__reg_lambda=0.05732854719567205, model__subsample=0.9734159526784273; total time=  18.9s\n",
      "[RankICScorer] Fold Rank IC = 0.090603\n",
      "[CV] END model__colsample_bytree=0.6045226001261937, model__gamma=0.27450735718828806, model__learning_rate=0.030402128337864747, model__max_depth=6, model__min_child_weight=29, model__n_estimators=1975, model__reg_alpha=0.15715866585142355, model__reg_lambda=0.05732854719567205, model__subsample=0.9734159526784273; total time=  23.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.073257\n",
      "[CV] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.005, model__max_depth=6, model__min_child_weight=25, model__n_estimators=2000, model__reg_alpha=0.01, model__reg_lambda=0.01, model__subsample=0.7771217344512616; total time=  28.7s\n",
      "[RankICScorer] Fold Rank IC = 0.076481\n",
      "[CV] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.005, model__max_depth=6, model__min_child_weight=25, model__n_estimators=2000, model__reg_alpha=0.01, model__reg_lambda=0.01, model__subsample=0.7771217344512616; total time=  35.3s\n",
      "[RankICScorer] Fold Rank IC = 0.096123\n",
      "[CV] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.005, model__max_depth=6, model__min_child_weight=25, model__n_estimators=2000, model__reg_alpha=0.01, model__reg_lambda=0.01, model__subsample=0.7771217344512616; total time=  41.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.058248\n",
      "[CV] END model__colsample_bytree=0.6460177459835177, model__gamma=0.8646030950688413, model__learning_rate=0.029562302178353685, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1984, model__reg_alpha=0.14362451859426661, model__reg_lambda=0.08185290397770813, model__subsample=0.9152026314010056; total time=  13.9s\n",
      "[RankICScorer] Fold Rank IC = 0.082319\n",
      "[CV] END model__colsample_bytree=0.6460177459835177, model__gamma=0.8646030950688413, model__learning_rate=0.029562302178353685, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1984, model__reg_alpha=0.14362451859426661, model__reg_lambda=0.08185290397770813, model__subsample=0.9152026314010056; total time=  18.2s\n",
      "[RankICScorer] Fold Rank IC = 0.079838\n",
      "[CV] END model__colsample_bytree=0.6460177459835177, model__gamma=0.8646030950688413, model__learning_rate=0.029562302178353685, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1984, model__reg_alpha=0.14362451859426661, model__reg_lambda=0.08185290397770813, model__subsample=0.9152026314010056; total time=  23.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.082933\n",
      "[CV] END model__colsample_bytree=0.7096245519666522, model__gamma=0.003328515687838874, model__learning_rate=0.04034979439273203, model__max_depth=5, model__min_child_weight=12, model__n_estimators=1351, model__reg_alpha=0.09256205364523129, model__reg_lambda=0.020441210146172655, model__subsample=0.9199322390761817; total time=  19.7s\n",
      "[RankICScorer] Fold Rank IC = 0.072825\n",
      "[CV] END model__colsample_bytree=0.7096245519666522, model__gamma=0.003328515687838874, model__learning_rate=0.04034979439273203, model__max_depth=5, model__min_child_weight=12, model__n_estimators=1351, model__reg_alpha=0.09256205364523129, model__reg_lambda=0.020441210146172655, model__subsample=0.9199322390761817; total time=  22.5s\n",
      "[RankICScorer] Fold Rank IC = 0.089307\n",
      "[CV] END model__colsample_bytree=0.7096245519666522, model__gamma=0.003328515687838874, model__learning_rate=0.04034979439273203, model__max_depth=5, model__min_child_weight=12, model__n_estimators=1351, model__reg_alpha=0.09256205364523129, model__reg_lambda=0.020441210146172655, model__subsample=0.9199322390761817; total time=  27.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.070302\n",
      "[CV] END model__colsample_bytree=0.9644719733608969, model__gamma=0.04890520465547345, model__learning_rate=0.01623156784228985, model__max_depth=8, model__min_child_weight=6, model__n_estimators=514, model__reg_alpha=0.4909856623810381, model__reg_lambda=0.013291512888078304, model__subsample=0.7348089827317357; total time=  12.2s\n",
      "[RankICScorer] Fold Rank IC = 0.077069\n",
      "[CV] END model__colsample_bytree=0.9644719733608969, model__gamma=0.04890520465547345, model__learning_rate=0.01623156784228985, model__max_depth=8, model__min_child_weight=6, model__n_estimators=514, model__reg_alpha=0.4909856623810381, model__reg_lambda=0.013291512888078304, model__subsample=0.7348089827317357; total time=  19.8s\n",
      "[RankICScorer] Fold Rank IC = 0.095222\n",
      "[CV] END model__colsample_bytree=0.9644719733608969, model__gamma=0.04890520465547345, model__learning_rate=0.01623156784228985, model__max_depth=8, model__min_child_weight=6, model__n_estimators=514, model__reg_alpha=0.4909856623810381, model__reg_lambda=0.013291512888078304, model__subsample=0.7348089827317357; total time=  24.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.071120\n",
      "[CV] END model__colsample_bytree=0.9753968815099563, model__gamma=0.05282181346596061, model__learning_rate=0.03409275753377418, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1119, model__reg_alpha=0.2795028754977072, model__reg_lambda=0.010743764274834517, model__subsample=0.704265153118204; total time=  11.9s\n",
      "[RankICScorer] Fold Rank IC = 0.075422\n",
      "[CV] END model__colsample_bytree=0.9753968815099563, model__gamma=0.05282181346596061, model__learning_rate=0.03409275753377418, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1119, model__reg_alpha=0.2795028754977072, model__reg_lambda=0.010743764274834517, model__subsample=0.704265153118204; total time=  20.6s\n",
      "[RankICScorer] Fold Rank IC = 0.085885\n",
      "[CV] END model__colsample_bytree=0.9753968815099563, model__gamma=0.05282181346596061, model__learning_rate=0.03409275753377418, model__max_depth=8, model__min_child_weight=16, model__n_estimators=1119, model__reg_alpha=0.2795028754977072, model__reg_lambda=0.010743764274834517, model__subsample=0.704265153118204; total time=  27.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.070981\n",
      "[CV] END model__colsample_bytree=0.9839704022974495, model__gamma=0.00429887691795905, model__learning_rate=0.006050086819919906, model__max_depth=3, model__min_child_weight=19, model__n_estimators=1425, model__reg_alpha=0.483821012315162, model__reg_lambda=0.013006298940982059, model__subsample=0.6812304436576703; total time=  15.0s\n",
      "[RankICScorer] Fold Rank IC = 0.078368\n",
      "[CV] END model__colsample_bytree=0.9839704022974495, model__gamma=0.00429887691795905, model__learning_rate=0.006050086819919906, model__max_depth=3, model__min_child_weight=19, model__n_estimators=1425, model__reg_alpha=0.483821012315162, model__reg_lambda=0.013006298940982059, model__subsample=0.6812304436576703; total time=  18.6s\n",
      "[RankICScorer] Fold Rank IC = 0.082650\n",
      "[CV] END model__colsample_bytree=0.9839704022974495, model__gamma=0.00429887691795905, model__learning_rate=0.006050086819919906, model__max_depth=3, model__min_child_weight=19, model__n_estimators=1425, model__reg_alpha=0.483821012315162, model__reg_lambda=0.013006298940982059, model__subsample=0.6812304436576703; total time=  23.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.080144\n",
      "[CV] END model__colsample_bytree=0.6720336567407248, model__gamma=0.006062745158960105, model__learning_rate=0.012674698500674758, model__max_depth=6, model__min_child_weight=24, model__n_estimators=1758, model__reg_alpha=0.011478532026925798, model__reg_lambda=0.9185991332581288, model__subsample=0.7868292776103716; total time=  28.2s\n",
      "[RankICScorer] Fold Rank IC = 0.075526\n",
      "[CV] END model__colsample_bytree=0.6720336567407248, model__gamma=0.006062745158960105, model__learning_rate=0.012674698500674758, model__max_depth=6, model__min_child_weight=24, model__n_estimators=1758, model__reg_alpha=0.011478532026925798, model__reg_lambda=0.9185991332581288, model__subsample=0.7868292776103716; total time=  31.9s\n",
      "[RankICScorer] Fold Rank IC = 0.094541\n",
      "[CV] END model__colsample_bytree=0.6720336567407248, model__gamma=0.006062745158960105, model__learning_rate=0.012674698500674758, model__max_depth=6, model__min_child_weight=24, model__n_estimators=1758, model__reg_alpha=0.011478532026925798, model__reg_lambda=0.9185991332581288, model__subsample=0.7868292776103716; total time=  37.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.087010\n",
      "[CV] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.029655135422861693, model__max_depth=6, model__min_child_weight=7, model__n_estimators=1623, model__reg_alpha=0.01, model__reg_lambda=0.01, model__subsample=0.869648267747283; total time=  26.5s\n",
      "[RankICScorer] Fold Rank IC = 0.073573\n",
      "[CV] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.029655135422861693, model__max_depth=6, model__min_child_weight=7, model__n_estimators=1623, model__reg_alpha=0.01, model__reg_lambda=0.01, model__subsample=0.869648267747283; total time=  29.7s\n",
      "[RankICScorer] Fold Rank IC = 0.085989\n",
      "[CV] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.029655135422861693, model__max_depth=6, model__min_child_weight=7, model__n_estimators=1623, model__reg_alpha=0.01, model__reg_lambda=0.01, model__subsample=0.869648267747283; total time=  35.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.063803\n",
      "[CV] END model__colsample_bytree=0.679541685925667, model__gamma=0.023086618670585927, model__learning_rate=0.007746641168297307, model__max_depth=6, model__min_child_weight=19, model__n_estimators=502, model__reg_alpha=0.02176296994665814, model__reg_lambda=0.015716962706233035, model__subsample=0.79922237535626; total time=  10.6s\n",
      "[RankICScorer] Fold Rank IC = 0.079081\n",
      "[CV] END model__colsample_bytree=0.679541685925667, model__gamma=0.023086618670585927, model__learning_rate=0.007746641168297307, model__max_depth=6, model__min_child_weight=19, model__n_estimators=502, model__reg_alpha=0.02176296994665814, model__reg_lambda=0.015716962706233035, model__subsample=0.79922237535626; total time=  14.4s\n",
      "[RankICScorer] Fold Rank IC = 0.089293\n",
      "[CV] END model__colsample_bytree=0.679541685925667, model__gamma=0.023086618670585927, model__learning_rate=0.007746641168297307, model__max_depth=6, model__min_child_weight=19, model__n_estimators=502, model__reg_alpha=0.02176296994665814, model__reg_lambda=0.015716962706233035, model__subsample=0.79922237535626; total time=  18.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.053854\n",
      "[CV] END model__colsample_bytree=0.740366999538833, model__gamma=0.9248117453266742, model__learning_rate=0.02320330453873486, model__max_depth=3, model__min_child_weight=8, model__n_estimators=521, model__reg_alpha=0.011038821925918214, model__reg_lambda=0.7894651331860367, model__subsample=0.9595845263642957; total time=   6.6s\n",
      "[RankICScorer] Fold Rank IC = 0.082338\n",
      "[CV] END model__colsample_bytree=0.740366999538833, model__gamma=0.9248117453266742, model__learning_rate=0.02320330453873486, model__max_depth=3, model__min_child_weight=8, model__n_estimators=521, model__reg_alpha=0.011038821925918214, model__reg_lambda=0.7894651331860367, model__subsample=0.9595845263642957; total time=   9.9s\n",
      "[RankICScorer] Fold Rank IC = 0.068911\n",
      "[CV] END model__colsample_bytree=0.740366999538833, model__gamma=0.9248117453266742, model__learning_rate=0.02320330453873486, model__max_depth=3, model__min_child_weight=8, model__n_estimators=521, model__reg_alpha=0.011038821925918214, model__reg_lambda=0.7894651331860367, model__subsample=0.9595845263642957; total time=  13.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.078230\n",
      "[CV] END model__colsample_bytree=0.6981703222999521, model__gamma=0.023770544767631636, model__learning_rate=0.04961905815330159, model__max_depth=8, model__min_child_weight=28, model__n_estimators=1299, model__reg_alpha=0.07032731266703279, model__reg_lambda=0.7066974659431737, model__subsample=0.792387255340063; total time=  14.2s\n",
      "[RankICScorer] Fold Rank IC = 0.078710\n",
      "[CV] END model__colsample_bytree=0.6981703222999521, model__gamma=0.023770544767631636, model__learning_rate=0.04961905815330159, model__max_depth=8, model__min_child_weight=28, model__n_estimators=1299, model__reg_alpha=0.07032731266703279, model__reg_lambda=0.7066974659431737, model__subsample=0.792387255340063; total time=  25.5s\n",
      "[RankICScorer] Fold Rank IC = 0.075827\n",
      "[CV] END model__colsample_bytree=0.6981703222999521, model__gamma=0.023770544767631636, model__learning_rate=0.04961905815330159, model__max_depth=8, model__min_child_weight=28, model__n_estimators=1299, model__reg_alpha=0.07032731266703279, model__reg_lambda=0.7066974659431737, model__subsample=0.792387255340063; total time=  33.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.072510\n",
      "[CV] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.005, model__max_depth=5, model__min_child_weight=5, model__n_estimators=1665, model__reg_alpha=0.24227178363024862, model__reg_lambda=1.0, model__subsample=0.6383745543173741; total time=  24.0s\n",
      "[RankICScorer] Fold Rank IC = 0.081290\n",
      "[CV] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.005, model__max_depth=5, model__min_child_weight=5, model__n_estimators=1665, model__reg_alpha=0.24227178363024862, model__reg_lambda=1.0, model__subsample=0.6383745543173741; total time=  26.6s\n",
      "[RankICScorer] Fold Rank IC = 0.094067\n",
      "[CV] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.005, model__max_depth=5, model__min_child_weight=5, model__n_estimators=1665, model__reg_alpha=0.24227178363024862, model__reg_lambda=1.0, model__subsample=0.6383745543173741; total time=  32.4s\n",
      "\n",
      "--- 超参数搜索完成 ---\n",
      "最佳参数: OrderedDict({'model__colsample_bytree': 0.6720336567407248, 'model__gamma': 0.006062745158960105, 'model__learning_rate': 0.012674698500674758, 'model__max_depth': 6, 'model__min_child_weight': 24, 'model__n_estimators': 1758, 'model__reg_alpha': 0.011478532026925798, 'model__reg_lambda': 0.9185991332581288, 'model__subsample': 0.7868292776103716})\n",
      "最佳交叉验证得分 (Rank IC): 0.083404\n",
      "\n",
      "--- 6. 在所有历史数据上训练最终模型 ---\n",
      "最终模型训练完成。\n",
      "\n",
      "--- 7. 在独立验证集上评估最终模型 ---\n",
      "\n",
      "独立验证集上的最终Rank IC: 0.078718\n",
      "\n",
      "--- 8. 生成最终提交文件 ---\n",
      "提交文件 'submission_pipeline_v12.1.csv' 已生成.\n",
      "   id    code  date    y_pred\n",
      "0   0     s_0  1691  0.013891\n",
      "1   1     s_1  1691 -0.015278\n",
      "2   2    s_10  1691  0.006372\n",
      "3   3   s_100  1691  0.018326\n",
      "4   4  s_1001  1691  0.015723\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T18:51:23.225422Z",
     "start_time": "2025-07-29T14:14:43.965862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 9.5 === 模型训练管道 v13.1 (三驾马车集成版) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import os\n",
    "import gc\n",
    "import polars as pl\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn & Scikit-optimize Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. 评估指标与评分函数 ---\n",
    "\n",
    "def calculate_rank_ic_polars(y_true, y_pred, dates):\n",
    "    \"\"\"使用Polars高效计算Rank IC\"\"\"\n",
    "    if isinstance(y_true, pd.Series): y_true = y_true.to_numpy()\n",
    "    if isinstance(y_pred, pd.Series): y_pred = y_pred.to_numpy()\n",
    "    if isinstance(dates, pd.Series): dates = dates.to_numpy()\n",
    "\n",
    "    df = pl.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'date': dates})\n",
    "    daily_ic = df.group_by('date', maintain_order=True).agg(\n",
    "        pl.corr('y_true', 'y_pred', method='spearman').fill_nan(0.0).alias('ic')\n",
    "    )\n",
    "    return daily_ic['ic'].mean()\n",
    "\n",
    "class RankICScorer:\n",
    "    \"\"\"(v1.2) 一个与scikit-learn兼容的自定义评分器\"\"\"\n",
    "    def __init__(self, dates: pd.Series):\n",
    "        self.dates = dates\n",
    "\n",
    "    def __call__(self, estimator, X, y_true) -> float:\n",
    "        y_pred = estimator.predict(X)\n",
    "        fold_dates = self.dates.loc[y_true.index]\n",
    "        rank_ic = calculate_rank_ic_polars(y_true, y_pred, fold_dates)\n",
    "        print(f\"[RankICScorer] Fold Rank IC = {rank_ic:.6f}\")\n",
    "        return rank_ic if np.isfinite(rank_ic) else 0.0\n",
    "\n",
    "# --- 2. 核心特征工程: 截面排名 ---\n",
    "def preprocess_and_rank(df):\n",
    "    \"\"\"初始预处理，只使用最核心的截面排名特征\"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ['code', 'date']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    float_cols = [c for c in df.columns if df[c].dtype == 'float64']\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    pl_df = pl.from_pandas(df)\n",
    "    feature_cols = [col for col in df.columns if col.startswith('f_')]\n",
    "    pl_df = pl_df.with_columns([\n",
    "        ((pl.col(feature).rank(method='ordinal').over('date') - 1) / (pl.col(feature).count().over('date') - 1)).alias(feature)\n",
    "        for feature in feature_cols\n",
    "    ])\n",
    "    final_df = pl_df.to_pandas()\n",
    "    final_df.fillna(0.5, inplace=True)\n",
    "    return final_df\n",
    "\n",
    "# --- 3. 主执行流程 ---\n",
    "def main():\n",
    "    print(\"--- 正在加载数据 ---\")\n",
    "    DATA_PATH = './stocks-return-prediction'\n",
    "    train_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'train_data9.pkl'))\n",
    "    test_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'test_data9.pkl'))\n",
    "\n",
    "    print(\"\\n--- 1. 核心特征工程 ---\")\n",
    "    train_df = preprocess_and_rank(train_df_raw.copy())\n",
    "    test_df = preprocess_and_rank(test_df_raw.copy())\n",
    "    train_df.sort_values(by=['date', 'code'], inplace=True, ignore_index=True)\n",
    "    test_df.sort_values(by=['date', 'code'], inplace=True, ignore_index=True)\n",
    "\n",
    "    del train_df_raw\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"\\n--- 2. 使用稳健时间窗口划分数据 ---\")\n",
    "    unique_dates = sorted(train_df['date'].unique())\n",
    "    val_start_date = unique_dates[-200]\n",
    "    # 最终训练和搜索都用近500天数据，以提供更多信息\n",
    "    search_start_date = unique_dates[-500]\n",
    "\n",
    "    val_df = train_df[train_df['date'] >= val_start_date]\n",
    "    search_df = train_df[train_df['date'] >= search_start_date]\n",
    "\n",
    "    print(f\"超参数搜索与最终训练集: {search_df['date'].min()} - {search_df['date'].max()} ({search_df['date'].nunique()} 天)\")\n",
    "    print(f\"最终验证集: {val_df['date'].min()} - {val_df['date'].max()} ({val_df['date'].nunique()} 天)\")\n",
    "\n",
    "    features = [f'f_{i}' for i in range(28)]\n",
    "\n",
    "    # --- 3. 独立调优三大模型 ---\n",
    "    models_to_tune = ['lgbm', 'xgb', 'catboost']\n",
    "    best_params_all = {}\n",
    "\n",
    "    for model_name in models_to_tune:\n",
    "        print(f\"\\n--- 3.{models_to_tune.index(model_name)+1} 开始为 {model_name.upper()} 进行贝叶斯优化 ---\")\n",
    "\n",
    "        if model_name == 'lgbm':\n",
    "            model = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)\n",
    "            search_spaces = {\n",
    "                'n_estimators': (500, 2000), 'learning_rate': (0.005, 0.05, 'log-uniform'),\n",
    "                'num_leaves': (20, 100), 'max_depth': (5, 15),\n",
    "                'feature_fraction': (0.6, 1.0, 'uniform'), 'bagging_fraction': (0.6, 1.0, 'uniform'),\n",
    "            }\n",
    "        elif model_name == 'xgb':\n",
    "            model = xgb.XGBRegressor(random_state=42, tree_method='gpu_hist', n_jobs=1)\n",
    "            search_spaces = {\n",
    "                'n_estimators': (500, 2000), 'learning_rate': (0.005, 0.05, 'log-uniform'),\n",
    "                'max_depth': (3, 8), 'subsample': (0.6, 1.0, 'uniform'),\n",
    "                'colsample_bytree': (0.6, 1.0, 'uniform'), 'min_child_weight': (1, 30),\n",
    "            }\n",
    "        elif model_name == 'catboost':\n",
    "            model = cb.CatBoostRegressor(random_state=42, verbose=0, thread_count=-1, allow_writing_files=False)\n",
    "            search_spaces = {\n",
    "                'iterations': (500, 2000), 'learning_rate': (0.005, 0.05, 'log-uniform'),\n",
    "                'depth': (4, 10), 'l2_leaf_reg': (1, 10, 'uniform'),\n",
    "            }\n",
    "\n",
    "        pipeline = Pipeline([('scaler', MinMaxScaler()), ('model', model)])\n",
    "\n",
    "        prefixed_search_spaces = {f'model__{k}': v for k, v in search_spaces.items()}\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=3)\n",
    "        rank_ic_scorer = RankICScorer(dates=search_df['date'])\n",
    "\n",
    "        search = BayesSearchCV(\n",
    "            estimator=pipeline, search_spaces=prefixed_search_spaces,\n",
    "            n_iter=15, scoring=rank_ic_scorer, cv=tscv,\n",
    "            random_state=42, n_jobs=1, verbose=2\n",
    "        )\n",
    "\n",
    "        search.fit(search_df[features], search_df['y'])\n",
    "        best_params_all[model_name] = {k.replace('model__', ''): v for k, v in search.best_params_.items()}\n",
    "        print(f\"--- {model_name.upper()} 调优完成 ---\")\n",
    "        print(f\"最佳交叉验证得分 (Rank IC): {search.best_score_:.6f}\")\n",
    "        print(f\"最佳参数: {best_params_all[model_name]}\")\n",
    "\n",
    "    # --- 4. 训练最终模型并进行集成预测 ---\n",
    "    print(\"\\n--- 4. 使用最优参数在最终训练集上训练三驾马车模型 ---\")\n",
    "\n",
    "    X_train_final = search_df[features]\n",
    "    y_train_final = search_df['y']\n",
    "    X_val_final = val_df[features]\n",
    "    y_val_final = val_df['y']\n",
    "    X_test_final = test_df[features]\n",
    "\n",
    "    predictions = []\n",
    "    for model_name in models_to_tune:\n",
    "        print(f\"正在训练最终的 {model_name.upper()} 模型...\")\n",
    "        params = best_params_all[model_name]\n",
    "\n",
    "        if model_name == 'lgbm':\n",
    "            model = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1, **params)\n",
    "        elif model_name == 'xgb':\n",
    "            model = xgb.XGBRegressor(random_state=42, tree_method='gpu_hist', n_jobs=-1, **params)\n",
    "        elif model_name == 'catboost':\n",
    "            model = cb.CatBoostRegressor(random_state=42, verbose=0, thread_count=-1, allow_writing_files=False, **params)\n",
    "\n",
    "        pipeline = Pipeline([('scaler', MinMaxScaler()), ('model', model)])\n",
    "        pipeline.fit(X_train_final, y_train_final)\n",
    "        predictions.append(pipeline.predict(X_test_final))\n",
    "        print(f\"{model_name.upper()} 预测完成。\")\n",
    "\n",
    "    # --- 5. 在验证集上评估并生成提交文件 ---\n",
    "    print(\"\\n--- 5. 在独立验证集上评估最终集成模型 ---\")\n",
    "    val_predictions = []\n",
    "    # 重新在训练集上训练，并在验证集上预测，以进行公正的评估\n",
    "    for model_name in models_to_tune:\n",
    "        params = best_params_all[model_name]\n",
    "        if model_name == 'lgbm': model = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1, **params)\n",
    "        elif model_name == 'xgb': model = xgb.XGBRegressor(random_state=42, tree_method='gpu_hist', n_jobs=-1, **params)\n",
    "        elif model_name == 'catboost': model = cb.CatBoostRegressor(random_state=42, verbose=0, thread_count=-1, allow_writing_files=False, **params)\n",
    "        pipeline = Pipeline([('scaler', MinMaxScaler()), ('model', model)])\n",
    "        pipeline.fit(X_train_final, y_train_final)\n",
    "        val_predictions.append(pipeline.predict(X_val_final))\n",
    "\n",
    "    ensemble_val_pred = np.mean(val_predictions, axis=0)\n",
    "    final_rank_ic = calculate_rank_ic_polars(y_val_final, ensemble_val_pred, val_df['date'])\n",
    "    print(f\"\\n独立验证集上的最终Rank IC: {final_rank_ic:.6f}\")\n",
    "\n",
    "    print(\"\\n--- 6. 生成最终提交文件 ---\")\n",
    "    ensemble_prediction = np.mean(predictions, axis=0)\n",
    "\n",
    "    submission_df = test_df[['code', 'date']].copy()\n",
    "    submission_df['y_pred'] = ensemble_prediction\n",
    "    submission_df.reset_index(inplace=True)\n",
    "    submission_df.rename(columns={'index': 'id'}, inplace=True)\n",
    "\n",
    "    submission_df = submission_df[['id', 'code', 'date', 'y_pred']]\n",
    "    submission_df.to_csv('submission_pipeline_v13.1.csv', index=False)\n",
    "    print(\"提交文件 'submission_pipeline_v13.1.csv' 已生成.\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "5bb5770e3d8a73ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在加载数据 ---\n",
      "\n",
      "--- 1. 核心特征工程 ---\n",
      "\n",
      "--- 2. 使用稳健时间窗口划分数据 ---\n",
      "超参数搜索与最终训练集: 1191 - 1690 (500 天)\n",
      "最终验证集: 1491 - 1690 (200 天)\n",
      "\n",
      "--- 3.1 开始为 LGBM 进行贝叶斯优化 ---\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.030189\n",
      "[CV] END model__bagging_fraction=0.7640415835413256, model__feature_fraction=0.89109029727093, model__learning_rate=0.04283886967006358, model__max_depth=8, model__n_estimators=1505, model__num_leaves=53; total time=  25.1s\n",
      "[RankICScorer] Fold Rank IC = 0.106550\n",
      "[CV] END model__bagging_fraction=0.7640415835413256, model__feature_fraction=0.89109029727093, model__learning_rate=0.04283886967006358, model__max_depth=8, model__n_estimators=1505, model__num_leaves=53; total time=  32.2s\n",
      "[RankICScorer] Fold Rank IC = 0.074066\n",
      "[CV] END model__bagging_fraction=0.7640415835413256, model__feature_fraction=0.89109029727093, model__learning_rate=0.04283886967006358, model__max_depth=8, model__n_estimators=1505, model__num_leaves=53; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.027203\n",
      "[CV] END model__bagging_fraction=0.9349553422213137, model__feature_fraction=0.9533261109523449, model__learning_rate=0.010054954604718277, model__max_depth=15, model__n_estimators=1796, model__num_leaves=25; total time=  27.4s\n",
      "[RankICScorer] Fold Rank IC = 0.127593\n",
      "[CV] END model__bagging_fraction=0.9349553422213137, model__feature_fraction=0.9533261109523449, model__learning_rate=0.010054954604718277, model__max_depth=15, model__n_estimators=1796, model__num_leaves=25; total time=  38.3s\n",
      "[RankICScorer] Fold Rank IC = 0.081420\n",
      "[CV] END model__bagging_fraction=0.9349553422213137, model__feature_fraction=0.9533261109523449, model__learning_rate=0.010054954604718277, model__max_depth=15, model__n_estimators=1796, model__num_leaves=25; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.027292\n",
      "[CV] END model__bagging_fraction=0.7779330049204607, model__feature_fraction=0.9674890086677508, model__learning_rate=0.006365450758349532, model__max_depth=9, model__n_estimators=782, model__num_leaves=56; total time=  16.4s\n",
      "[RankICScorer] Fold Rank IC = 0.128858\n",
      "[CV] END model__bagging_fraction=0.7779330049204607, model__feature_fraction=0.9674890086677508, model__learning_rate=0.006365450758349532, model__max_depth=9, model__n_estimators=782, model__num_leaves=56; total time=  26.6s\n",
      "[RankICScorer] Fold Rank IC = 0.080164\n",
      "[CV] END model__bagging_fraction=0.7779330049204607, model__feature_fraction=0.9674890086677508, model__learning_rate=0.006365450758349532, model__max_depth=9, model__n_estimators=782, model__num_leaves=56; total time= 1.1min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.029614\n",
      "[CV] END model__bagging_fraction=0.9249583953429453, model__feature_fraction=0.6687486245586243, model__learning_rate=0.019816049655691, model__max_depth=13, model__n_estimators=1285, model__num_leaves=28; total time=  20.0s\n",
      "[RankICScorer] Fold Rank IC = 0.126556\n",
      "[CV] END model__bagging_fraction=0.9249583953429453, model__feature_fraction=0.6687486245586243, model__learning_rate=0.019816049655691, model__max_depth=13, model__n_estimators=1285, model__num_leaves=28; total time=  26.0s\n",
      "[RankICScorer] Fold Rank IC = 0.079027\n",
      "[CV] END model__bagging_fraction=0.9249583953429453, model__feature_fraction=0.6687486245586243, model__learning_rate=0.019816049655691, model__max_depth=13, model__n_estimators=1285, model__num_leaves=28; total time=  36.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.030852\n",
      "[CV] END model__bagging_fraction=0.9198213766428692, model__feature_fraction=0.7752116745763693, model__learning_rate=0.016810872002582168, model__max_depth=12, model__n_estimators=1856, model__num_leaves=77; total time=  33.7s\n",
      "[RankICScorer] Fold Rank IC = 0.117032\n",
      "[CV] END model__bagging_fraction=0.9198213766428692, model__feature_fraction=0.7752116745763693, model__learning_rate=0.016810872002582168, model__max_depth=12, model__n_estimators=1856, model__num_leaves=77; total time=  43.4s\n",
      "[RankICScorer] Fold Rank IC = 0.079709\n",
      "[CV] END model__bagging_fraction=0.9198213766428692, model__feature_fraction=0.7752116745763693, model__learning_rate=0.016810872002582168, model__max_depth=12, model__n_estimators=1856, model__num_leaves=77; total time= 1.0min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.029459\n",
      "[CV] END model__bagging_fraction=0.8936112071942273, model__feature_fraction=0.9757478950411087, model__learning_rate=0.007287476763095815, model__max_depth=7, model__n_estimators=1701, model__num_leaves=50; total time=  30.5s\n",
      "[RankICScorer] Fold Rank IC = 0.125453\n",
      "[CV] END model__bagging_fraction=0.8936112071942273, model__feature_fraction=0.9757478950411087, model__learning_rate=0.007287476763095815, model__max_depth=7, model__n_estimators=1701, model__num_leaves=50; total time=  46.6s\n",
      "[RankICScorer] Fold Rank IC = 0.078623\n",
      "[CV] END model__bagging_fraction=0.8936112071942273, model__feature_fraction=0.9757478950411087, model__learning_rate=0.007287476763095815, model__max_depth=7, model__n_estimators=1701, model__num_leaves=50; total time= 1.8min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.028343\n",
      "[CV] END model__bagging_fraction=0.8468317434009265, model__feature_fraction=0.9101457515311531, model__learning_rate=0.01142859746175277, model__max_depth=14, model__n_estimators=1389, model__num_leaves=68; total time=  26.7s\n",
      "[RankICScorer] Fold Rank IC = 0.121905\n",
      "[CV] END model__bagging_fraction=0.8468317434009265, model__feature_fraction=0.9101457515311531, model__learning_rate=0.01142859746175277, model__max_depth=14, model__n_estimators=1389, model__num_leaves=68; total time=  35.8s\n",
      "[RankICScorer] Fold Rank IC = 0.081513\n",
      "[CV] END model__bagging_fraction=0.8468317434009265, model__feature_fraction=0.9101457515311531, model__learning_rate=0.01142859746175277, model__max_depth=14, model__n_estimators=1389, model__num_leaves=68; total time= 1.5min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.027483\n",
      "[CV] END model__bagging_fraction=0.817361227076125, model__feature_fraction=0.9680036905749265, model__learning_rate=0.015683273202615675, model__max_depth=13, model__n_estimators=986, model__num_leaves=24; total time=  15.8s\n",
      "[RankICScorer] Fold Rank IC = 0.128448\n",
      "[CV] END model__bagging_fraction=0.817361227076125, model__feature_fraction=0.9680036905749265, model__learning_rate=0.015683273202615675, model__max_depth=13, model__n_estimators=986, model__num_leaves=24; total time=  21.3s\n",
      "[RankICScorer] Fold Rank IC = 0.082492\n",
      "[CV] END model__bagging_fraction=0.817361227076125, model__feature_fraction=0.9680036905749265, model__learning_rate=0.015683273202615675, model__max_depth=13, model__n_estimators=986, model__num_leaves=24; total time=  43.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.029705\n",
      "[CV] END model__bagging_fraction=0.9821911945239713, model__feature_fraction=0.8802485778485464, model__learning_rate=0.037206766845782564, model__max_depth=9, model__n_estimators=1072, model__num_leaves=37; total time=  16.1s\n",
      "[RankICScorer] Fold Rank IC = 0.117353\n",
      "[CV] END model__bagging_fraction=0.9821911945239713, model__feature_fraction=0.8802485778485464, model__learning_rate=0.037206766845782564, model__max_depth=9, model__n_estimators=1072, model__num_leaves=37; total time=  22.2s\n",
      "[RankICScorer] Fold Rank IC = 0.078377\n",
      "[CV] END model__bagging_fraction=0.9821911945239713, model__feature_fraction=0.8802485778485464, model__learning_rate=0.037206766845782564, model__max_depth=9, model__n_estimators=1072, model__num_leaves=37; total time=  31.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.030280\n",
      "[CV] END model__bagging_fraction=0.6014521229018973, model__feature_fraction=0.9271320078655007, model__learning_rate=0.027558320631972947, model__max_depth=8, model__n_estimators=1368, model__num_leaves=42; total time=  17.5s\n",
      "[RankICScorer] Fold Rank IC = 0.117877\n",
      "[CV] END model__bagging_fraction=0.6014521229018973, model__feature_fraction=0.9271320078655007, model__learning_rate=0.027558320631972947, model__max_depth=8, model__n_estimators=1368, model__num_leaves=42; total time=  28.5s\n",
      "[RankICScorer] Fold Rank IC = 0.075574\n",
      "[CV] END model__bagging_fraction=0.6014521229018973, model__feature_fraction=0.9271320078655007, model__learning_rate=0.027558320631972947, model__max_depth=8, model__n_estimators=1368, model__num_leaves=42; total time= 1.1min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.025707\n",
      "[CV] END model__bagging_fraction=0.8555686190062417, model__feature_fraction=0.8652822800805393, model__learning_rate=0.005, model__max_depth=10, model__n_estimators=500, model__num_leaves=100; total time=  11.9s\n",
      "[RankICScorer] Fold Rank IC = 0.128423\n",
      "[CV] END model__bagging_fraction=0.8555686190062417, model__feature_fraction=0.8652822800805393, model__learning_rate=0.005, model__max_depth=10, model__n_estimators=500, model__num_leaves=100; total time=  19.6s\n",
      "[RankICScorer] Fold Rank IC = 0.079207\n",
      "[CV] END model__bagging_fraction=0.8555686190062417, model__feature_fraction=0.8652822800805393, model__learning_rate=0.005, model__max_depth=10, model__n_estimators=500, model__num_leaves=100; total time=  59.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.031220\n",
      "[CV] END model__bagging_fraction=0.7613583429151329, model__feature_fraction=0.9533035177275063, model__learning_rate=0.005, model__max_depth=8, model__n_estimators=2000, model__num_leaves=77; total time=  35.4s\n",
      "[RankICScorer] Fold Rank IC = 0.124159\n",
      "[CV] END model__bagging_fraction=0.7613583429151329, model__feature_fraction=0.9533035177275063, model__learning_rate=0.005, model__max_depth=8, model__n_estimators=2000, model__num_leaves=77; total time=  57.3s\n",
      "[RankICScorer] Fold Rank IC = 0.080355\n",
      "[CV] END model__bagging_fraction=0.7613583429151329, model__feature_fraction=0.9533035177275063, model__learning_rate=0.005, model__max_depth=8, model__n_estimators=2000, model__num_leaves=77; total time= 2.7min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.028780\n",
      "[CV] END model__bagging_fraction=0.9373859105784483, model__feature_fraction=0.6694954735867986, model__learning_rate=0.04635595343323531, model__max_depth=8, model__n_estimators=657, model__num_leaves=100; total time=  11.2s\n",
      "[RankICScorer] Fold Rank IC = 0.113246\n",
      "[CV] END model__bagging_fraction=0.9373859105784483, model__feature_fraction=0.6694954735867986, model__learning_rate=0.04635595343323531, model__max_depth=8, model__n_estimators=657, model__num_leaves=100; total time=  18.2s\n",
      "[RankICScorer] Fold Rank IC = 0.075081\n",
      "[CV] END model__bagging_fraction=0.9373859105784483, model__feature_fraction=0.6694954735867986, model__learning_rate=0.04635595343323531, model__max_depth=8, model__n_estimators=657, model__num_leaves=100; total time=  26.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.022571\n",
      "[CV] END model__bagging_fraction=0.6026607232464213, model__feature_fraction=0.8033732508491402, model__learning_rate=0.006785094370124956, model__max_depth=11, model__n_estimators=672, model__num_leaves=21; total time=   9.8s\n",
      "[RankICScorer] Fold Rank IC = 0.133970\n",
      "[CV] END model__bagging_fraction=0.6026607232464213, model__feature_fraction=0.8033732508491402, model__learning_rate=0.006785094370124956, model__max_depth=11, model__n_estimators=672, model__num_leaves=21; total time=  16.0s\n",
      "[RankICScorer] Fold Rank IC = 0.078689\n",
      "[CV] END model__bagging_fraction=0.6026607232464213, model__feature_fraction=0.8033732508491402, model__learning_rate=0.006785094370124956, model__max_depth=11, model__n_estimators=672, model__num_leaves=21; total time=  35.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.028735\n",
      "[CV] END model__bagging_fraction=0.6594100707104185, model__feature_fraction=1.0, model__learning_rate=0.04345992774879487, model__max_depth=13, model__n_estimators=500, model__num_leaves=20; total time=   5.9s\n",
      "[RankICScorer] Fold Rank IC = 0.127806\n",
      "[CV] END model__bagging_fraction=0.6594100707104185, model__feature_fraction=1.0, model__learning_rate=0.04345992774879487, model__max_depth=13, model__n_estimators=500, model__num_leaves=20; total time=  10.5s\n",
      "[RankICScorer] Fold Rank IC = 0.081769\n",
      "[CV] END model__bagging_fraction=0.6594100707104185, model__feature_fraction=1.0, model__learning_rate=0.04345992774879487, model__max_depth=13, model__n_estimators=500, model__num_leaves=20; total time=  19.7s\n",
      "--- LGBM 调优完成 ---\n",
      "最佳交叉验证得分 (Rank IC): 0.079474\n",
      "最佳参数: {'bagging_fraction': 0.817361227076125, 'feature_fraction': 0.9680036905749265, 'learning_rate': 0.015683273202615675, 'max_depth': 13, 'n_estimators': 986, 'num_leaves': 24}\n",
      "\n",
      "--- 3.2 开始为 XGB 进行贝叶斯优化 ---\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.034528\n",
      "[CV] END model__colsample_bytree=0.7640415835413256, model__learning_rate=0.026711344437355546, model__max_depth=8, model__min_child_weight=10, model__n_estimators=1505, model__subsample=0.7656474529942154; total time=  35.9s\n",
      "[RankICScorer] Fold Rank IC = 0.107975\n",
      "[CV] END model__colsample_bytree=0.7640415835413256, model__learning_rate=0.026711344437355546, model__max_depth=8, model__min_child_weight=10, model__n_estimators=1505, model__subsample=0.7656474529942154; total time=  45.9s\n",
      "[RankICScorer] Fold Rank IC = 0.070231\n",
      "[CV] END model__colsample_bytree=0.7640415835413256, model__learning_rate=0.026711344437355546, model__max_depth=8, model__min_child_weight=10, model__n_estimators=1505, model__subsample=0.7656474529942154; total time=  54.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033413\n",
      "[CV] END model__colsample_bytree=0.9349553422213137, model__learning_rate=0.03821952468883263, model__max_depth=5, model__min_child_weight=29, model__n_estimators=1796, model__subsample=0.6249251763376286; total time=  26.6s\n",
      "[RankICScorer] Fold Rank IC = 0.112596\n",
      "[CV] END model__colsample_bytree=0.9349553422213137, model__learning_rate=0.03821952468883263, model__max_depth=5, model__min_child_weight=29, model__n_estimators=1796, model__subsample=0.6249251763376286; total time=  29.8s\n",
      "[RankICScorer] Fold Rank IC = 0.069112\n",
      "[CV] END model__colsample_bytree=0.9349553422213137, model__learning_rate=0.03821952468883263, model__max_depth=5, model__min_child_weight=29, model__n_estimators=1796, model__subsample=0.6249251763376286; total time=  38.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033118\n",
      "[CV] END model__colsample_bytree=0.7779330049204607, model__learning_rate=0.0414660365353187, model__max_depth=4, model__min_child_weight=14, model__n_estimators=782, model__subsample=0.7814661375225196; total time=  12.5s\n",
      "[RankICScorer] Fold Rank IC = 0.127938\n",
      "[CV] END model__colsample_bytree=0.7779330049204607, model__learning_rate=0.0414660365353187, model__max_depth=4, model__min_child_weight=14, model__n_estimators=782, model__subsample=0.7814661375225196; total time=  15.7s\n",
      "[RankICScorer] Fold Rank IC = 0.076343\n",
      "[CV] END model__colsample_bytree=0.7779330049204607, model__learning_rate=0.0414660365353187, model__max_depth=4, model__min_child_weight=14, model__n_estimators=782, model__subsample=0.7814661375225196; total time=  20.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.031312\n",
      "[CV] END model__colsample_bytree=0.9249583953429453, model__learning_rate=0.007427481277233235, model__max_depth=6, model__min_child_weight=24, model__n_estimators=1285, model__subsample=0.6381820156859974; total time=  22.2s\n",
      "[RankICScorer] Fold Rank IC = 0.131056\n",
      "[CV] END model__colsample_bytree=0.9249583953429453, model__learning_rate=0.007427481277233235, model__max_depth=6, model__min_child_weight=24, model__n_estimators=1285, model__subsample=0.6381820156859974; total time=  28.8s\n",
      "[RankICScorer] Fold Rank IC = 0.080191\n",
      "[CV] END model__colsample_bytree=0.9249583953429453, model__learning_rate=0.007427481277233235, model__max_depth=6, model__min_child_weight=24, model__n_estimators=1285, model__subsample=0.6381820156859974; total time=  33.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.032765\n",
      "[CV] END model__colsample_bytree=0.9198213766428692, model__learning_rate=0.013708792117964526, model__max_depth=6, model__min_child_weight=22, model__n_estimators=1856, model__subsample=0.8868124604639347; total time=  27.9s\n",
      "[RankICScorer] Fold Rank IC = 0.119618\n",
      "[CV] END model__colsample_bytree=0.9198213766428692, model__learning_rate=0.013708792117964526, model__max_depth=6, model__min_child_weight=22, model__n_estimators=1856, model__subsample=0.8868124604639347; total time=  35.5s\n",
      "[RankICScorer] Fold Rank IC = 0.074234\n",
      "[CV] END model__colsample_bytree=0.9198213766428692, model__learning_rate=0.013708792117964526, model__max_depth=6, model__min_child_weight=22, model__n_estimators=1856, model__subsample=0.8868124604639347; total time=  43.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.034811\n",
      "[CV] END model__colsample_bytree=0.8936112071942273, model__learning_rate=0.04348502678703971, model__max_depth=4, model__min_child_weight=6, model__n_estimators=1701, model__subsample=0.7490319111933031; total time=  20.1s\n",
      "[RankICScorer] Fold Rank IC = 0.115704\n",
      "[CV] END model__colsample_bytree=0.8936112071942273, model__learning_rate=0.04348502678703971, model__max_depth=4, model__min_child_weight=6, model__n_estimators=1701, model__subsample=0.7490319111933031; total time=  27.5s\n",
      "[RankICScorer] Fold Rank IC = 0.072007\n",
      "[CV] END model__colsample_bytree=0.8936112071942273, model__learning_rate=0.04348502678703971, model__max_depth=4, model__min_child_weight=6, model__n_estimators=1701, model__subsample=0.7490319111933031; total time=  31.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033934\n",
      "[CV] END model__colsample_bytree=0.8468317434009265, model__learning_rate=0.029808106083955625, model__max_depth=5, model__min_child_weight=26, model__n_estimators=1389, model__subsample=0.8378480140347354; total time=  18.7s\n",
      "[RankICScorer] Fold Rank IC = 0.117099\n",
      "[CV] END model__colsample_bytree=0.8468317434009265, model__learning_rate=0.029808106083955625, model__max_depth=5, model__min_child_weight=26, model__n_estimators=1389, model__subsample=0.8378480140347354; total time=  24.5s\n",
      "[RankICScorer] Fold Rank IC = 0.071989\n",
      "[CV] END model__colsample_bytree=0.8468317434009265, model__learning_rate=0.029808106083955625, model__max_depth=5, model__min_child_weight=26, model__n_estimators=1389, model__subsample=0.8378480140347354; total time=  30.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033254\n",
      "[CV] END model__colsample_bytree=0.817361227076125, model__learning_rate=0.04158907209132091, model__max_depth=5, model__min_child_weight=25, model__n_estimators=986, model__subsample=0.6204538214708207; total time=  14.4s\n",
      "[RankICScorer] Fold Rank IC = 0.118265\n",
      "[CV] END model__colsample_bytree=0.817361227076125, model__learning_rate=0.04158907209132091, model__max_depth=5, model__min_child_weight=25, model__n_estimators=986, model__subsample=0.6204538214708207; total time=  19.9s\n",
      "[RankICScorer] Fold Rank IC = 0.073537\n",
      "[CV] END model__colsample_bytree=0.817361227076125, model__learning_rate=0.04158907209132091, model__max_depth=5, model__min_child_weight=25, model__n_estimators=986, model__subsample=0.6204538214708207; total time=  24.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.035693\n",
      "[CV] END model__colsample_bytree=0.9821911945239713, model__learning_rate=0.025095245519245572, model__max_depth=7, model__min_child_weight=13, model__n_estimators=1072, model__subsample=0.6845657149096784; total time=  22.1s\n",
      "[RankICScorer] Fold Rank IC = 0.114958\n",
      "[CV] END model__colsample_bytree=0.9821911945239713, model__learning_rate=0.025095245519245572, model__max_depth=7, model__min_child_weight=13, model__n_estimators=1072, model__subsample=0.6845657149096784; total time=  28.8s\n",
      "[RankICScorer] Fold Rank IC = 0.072283\n",
      "[CV] END model__colsample_bytree=0.9821911945239713, model__learning_rate=0.025095245519245572, model__max_depth=7, model__min_child_weight=13, model__n_estimators=1072, model__subsample=0.6845657149096784; total time=  33.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033910\n",
      "[CV] END model__colsample_bytree=0.6014521229018973, model__learning_rate=0.03287002421332476, model__max_depth=7, model__min_child_weight=8, model__n_estimators=1368, model__subsample=0.709885939534167; total time=  28.0s\n",
      "[RankICScorer] Fold Rank IC = 0.108613\n",
      "[CV] END model__colsample_bytree=0.6014521229018973, model__learning_rate=0.03287002421332476, model__max_depth=7, model__min_child_weight=8, model__n_estimators=1368, model__subsample=0.709885939534167; total time=  34.3s\n",
      "[RankICScorer] Fold Rank IC = 0.070978\n",
      "[CV] END model__colsample_bytree=0.6014521229018973, model__learning_rate=0.03287002421332476, model__max_depth=7, model__min_child_weight=8, model__n_estimators=1368, model__subsample=0.709885939534167; total time=  42.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.005192\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.005, model__max_depth=3, model__min_child_weight=1, model__n_estimators=500, model__subsample=1.0; total time=   8.3s\n",
      "[RankICScorer] Fold Rank IC = 0.124886\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.005, model__max_depth=3, model__min_child_weight=1, model__n_estimators=500, model__subsample=1.0; total time=  12.1s\n",
      "[RankICScorer] Fold Rank IC = 0.070581\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.005, model__max_depth=3, model__min_child_weight=1, model__n_estimators=500, model__subsample=1.0; total time=  16.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.006839\n",
      "[CV] END model__colsample_bytree=0.9838062616594775, model__learning_rate=0.005, model__max_depth=3, model__min_child_weight=30, model__n_estimators=500, model__subsample=0.7299894633527474; total time=  10.0s\n",
      "[RankICScorer] Fold Rank IC = 0.125242\n",
      "[CV] END model__colsample_bytree=0.9838062616594775, model__learning_rate=0.005, model__max_depth=3, model__min_child_weight=30, model__n_estimators=500, model__subsample=0.7299894633527474; total time=  11.8s\n",
      "[RankICScorer] Fold Rank IC = 0.070741\n",
      "[CV] END model__colsample_bytree=0.9838062616594775, model__learning_rate=0.005, model__max_depth=3, model__min_child_weight=30, model__n_estimators=500, model__subsample=0.7299894633527474; total time=  16.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.026193\n",
      "[CV] END model__colsample_bytree=0.7062333252130372, model__learning_rate=0.005, model__max_depth=8, model__min_child_weight=17, model__n_estimators=500, model__subsample=0.7744128365910068; total time=  15.2s\n",
      "[RankICScorer] Fold Rank IC = 0.131892\n",
      "[CV] END model__colsample_bytree=0.7062333252130372, model__learning_rate=0.005, model__max_depth=8, model__min_child_weight=17, model__n_estimators=500, model__subsample=0.7744128365910068; total time=  20.8s\n",
      "[RankICScorer] Fold Rank IC = 0.079816\n",
      "[CV] END model__colsample_bytree=0.7062333252130372, model__learning_rate=0.005, model__max_depth=8, model__min_child_weight=17, model__n_estimators=500, model__subsample=0.7744128365910068; total time=  26.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.034083\n",
      "[CV] END model__colsample_bytree=0.845811644520922, model__learning_rate=0.005033527388361385, model__max_depth=8, model__min_child_weight=19, model__n_estimators=1997, model__subsample=0.8237736465487392; total time=  46.9s\n",
      "[RankICScorer] Fold Rank IC = 0.125195\n",
      "[CV] END model__colsample_bytree=0.845811644520922, model__learning_rate=0.005033527388361385, model__max_depth=8, model__min_child_weight=19, model__n_estimators=1997, model__subsample=0.8237736465487392; total time=  56.5s\n",
      "[RankICScorer] Fold Rank IC = 0.078925\n",
      "[CV] END model__colsample_bytree=0.845811644520922, model__learning_rate=0.005033527388361385, model__max_depth=8, model__min_child_weight=19, model__n_estimators=1997, model__subsample=0.8237736465487392; total time= 1.1min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.029973\n",
      "[CV] END model__colsample_bytree=0.8303558734671749, model__learning_rate=0.02704698419279335, model__max_depth=3, model__min_child_weight=20, model__n_estimators=500, model__subsample=0.6; total time=   9.2s\n",
      "[RankICScorer] Fold Rank IC = 0.135636\n",
      "[CV] END model__colsample_bytree=0.8303558734671749, model__learning_rate=0.02704698419279335, model__max_depth=3, model__min_child_weight=20, model__n_estimators=500, model__subsample=0.6; total time=  12.1s\n",
      "[RankICScorer] Fold Rank IC = 0.083598\n",
      "[CV] END model__colsample_bytree=0.8303558734671749, model__learning_rate=0.02704698419279335, model__max_depth=3, model__min_child_weight=20, model__n_estimators=500, model__subsample=0.6; total time=  16.1s\n",
      "--- XGB 调优完成 ---\n",
      "最佳交叉验证得分 (Rank IC): 0.083069\n",
      "最佳参数: {'colsample_bytree': 0.8303558734671749, 'learning_rate': 0.02704698419279335, 'max_depth': 3, 'min_child_weight': 20, 'n_estimators': 500, 'subsample': 0.6}\n",
      "\n",
      "--- 3.3 开始为 CATBOOST 进行贝叶斯优化 ---\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.031538\n",
      "[CV] END model__depth=6, model__iterations=1592, model__l2_leaf_reg=9, model__learning_rate=0.010345931480630859; total time= 2.6min\n",
      "[RankICScorer] Fold Rank IC = 0.134644\n",
      "[CV] END model__depth=6, model__iterations=1592, model__l2_leaf_reg=9, model__learning_rate=0.010345931480630859; total time= 4.2min\n",
      "[RankICScorer] Fold Rank IC = 0.080259\n",
      "[CV] END model__depth=6, model__iterations=1592, model__l2_leaf_reg=9, model__learning_rate=0.010345931480630859; total time= 4.9min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.036177\n",
      "[CV] END model__depth=9, model__iterations=1825, model__l2_leaf_reg=4, model__learning_rate=0.04468830793054611; total time= 4.0min\n",
      "[RankICScorer] Fold Rank IC = 0.110990\n",
      "[CV] END model__depth=9, model__iterations=1825, model__l2_leaf_reg=4, model__learning_rate=0.04468830793054611; total time= 6.7min\n",
      "[RankICScorer] Fold Rank IC = 0.074020\n",
      "[CV] END model__depth=9, model__iterations=1825, model__l2_leaf_reg=4, model__learning_rate=0.04468830793054611; total time= 8.1min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033118\n",
      "[CV] END model__depth=7, model__iterations=1878, model__l2_leaf_reg=2, model__learning_rate=0.013561346301101212; total time= 3.2min\n",
      "[RankICScorer] Fold Rank IC = 0.128451\n",
      "[CV] END model__depth=7, model__iterations=1878, model__l2_leaf_reg=2, model__learning_rate=0.013561346301101212; total time= 5.6min\n",
      "[RankICScorer] Fold Rank IC = 0.078607\n",
      "[CV] END model__depth=7, model__iterations=1878, model__l2_leaf_reg=2, model__learning_rate=0.013561346301101212; total time= 6.4min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.032527\n",
      "[CV] END model__depth=9, model__iterations=758, model__l2_leaf_reg=6, model__learning_rate=0.03174934612712105; total time= 1.8min\n",
      "[RankICScorer] Fold Rank IC = 0.122417\n",
      "[CV] END model__depth=9, model__iterations=758, model__l2_leaf_reg=6, model__learning_rate=0.03174934612712105; total time= 2.6min\n",
      "[RankICScorer] Fold Rank IC = 0.077736\n",
      "[CV] END model__depth=9, model__iterations=758, model__l2_leaf_reg=6, model__learning_rate=0.03174934612712105; total time= 3.6min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033063\n",
      "[CV] END model__depth=9, model__iterations=1157, model__l2_leaf_reg=6, model__learning_rate=0.02598263942609248; total time= 2.1min\n",
      "[RankICScorer] Fold Rank IC = 0.120595\n",
      "[CV] END model__depth=9, model__iterations=1157, model__l2_leaf_reg=6, model__learning_rate=0.02598263942609248; total time= 4.0min\n",
      "[RankICScorer] Fold Rank IC = 0.078978\n",
      "[CV] END model__depth=9, model__iterations=1157, model__l2_leaf_reg=6, model__learning_rate=0.02598263942609248; total time= 5.1min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.032763\n",
      "[CV] END model__depth=8, model__iterations=1909, model__l2_leaf_reg=2, model__learning_rate=0.0077160546707755046; total time= 3.5min\n",
      "[RankICScorer] Fold Rank IC = 0.130954\n",
      "[CV] END model__depth=8, model__iterations=1909, model__l2_leaf_reg=2, model__learning_rate=0.0077160546707755046; total time= 6.3min\n",
      "[RankICScorer] Fold Rank IC = 0.080761\n",
      "[CV] END model__depth=8, model__iterations=1909, model__l2_leaf_reg=2, model__learning_rate=0.0077160546707755046; total time= 8.3min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033597\n",
      "[CV] END model__depth=8, model__iterations=1663, model__l2_leaf_reg=4, model__learning_rate=0.0374365052248341; total time= 3.2min\n",
      "[RankICScorer] Fold Rank IC = 0.115640\n",
      "[CV] END model__depth=8, model__iterations=1663, model__l2_leaf_reg=4, model__learning_rate=0.0374365052248341; total time= 5.0min\n",
      "[RankICScorer] Fold Rank IC = 0.075551\n",
      "[CV] END model__depth=8, model__iterations=1663, model__l2_leaf_reg=4, model__learning_rate=0.0374365052248341; total time= 7.4min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.035145\n",
      "[CV] END model__depth=7, model__iterations=1880, model__l2_leaf_reg=5, model__learning_rate=0.034405386535662504; total time= 3.1min\n",
      "[RankICScorer] Fold Rank IC = 0.119750\n",
      "[CV] END model__depth=7, model__iterations=1880, model__l2_leaf_reg=5, model__learning_rate=0.034405386535662504; total time= 4.9min\n",
      "[RankICScorer] Fold Rank IC = 0.075038\n",
      "[CV] END model__depth=7, model__iterations=1880, model__l2_leaf_reg=5, model__learning_rate=0.034405386535662504; total time= 7.0min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.030488\n",
      "[CV] END model__depth=10, model__iterations=1551, model__l2_leaf_reg=9, model__learning_rate=0.013025400686523187; total time= 4.6min\n",
      "[RankICScorer] Fold Rank IC = 0.122867\n",
      "[CV] END model__depth=10, model__iterations=1551, model__l2_leaf_reg=9, model__learning_rate=0.013025400686523187; total time= 8.7min\n",
      "[RankICScorer] Fold Rank IC = 0.078912\n",
      "[CV] END model__depth=10, model__iterations=1551, model__l2_leaf_reg=9, model__learning_rate=0.013025400686523187; total time=18.6min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.028541\n",
      "[CV] END model__depth=4, model__iterations=1727, model__l2_leaf_reg=8, model__learning_rate=0.008985127872864616; total time= 2.7min\n",
      "[RankICScorer] Fold Rank IC = 0.137768\n",
      "[CV] END model__depth=4, model__iterations=1727, model__l2_leaf_reg=8, model__learning_rate=0.008985127872864616; total time= 4.8min\n",
      "[RankICScorer] Fold Rank IC = 0.080983\n",
      "[CV] END model__depth=4, model__iterations=1727, model__l2_leaf_reg=8, model__learning_rate=0.008985127872864616; total time= 6.5min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.028159\n",
      "[CV] END model__depth=4, model__iterations=559, model__l2_leaf_reg=10, model__learning_rate=0.02992437375773952; total time= 1.1min\n",
      "[RankICScorer] Fold Rank IC = 0.137788\n",
      "[CV] END model__depth=4, model__iterations=559, model__l2_leaf_reg=10, model__learning_rate=0.02992437375773952; total time= 1.8min\n",
      "[RankICScorer] Fold Rank IC = 0.080958\n",
      "[CV] END model__depth=4, model__iterations=559, model__l2_leaf_reg=10, model__learning_rate=0.02992437375773952; total time= 2.4min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.011959\n",
      "[CV] END model__depth=4, model__iterations=640, model__l2_leaf_reg=3, model__learning_rate=0.005069781418441629; total time= 1.1min\n",
      "[RankICScorer] Fold Rank IC = 0.129845\n",
      "[CV] END model__depth=4, model__iterations=640, model__l2_leaf_reg=3, model__learning_rate=0.005069781418441629; total time= 1.8min\n",
      "[RankICScorer] Fold Rank IC = 0.074321\n",
      "[CV] END model__depth=4, model__iterations=640, model__l2_leaf_reg=3, model__learning_rate=0.005069781418441629; total time= 2.8min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.033207\n",
      "[CV] END model__depth=10, model__iterations=736, model__l2_leaf_reg=1, model__learning_rate=0.047409055529355766; total time= 3.7min\n",
      "[RankICScorer] Fold Rank IC = 0.115389\n",
      "[CV] END model__depth=10, model__iterations=736, model__l2_leaf_reg=1, model__learning_rate=0.047409055529355766; total time= 5.6min\n",
      "[RankICScorer] Fold Rank IC = 0.075227\n",
      "[CV] END model__depth=10, model__iterations=736, model__l2_leaf_reg=1, model__learning_rate=0.047409055529355766; total time= 8.6min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.032283\n",
      "[CV] END model__depth=8, model__iterations=503, model__l2_leaf_reg=8, model__learning_rate=0.0373153830930954; total time= 1.4min\n",
      "[RankICScorer] Fold Rank IC = 0.128799\n",
      "[CV] END model__depth=8, model__iterations=503, model__l2_leaf_reg=8, model__learning_rate=0.0373153830930954; total time= 2.2min\n",
      "[RankICScorer] Fold Rank IC = 0.078499\n",
      "[CV] END model__depth=8, model__iterations=503, model__l2_leaf_reg=8, model__learning_rate=0.0373153830930954; total time= 3.4min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.030470\n",
      "[CV] END model__depth=4, model__iterations=548, model__l2_leaf_reg=7, model__learning_rate=0.044553079450653385; total time=  59.2s\n",
      "[RankICScorer] Fold Rank IC = 0.134664\n",
      "[CV] END model__depth=4, model__iterations=548, model__l2_leaf_reg=7, model__learning_rate=0.044553079450653385; total time= 1.5min\n",
      "[RankICScorer] Fold Rank IC = 0.081075\n",
      "[CV] END model__depth=4, model__iterations=548, model__l2_leaf_reg=7, model__learning_rate=0.044553079450653385; total time= 2.1min\n",
      "--- CATBOOST 调优完成 ---\n",
      "最佳交叉验证得分 (Rank IC): 0.082431\n",
      "最佳参数: {'depth': 4, 'iterations': 1727, 'l2_leaf_reg': 8, 'learning_rate': 0.008985127872864616}\n",
      "\n",
      "--- 4. 使用最优参数在最终训练集上训练三驾马车模型 ---\n",
      "正在训练最终的 LGBM 模型...\n",
      "LGBM 预测完成。\n",
      "正在训练最终的 XGB 模型...\n",
      "XGB 预测完成。\n",
      "正在训练最终的 CATBOOST 模型...\n",
      "CATBOOST 预测完成。\n",
      "\n",
      "--- 5. 在独立验证集上评估最终集成模型 ---\n",
      "\n",
      "独立验证集上的最终Rank IC: 0.160886\n",
      "\n",
      "--- 6. 生成最终提交文件 ---\n",
      "提交文件 'submission_pipeline_v13.1.csv' 已生成.\n",
      "   id    code  date    y_pred\n",
      "0   0     s_0  1691  0.003530\n",
      "1   1     s_1  1691 -0.045584\n",
      "2   2    s_10  1691  0.003449\n",
      "3   3   s_100  1691 -0.005165\n",
      "4   4  s_1001  1691 -0.001984\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:28:35.201770Z",
     "start_time": "2025-07-30T05:55:24.542107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 0.9 === 模型训练管道 v22.1 (错误修复与跳过搜索版) ===\n",
    "# 核心变更:\n",
    "# 1. (修复) 为CatBoost模型添加 bootstrap_type='MVS'，以解决与 subsample 参数的兼容性问题。\n",
    "# 2. (优化) 硬编码已知的XGBoost最优参数，并在本次运行中跳过其超参数搜索过程以节省时间。\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import os\n",
    "import gc\n",
    "import polars as pl\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn & Scikit-optimize Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def calculate_rank_ic_polars(y_true, y_pred, dates):\n",
    "    \"\"\"使用Polars高效计算Rank IC\"\"\"\n",
    "    if isinstance(y_true, pd.Series): y_true = y_true.to_numpy()\n",
    "    if isinstance(y_pred, pd.Series): y_pred = y_pred.to_numpy()\n",
    "    if isinstance(dates, pd.Series): dates = dates.to_numpy()\n",
    "\n",
    "    df = pl.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'date': dates})\n",
    "    daily_ic = df.group_by('date', maintain_order=True).agg(\n",
    "        pl.corr('y_true', 'y_pred', method='spearman').fill_nan(0.0).alias('ic')\n",
    "    )\n",
    "    return daily_ic['ic'].mean()\n",
    "\n",
    "class RankICScorer:\n",
    "    \"\"\"一个与scikit-learn兼容的自定义评分器\"\"\"\n",
    "    def __init__(self, dates: pd.Series):\n",
    "        self.dates = dates.reset_index(drop=True)\n",
    "\n",
    "    def __call__(self, estimator, X, y_true) -> float:\n",
    "        fold_dates = self.dates.iloc[X.index]\n",
    "        y_pred = estimator.predict(X)\n",
    "        rank_ic = calculate_rank_ic_polars(y_true, y_pred, fold_dates)\n",
    "        print(f\"[RankICScorer] Fold Rank IC = {rank_ic:.6f}\")\n",
    "        return rank_ic if np.isfinite(rank_ic) else 0.0\n",
    "\n",
    "# --- 自定义重叠滑动窗口交叉验证 ---\n",
    "def sliding_window_cv(dates, n_splits=3, train_days=300, test_days=200, step_days=100):\n",
    "    \"\"\"生成重叠的、向前滚动的滑动窗口交叉验证索引\"\"\"\n",
    "    unique_dates = sorted(dates.unique())\n",
    "    last_split_test_end_idx = (n_splits - 1) * step_days + train_days + test_days\n",
    "\n",
    "    if len(unique_dates) < last_split_test_end_idx:\n",
    "        raise ValueError(\n",
    "            f\"数据不足以创建{n_splits}个重叠滑动窗口。\"\n",
    "            f\"需要 {last_split_test_end_idx} 天, 但只有 {len(unique_dates)} 天。\"\n",
    "        )\n",
    "\n",
    "    print(f\"--- 创建重叠滑动窗口 (训练={train_days}天, 验证={test_days}天, 步长={step_days}天, 共{n_splits}折) ---\")\n",
    "    for i in range(n_splits):\n",
    "        train_start_idx = i * step_days\n",
    "        train_end_idx = train_start_idx + train_days\n",
    "        test_start_idx = train_end_idx\n",
    "        test_end_idx = test_start_idx + test_days\n",
    "        train_dates = unique_dates[train_start_idx : train_end_idx]\n",
    "        test_dates = unique_dates[test_start_idx : test_end_idx]\n",
    "        print(f\"Fold {i+1}: Train on {train_dates[0]} to {train_dates[-1]}, \"\n",
    "              f\"Validate on {test_dates[0]} to {test_dates[-1]}\")\n",
    "        train_mask = dates.isin(train_dates)\n",
    "        test_mask = dates.isin(test_dates)\n",
    "        yield dates[train_mask].index.to_numpy(), dates[test_mask].index.to_numpy()\n",
    "\n",
    "# --- 1. 核心特征工程 ---\n",
    "def preprocess_and_rank(df):\n",
    "    \"\"\"截面排名特征\"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ['code', 'date']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    float_cols = [c for c in df.columns if df[c].dtype == 'float64']\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    pl_df = pl.from_pandas(df)\n",
    "    feature_cols = [col for col in df.columns if col.startswith('f_')]\n",
    "    pl_df = pl_df.with_columns([\n",
    "        ((pl.col(feature).rank(method='ordinal').over('date') - 1) / (pl.col(feature).count().over('date') - 1)).alias(feature)\n",
    "        for feature in feature_cols\n",
    "    ])\n",
    "    final_df = pl_df.to_pandas()\n",
    "    final_df.fillna(0.5, inplace=True)\n",
    "    return final_df\n",
    "\n",
    "# --- 2. 主执行流程 ---\n",
    "def main():\n",
    "    print(\"--- 正在加载数据 ---\")\n",
    "    DATA_PATH = './stocks-return-prediction'\n",
    "    train_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'train_data9.pkl'))\n",
    "    test_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'test_data9.pkl'))\n",
    "\n",
    "    print(\"\\n--- 1. 核心特征工程 (仅截面排名) ---\")\n",
    "    train_df = preprocess_and_rank(train_df_raw.copy())\n",
    "    test_df = preprocess_and_rank(test_df_raw.copy())\n",
    "    train_df.sort_values(by=['date', 'code'], inplace=True, ignore_index=True)\n",
    "    test_df.sort_values(by=['date', 'code'], inplace=True, ignore_index=True)\n",
    "    del train_df_raw\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"\\n--- 2. 数据集划分 ---\")\n",
    "    unique_dates = sorted(train_df['date'].unique())\n",
    "\n",
    "    # 最终训练集：最新的300天\n",
    "    train_final_start_date = unique_dates[-300]\n",
    "    train_final_df = train_df[train_df['date'] >= train_final_start_date].copy()\n",
    "\n",
    "    # 超参数搜索集：最新的700天\n",
    "    search_start_date = unique_dates[-700]\n",
    "    search_df = train_df[train_df['date'] >= search_start_date].copy()\n",
    "\n",
    "    print(f\"超参数搜索集: {search_df['date'].min()} - {search_df['date'].max()} ({search_df['date'].nunique()} 天)\")\n",
    "    print(f\"最终训练集: {train_final_df['date'].min()} - {train_final_df['date'].max()} ({train_final_df['date'].nunique()} 天)\")\n",
    "\n",
    "    features = [col for col in train_df.columns if col.startswith('f_')]\n",
    "    print(f\"\\n--- 3. 使用全部 {len(features)} 个初始特征进行训练 ---\")\n",
    "\n",
    "    # --- 4. 独立调优三驾马车模型 (扩展搜索空间) ---\n",
    "    search_df.reset_index(drop=True, inplace=True)\n",
    "    X_search, y_search = search_df[features], search_df['y']\n",
    "    custom_cv = list(sliding_window_cv(search_df['date'], n_splits=3, train_days=300, test_days=200, step_days=100))\n",
    "    rank_ic_scorer = RankICScorer(dates=search_df['date'])\n",
    "\n",
    "    # (优化) 硬编码XGBoost参数并跳过搜索\n",
    "    best_params_all = {\n",
    "        'xgb': {'colsample_bytree': 0.6, 'learning_rate': 0.012428019985097712, 'max_depth': 3, 'min_child_weight': 20, 'n_estimators': 1200, 'subsample': 0.6}\n",
    "    }\n",
    "    print(\"\\n--- 使用已知的XGBoost最佳参数，跳过其搜索过程 ---\")\n",
    "    print(f\"XGBoost Params: {best_params_all['xgb']}\")\n",
    "\n",
    "    # 本次运行只搜索CatBoost和LGBM\n",
    "    models_to_tune = ['catboost', 'lgbm']\n",
    "\n",
    "    for model_name in models_to_tune:\n",
    "        print(f\"\\n--- 4.{models_to_tune.index(model_name)+1} 开始为 {model_name.upper()} 进行贝叶斯优化 ---\")\n",
    "        if model_name == 'xgb': # 这部分代码保留，但不会被执行\n",
    "            model = xgb.XGBRegressor(random_state=42, tree_method='gpu_hist', n_jobs=-1)\n",
    "            search_spaces = {\n",
    "                'n_estimators': (500, 2000), 'learning_rate': (0.005, 0.05, 'log-uniform'), 'max_depth': (3, 10),\n",
    "                'subsample': (0.6, 1.0, 'uniform'), 'colsample_bytree': (0.6, 1.0, 'uniform'), 'min_child_weight': (1, 30)\n",
    "            }\n",
    "        elif model_name == 'catboost':\n",
    "            # (修复) 添加 bootstrap_type='MVS' 以兼容 subsample\n",
    "            model = cb.CatBoostRegressor(random_state=42, verbose=0, allow_writing_files=False, task_type='GPU', bootstrap_type='MVS')\n",
    "            search_spaces = {\n",
    "                'iterations': (100, 1200), 'learning_rate': (0.005, 0.05, 'log-uniform'), 'depth': (4, 10),\n",
    "                'l2_leaf_reg': (1, 10, 'uniform'), 'subsample': (0.6, 1.0, 'uniform')\n",
    "            }\n",
    "        elif model_name == 'lgbm':\n",
    "            model = lgb.LGBMRegressor(random_state=42, device='gpu', n_jobs=-1, verbose=-1)\n",
    "            search_spaces = {\n",
    "                'n_estimators': (100, 1200), 'learning_rate': (0.005, 0.05, 'log-uniform'), 'num_leaves': (20, 150),\n",
    "                'feature_fraction': (0.6, 1.0, 'uniform'), 'bagging_fraction': (0.6, 1.0, 'uniform'),\n",
    "                'lambda_l1': (1e-8, 10.0, 'log-uniform'), 'lambda_l2': (1e-8, 10.0, 'log-uniform')\n",
    "            }\n",
    "\n",
    "        pipeline = Pipeline([('scaler', MinMaxScaler()), ('model', model)])\n",
    "        prefixed_search_spaces = {f'model__{k}': v for k, v in search_spaces.items()}\n",
    "        search = BayesSearchCV(\n",
    "            estimator=pipeline, search_spaces=prefixed_search_spaces,\n",
    "            n_iter=20, scoring=rank_ic_scorer, cv=custom_cv,\n",
    "            random_state=42, n_jobs=1, verbose=2\n",
    "        )\n",
    "        search.fit(X_search, y_search)\n",
    "        best_params_all[model_name] = {k.replace('model__', ''): v for k, v in search.best_params_.items()}\n",
    "        print(f\"--- {model_name.upper()} 调优完成, 最佳CV得分: {search.best_score_:.6f} ---\")\n",
    "        print(f\"最佳参数: {best_params_all[model_name]}\")\n",
    "\n",
    "    # --- 5. 使用最优参数训练最终模型 ---\n",
    "    print(\"\\n--- 5. 使用最优参数在最终训练集上训练模型 ---\")\n",
    "    X_train_final, y_train_final = train_final_df[features], train_final_df['y']\n",
    "    X_test_final = test_df[features]\n",
    "\n",
    "    test_predictions = []\n",
    "    # 最终训练时，使用所有模型\n",
    "    all_models_for_final_training = ['xgb', 'catboost', 'lgbm']\n",
    "\n",
    "    for model_name in all_models_for_final_training:\n",
    "        print(f\"正在训练并预测 {model_name.upper()} 模型...\")\n",
    "        params = best_params_all[model_name]\n",
    "\n",
    "        if model_name == 'xgb':\n",
    "            model = xgb.XGBRegressor(random_state=42, tree_method='gpu_hist', n_jobs=-1, **params)\n",
    "        elif model_name == 'catboost':\n",
    "            # (修复) 同样需要在此处添加\n",
    "            model = cb.CatBoostRegressor(random_state=42, verbose=0, allow_writing_files=False, task_type='GPU', bootstrap_type='MVS', **params)\n",
    "        elif model_name == 'lgbm':\n",
    "            model = lgb.LGBMRegressor(random_state=42, device='gpu', n_jobs=-1, verbose=-1, **params)\n",
    "\n",
    "        pipeline = Pipeline([('scaler', MinMaxScaler()), ('model', model)])\n",
    "        pipeline.fit(X_train_final, y_train_final)\n",
    "\n",
    "        test_predictions.append(pipeline.predict(X_test_final))\n",
    "        print(f\"{model_name.upper()} 预测完成。\")\n",
    "\n",
    "    # --- 6. 生成最终提交文件 (简单平均集成) ---\n",
    "    print(\"\\n--- 6. 使用简单平均法集成并生成最终提交文件 ---\")\n",
    "    ensemble_prediction = np.mean(test_predictions, axis=0)\n",
    "\n",
    "    submission_df = test_df[['code', 'date']].copy()\n",
    "    submission_df['y_pred'] = ensemble_prediction\n",
    "    submission_df.reset_index(inplace=True)\n",
    "    submission_df.rename(columns={'index': 'id'}, inplace=True)\n",
    "    submission_df = submission_df[['id', 'code', 'date', 'y_pred']]\n",
    "\n",
    "    submission_df.to_csv('submission_pipeline_v22_fix.csv', index=False)\n",
    "    print(\"提交文件 'submission_pipeline_v22_fix.csv' 已生成.\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "7047c8c72fbabd48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在加载数据 ---\n",
      "\n",
      "--- 1. 核心特征工程 (仅截面排名) ---\n",
      "\n",
      "--- 2. 数据集划分 ---\n",
      "超参数搜索集: 991 - 1690 (700 天)\n",
      "最终训练集: 1391 - 1690 (300 天)\n",
      "\n",
      "--- 3. 使用全部 28 个初始特征进行训练 ---\n",
      "--- 创建重叠滑动窗口 (训练=300天, 验证=200天, 步长=100天, 共3折) ---\n",
      "Fold 1: Train on 991 to 1290, Validate on 1291 to 1490\n",
      "Fold 2: Train on 1091 to 1390, Validate on 1391 to 1590\n",
      "Fold 3: Train on 1191 to 1490, Validate on 1491 to 1690\n",
      "\n",
      "--- 使用已知的XGBoost最佳参数，跳过其搜索过程 ---\n",
      "XGBoost Params: {'colsample_bytree': 0.6, 'learning_rate': 0.012428019985097712, 'max_depth': 3, 'min_child_weight': 20, 'n_estimators': 1200, 'subsample': 0.6}\n",
      "\n",
      "--- 4.1 开始为 CATBOOST 进行贝叶斯优化 ---\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.072748\n",
      "[CV] END model__depth=6, model__iterations=1592, model__l2_leaf_reg=9, model__learning_rate=0.010345931480630859, model__subsample=0.8680591793075738; total time=  33.1s\n",
      "[RankICScorer] Fold Rank IC = 0.102335\n",
      "[CV] END model__depth=6, model__iterations=1592, model__l2_leaf_reg=9, model__learning_rate=0.010345931480630859, model__subsample=0.8680591793075738; total time=  32.9s\n",
      "[RankICScorer] Fold Rank IC = 0.092859\n",
      "[CV] END model__depth=6, model__iterations=1592, model__l2_leaf_reg=9, model__learning_rate=0.010345931480630859, model__subsample=0.8680591793075738; total time=  36.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.069663\n",
      "[CV] END model__depth=9, model__iterations=1825, model__l2_leaf_reg=4, model__learning_rate=0.04468830793054611, model__subsample=0.9456511661859803; total time=  54.4s\n",
      "[RankICScorer] Fold Rank IC = 0.081620\n",
      "[CV] END model__depth=9, model__iterations=1825, model__l2_leaf_reg=4, model__learning_rate=0.04468830793054611, model__subsample=0.9456511661859803; total time=  55.6s\n",
      "[RankICScorer] Fold Rank IC = 0.081105\n",
      "[CV] END model__depth=9, model__iterations=1825, model__l2_leaf_reg=4, model__learning_rate=0.04468830793054611, model__subsample=0.9456511661859803; total time=  55.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.076141\n",
      "[CV] END model__depth=7, model__iterations=1878, model__l2_leaf_reg=2, model__learning_rate=0.013561346301101212, model__subsample=0.6751820745469395; total time=  40.5s\n",
      "[RankICScorer] Fold Rank IC = 0.101277\n",
      "[CV] END model__depth=7, model__iterations=1878, model__l2_leaf_reg=2, model__learning_rate=0.013561346301101212, model__subsample=0.6751820745469395; total time=  42.4s\n",
      "[RankICScorer] Fold Rank IC = 0.092444\n",
      "[CV] END model__depth=7, model__iterations=1878, model__l2_leaf_reg=2, model__learning_rate=0.013561346301101212, model__subsample=0.6751820745469395; total time=  42.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.071230\n",
      "[CV] END model__depth=9, model__iterations=758, model__l2_leaf_reg=6, model__learning_rate=0.03174934612712105, model__subsample=0.8092209312217534; total time=  22.9s\n",
      "[RankICScorer] Fold Rank IC = 0.092709\n",
      "[CV] END model__depth=9, model__iterations=758, model__l2_leaf_reg=6, model__learning_rate=0.03174934612712105, model__subsample=0.8092209312217534; total time=  23.8s\n",
      "[RankICScorer] Fold Rank IC = 0.086550\n",
      "[CV] END model__depth=9, model__iterations=758, model__l2_leaf_reg=6, model__learning_rate=0.03174934612712105, model__subsample=0.8092209312217534; total time=  24.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.069169\n",
      "[CV] END model__depth=9, model__iterations=1157, model__l2_leaf_reg=6, model__learning_rate=0.02598263942609248, model__subsample=0.9615408290026747; total time=  34.5s\n",
      "[RankICScorer] Fold Rank IC = 0.091555\n",
      "[CV] END model__depth=9, model__iterations=1157, model__l2_leaf_reg=6, model__learning_rate=0.02598263942609248, model__subsample=0.9615408290026747; total time=  35.9s\n",
      "[RankICScorer] Fold Rank IC = 0.081682\n",
      "[CV] END model__depth=9, model__iterations=1157, model__l2_leaf_reg=6, model__learning_rate=0.02598263942609248, model__subsample=0.9615408290026747; total time=  35.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.074449\n",
      "[CV] END model__depth=8, model__iterations=1909, model__l2_leaf_reg=2, model__learning_rate=0.0077160546707755046, model__subsample=0.920201292582698; total time=  47.3s\n",
      "[RankICScorer] Fold Rank IC = 0.100552\n",
      "[CV] END model__depth=8, model__iterations=1909, model__l2_leaf_reg=2, model__learning_rate=0.0077160546707755046, model__subsample=0.920201292582698; total time=  48.1s\n",
      "[RankICScorer] Fold Rank IC = 0.092951\n",
      "[CV] END model__depth=8, model__iterations=1909, model__l2_leaf_reg=2, model__learning_rate=0.0077160546707755046, model__subsample=0.920201292582698; total time=  48.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.069214\n",
      "[CV] END model__depth=8, model__iterations=1663, model__l2_leaf_reg=4, model__learning_rate=0.0374365052248341, model__subsample=0.8370478701222271; total time=  41.6s\n",
      "[RankICScorer] Fold Rank IC = 0.088362\n",
      "[CV] END model__depth=8, model__iterations=1663, model__l2_leaf_reg=4, model__learning_rate=0.0374365052248341, model__subsample=0.8370478701222271; total time=  42.8s\n",
      "[RankICScorer] Fold Rank IC = 0.087490\n",
      "[CV] END model__depth=8, model__iterations=1663, model__l2_leaf_reg=4, model__learning_rate=0.0374365052248341, model__subsample=0.8370478701222271; total time=  44.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.074481\n",
      "[CV] END model__depth=7, model__iterations=1880, model__l2_leaf_reg=5, model__learning_rate=0.034405386535662504, model__subsample=0.7296239929137495; total time=  40.2s\n",
      "[RankICScorer] Fold Rank IC = 0.095541\n",
      "[CV] END model__depth=7, model__iterations=1880, model__l2_leaf_reg=5, model__learning_rate=0.034405386535662504, model__subsample=0.7296239929137495; total time=  43.2s\n",
      "[RankICScorer] Fold Rank IC = 0.091731\n",
      "[CV] END model__depth=7, model__iterations=1880, model__l2_leaf_reg=5, model__learning_rate=0.034405386535662504, model__subsample=0.7296239929137495; total time=  43.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.071131\n",
      "[CV] END model__depth=10, model__iterations=1551, model__l2_leaf_reg=9, model__learning_rate=0.013025400686523187, model__subsample=0.7524259059189972; total time=  53.8s\n",
      "[RankICScorer] Fold Rank IC = 0.090759\n",
      "[CV] END model__depth=10, model__iterations=1551, model__l2_leaf_reg=9, model__learning_rate=0.013025400686523187, model__subsample=0.7524259059189972; total time=  55.2s\n",
      "[RankICScorer] Fold Rank IC = 0.087953\n",
      "[CV] END model__depth=10, model__iterations=1551, model__l2_leaf_reg=9, model__learning_rate=0.013025400686523187, model__subsample=0.7524259059189972; total time=  56.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.074283\n",
      "[CV] END model__depth=4, model__iterations=1727, model__l2_leaf_reg=8, model__learning_rate=0.008985127872864616, model__subsample=0.831465734491354; total time=  26.2s\n",
      "[RankICScorer] Fold Rank IC = 0.099855\n",
      "[CV] END model__depth=4, model__iterations=1727, model__l2_leaf_reg=8, model__learning_rate=0.008985127872864616, model__subsample=0.831465734491354; total time=  25.5s\n",
      "[RankICScorer] Fold Rank IC = 0.085962\n",
      "[CV] END model__depth=4, model__iterations=1727, model__l2_leaf_reg=8, model__learning_rate=0.008985127872864616, model__subsample=0.831465734491354; total time=  25.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.067584\n",
      "[CV] END model__depth=4, model__iterations=510, model__l2_leaf_reg=5, model__learning_rate=0.049401840358420636, model__subsample=0.9582362845013939; total time=   9.2s\n",
      "[RankICScorer] Fold Rank IC = 0.098264\n",
      "[CV] END model__depth=4, model__iterations=510, model__l2_leaf_reg=5, model__learning_rate=0.049401840358420636, model__subsample=0.9582362845013939; total time=   9.2s\n",
      "[RankICScorer] Fold Rank IC = 0.082061\n",
      "[CV] END model__depth=4, model__iterations=510, model__l2_leaf_reg=5, model__learning_rate=0.049401840358420636, model__subsample=0.9582362845013939; total time=   9.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.077295\n",
      "[CV] END model__depth=7, model__iterations=514, model__l2_leaf_reg=4, model__learning_rate=0.0052014797367520545, model__subsample=0.8743997984076751; total time=  13.2s\n",
      "[RankICScorer] Fold Rank IC = 0.101176\n",
      "[CV] END model__depth=7, model__iterations=514, model__l2_leaf_reg=4, model__learning_rate=0.0052014797367520545, model__subsample=0.8743997984076751; total time=  13.2s\n",
      "[RankICScorer] Fold Rank IC = 0.083807\n",
      "[CV] END model__depth=7, model__iterations=514, model__l2_leaf_reg=4, model__learning_rate=0.0052014797367520545, model__subsample=0.8743997984076751; total time=  13.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.076262\n",
      "[CV] END model__depth=4, model__iterations=675, model__l2_leaf_reg=1, model__learning_rate=0.02198675074562575, model__subsample=0.6; total time=  12.3s\n",
      "[RankICScorer] Fold Rank IC = 0.101316\n",
      "[CV] END model__depth=4, model__iterations=675, model__l2_leaf_reg=1, model__learning_rate=0.02198675074562575, model__subsample=0.6; total time=  11.4s\n",
      "[RankICScorer] Fold Rank IC = 0.085284\n",
      "[CV] END model__depth=4, model__iterations=675, model__l2_leaf_reg=1, model__learning_rate=0.02198675074562575, model__subsample=0.6; total time=  12.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.075703\n",
      "[CV] END model__depth=5, model__iterations=1973, model__l2_leaf_reg=5, model__learning_rate=0.005, model__subsample=0.6; total time=  32.4s\n",
      "[RankICScorer] Fold Rank IC = 0.101649\n",
      "[CV] END model__depth=5, model__iterations=1973, model__l2_leaf_reg=5, model__learning_rate=0.005, model__subsample=0.6; total time=  32.3s\n",
      "[RankICScorer] Fold Rank IC = 0.088041\n",
      "[CV] END model__depth=5, model__iterations=1973, model__l2_leaf_reg=5, model__learning_rate=0.005, model__subsample=0.6; total time=  32.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.077259\n",
      "[CV] END model__depth=4, model__iterations=1892, model__l2_leaf_reg=8, model__learning_rate=0.04840868766247768, model__subsample=0.6367330574223569; total time=  26.6s\n",
      "[RankICScorer] Fold Rank IC = 0.103655\n",
      "[CV] END model__depth=4, model__iterations=1892, model__l2_leaf_reg=8, model__learning_rate=0.04840868766247768, model__subsample=0.6367330574223569; total time=  26.7s\n",
      "[RankICScorer] Fold Rank IC = 0.085505\n",
      "[CV] END model__depth=4, model__iterations=1892, model__l2_leaf_reg=8, model__learning_rate=0.04840868766247768, model__subsample=0.6367330574223569; total time=  27.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.075414\n",
      "[CV] END model__depth=9, model__iterations=613, model__l2_leaf_reg=5, model__learning_rate=0.005599884184415394, model__subsample=0.6114168444443656; total time=  18.7s\n",
      "[RankICScorer] Fold Rank IC = 0.102939\n",
      "[CV] END model__depth=9, model__iterations=613, model__l2_leaf_reg=5, model__learning_rate=0.005599884184415394, model__subsample=0.6114168444443656; total time=  19.4s\n",
      "[RankICScorer] Fold Rank IC = 0.092709\n",
      "[CV] END model__depth=9, model__iterations=613, model__l2_leaf_reg=5, model__learning_rate=0.005599884184415394, model__subsample=0.6114168444443656; total time=  19.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.061002\n",
      "[CV] END model__depth=10, model__iterations=1996, model__l2_leaf_reg=10, model__learning_rate=0.042751296703605536, model__subsample=0.6015789889728506; total time= 1.1min\n",
      "[RankICScorer] Fold Rank IC = 0.078852\n",
      "[CV] END model__depth=10, model__iterations=1996, model__l2_leaf_reg=10, model__learning_rate=0.042751296703605536, model__subsample=0.6015789889728506; total time= 1.2min\n",
      "[RankICScorer] Fold Rank IC = 0.072373\n",
      "[CV] END model__depth=10, model__iterations=1996, model__l2_leaf_reg=10, model__learning_rate=0.042751296703605536, model__subsample=0.6015789889728506; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.070167\n",
      "[CV] END model__depth=5, model__iterations=2000, model__l2_leaf_reg=1, model__learning_rate=0.024252228012627056, model__subsample=0.9574138140463664; total time=  32.0s\n",
      "[RankICScorer] Fold Rank IC = 0.104285\n",
      "[CV] END model__depth=5, model__iterations=2000, model__l2_leaf_reg=1, model__learning_rate=0.024252228012627056, model__subsample=0.9574138140463664; total time=  33.3s\n",
      "[RankICScorer] Fold Rank IC = 0.086619\n",
      "[CV] END model__depth=5, model__iterations=2000, model__l2_leaf_reg=1, model__learning_rate=0.024252228012627056, model__subsample=0.9574138140463664; total time=  33.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.074181\n",
      "[CV] END model__depth=8, model__iterations=1527, model__l2_leaf_reg=8, model__learning_rate=0.005, model__subsample=0.6; total time=  38.6s\n",
      "[RankICScorer] Fold Rank IC = 0.102854\n",
      "[CV] END model__depth=8, model__iterations=1527, model__l2_leaf_reg=8, model__learning_rate=0.005, model__subsample=0.6; total time=  39.5s\n",
      "[RankICScorer] Fold Rank IC = 0.094069\n",
      "[CV] END model__depth=8, model__iterations=1527, model__l2_leaf_reg=8, model__learning_rate=0.005, model__subsample=0.6; total time=  40.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.073235\n",
      "[CV] END model__depth=10, model__iterations=500, model__l2_leaf_reg=2, model__learning_rate=0.005, model__subsample=1.0; total time=  18.8s\n",
      "[RankICScorer] Fold Rank IC = 0.100703\n",
      "[CV] END model__depth=10, model__iterations=500, model__l2_leaf_reg=2, model__learning_rate=0.005, model__subsample=1.0; total time=  19.2s\n",
      "[RankICScorer] Fold Rank IC = 0.087308\n",
      "[CV] END model__depth=10, model__iterations=500, model__l2_leaf_reg=2, model__learning_rate=0.005, model__subsample=1.0; total time=  19.5s\n",
      "--- CATBOOST 调优完成, 最佳CV得分: 0.090368 ---\n",
      "最佳参数: {'depth': 8, 'iterations': 1527, 'l2_leaf_reg': 8, 'learning_rate': 0.005, 'subsample': 0.6}\n",
      "\n",
      "--- 4.2 开始为 LGBM 进行贝叶斯优化 ---\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.079483\n",
      "[CV] END model__bagging_fraction=0.7640415835413256, model__feature_fraction=0.89109029727093, model__lambda_l1=2.4877801005599336, model__lambda_l2=6.9533860407670616e-06, model__learning_rate=0.02339472543556369, model__n_estimators=1121, model__num_leaves=66; total time= 1.8min\n",
      "[RankICScorer] Fold Rank IC = 0.113794\n",
      "[CV] END model__bagging_fraction=0.7640415835413256, model__feature_fraction=0.89109029727093, model__lambda_l1=2.4877801005599336, model__lambda_l2=6.9533860407670616e-06, model__learning_rate=0.02339472543556369, model__n_estimators=1121, model__num_leaves=66; total time= 1.7min\n",
      "[RankICScorer] Fold Rank IC = 0.079132\n",
      "[CV] END model__bagging_fraction=0.7640415835413256, model__feature_fraction=0.89109029727093, model__lambda_l1=2.4877801005599336, model__lambda_l2=6.9533860407670616e-06, model__learning_rate=0.02339472543556369, model__n_estimators=1121, model__num_leaves=66; total time= 1.7min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.077695\n",
      "[CV] END model__bagging_fraction=0.9349553422213137, model__feature_fraction=0.9533261109523449, model__lambda_l1=5.3788692675093665e-06, model__lambda_l2=3.6392773904714772, model__learning_rate=0.03656772310794284, model__n_estimators=593, model__num_leaves=38; total time=  34.7s\n",
      "[RankICScorer] Fold Rank IC = 0.114746\n",
      "[CV] END model__bagging_fraction=0.9349553422213137, model__feature_fraction=0.9533261109523449, model__lambda_l1=5.3788692675093665e-06, model__lambda_l2=3.6392773904714772, model__learning_rate=0.03656772310794284, model__n_estimators=593, model__num_leaves=38; total time=  34.9s\n",
      "[RankICScorer] Fold Rank IC = 0.084065\n",
      "[CV] END model__bagging_fraction=0.9349553422213137, model__feature_fraction=0.9533261109523449, model__lambda_l1=5.3788692675093665e-06, model__lambda_l2=3.6392773904714772, model__learning_rate=0.03656772310794284, model__n_estimators=593, model__num_leaves=38; total time=  35.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.075909\n",
      "[CV] END model__bagging_fraction=0.7779330049204607, model__feature_fraction=0.9674890086677508, model__lambda_l1=8.784811093670505e-08, model__lambda_l2=7.943194863182842e-05, model__learning_rate=0.007707706887000696, model__n_estimators=1180, model__num_leaves=40; total time= 1.3min\n",
      "[RankICScorer] Fold Rank IC = 0.114929\n",
      "[CV] END model__bagging_fraction=0.7779330049204607, model__feature_fraction=0.9674890086677508, model__lambda_l1=8.784811093670505e-08, model__lambda_l2=7.943194863182842e-05, model__learning_rate=0.007707706887000696, model__n_estimators=1180, model__num_leaves=40; total time= 1.3min\n",
      "[RankICScorer] Fold Rank IC = 0.094672\n",
      "[CV] END model__bagging_fraction=0.7779330049204607, model__feature_fraction=0.9674890086677508, model__lambda_l1=8.784811093670505e-08, model__lambda_l2=7.943194863182842e-05, model__learning_rate=0.007707706887000696, model__n_estimators=1180, model__num_leaves=40; total time= 1.3min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.077961\n",
      "[CV] END model__bagging_fraction=0.9249583953429453, model__feature_fraction=0.6687486245586243, model__lambda_l1=0.002412257679178859, model__lambda_l2=0.16783519226220392, model__learning_rate=0.01667332948323755, model__n_estimators=643, model__num_leaves=118; total time= 1.4min\n",
      "[RankICScorer] Fold Rank IC = 0.115919\n",
      "[CV] END model__bagging_fraction=0.9249583953429453, model__feature_fraction=0.6687486245586243, model__lambda_l1=0.002412257679178859, model__lambda_l2=0.16783519226220392, model__learning_rate=0.01667332948323755, model__n_estimators=643, model__num_leaves=118; total time= 1.4min\n",
      "[RankICScorer] Fold Rank IC = 0.087973\n",
      "[CV] END model__bagging_fraction=0.9249583953429453, model__feature_fraction=0.6687486245586243, model__lambda_l1=0.002412257679178859, model__lambda_l2=0.16783519226220392, model__learning_rate=0.01667332948323755, model__n_estimators=643, model__num_leaves=118; total time= 1.5min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.076089\n",
      "[CV] END model__bagging_fraction=0.9198213766428692, model__feature_fraction=0.7752116745763693, model__lambda_l1=0.0005490123754862843, model__lambda_l2=0.027632447843676397, model__learning_rate=0.04007025228999773, model__n_estimators=1576, model__num_leaves=75; total time= 2.3min\n",
      "[RankICScorer] Fold Rank IC = 0.105233\n",
      "[CV] END model__bagging_fraction=0.9198213766428692, model__feature_fraction=0.7752116745763693, model__lambda_l1=0.0005490123754862843, model__lambda_l2=0.027632447843676397, model__learning_rate=0.04007025228999773, model__n_estimators=1576, model__num_leaves=75; total time= 2.3min\n",
      "[RankICScorer] Fold Rank IC = 0.073834\n",
      "[CV] END model__bagging_fraction=0.9198213766428692, model__feature_fraction=0.7752116745763693, model__lambda_l1=0.0005490123754862843, model__lambda_l2=0.027632447843676397, model__learning_rate=0.04007025228999773, model__n_estimators=1576, model__num_leaves=75; total time= 2.3min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.075698\n",
      "[CV] END model__bagging_fraction=0.8936112071942273, model__feature_fraction=0.9757478950411087, model__lambda_l1=2.96800485998608e-07, model__lambda_l2=4.963952600592636e-07, model__learning_rate=0.03158444397400415, model__n_estimators=1059, model__num_leaves=80; total time= 1.6min\n",
      "[RankICScorer] Fold Rank IC = 0.108800\n",
      "[CV] END model__bagging_fraction=0.8936112071942273, model__feature_fraction=0.9757478950411087, model__lambda_l1=2.96800485998608e-07, model__lambda_l2=4.963952600592636e-07, model__learning_rate=0.03158444397400415, model__n_estimators=1059, model__num_leaves=80; total time= 1.7min\n",
      "[RankICScorer] Fold Rank IC = 0.077844\n",
      "[CV] END model__bagging_fraction=0.8936112071942273, model__feature_fraction=0.9757478950411087, model__lambda_l1=2.96800485998608e-07, model__lambda_l2=4.963952600592636e-07, model__learning_rate=0.03158444397400415, model__n_estimators=1059, model__num_leaves=80; total time= 1.8min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.079106\n",
      "[CV] END model__bagging_fraction=0.8468317434009265, model__feature_fraction=0.9101457515311531, model__lambda_l1=1.702967607722994e-05, model__lambda_l2=0.739482086614497, model__learning_rate=0.019569948358746023, model__n_estimators=1392, model__num_leaves=104; total time= 2.8min\n",
      "[RankICScorer] Fold Rank IC = 0.109350\n",
      "[CV] END model__bagging_fraction=0.8468317434009265, model__feature_fraction=0.9101457515311531, model__lambda_l1=1.702967607722994e-05, model__lambda_l2=0.739482086614497, model__learning_rate=0.019569948358746023, model__n_estimators=1392, model__num_leaves=104; total time= 2.8min\n",
      "[RankICScorer] Fold Rank IC = 0.079002\n",
      "[CV] END model__bagging_fraction=0.8468317434009265, model__feature_fraction=0.9101457515311531, model__lambda_l1=1.702967607722994e-05, model__lambda_l2=0.739482086614497, model__learning_rate=0.019569948358746023, model__n_estimators=1392, model__num_leaves=104; total time= 2.8min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.076775\n",
      "[CV] END model__bagging_fraction=0.817361227076125, model__feature_fraction=0.9680036905749265, model__lambda_l1=0.00029390050504238995, model__lambda_l2=0.34586604961698086, model__learning_rate=0.010544597008879638, model__n_estimators=577, model__num_leaves=94; total time= 1.1min\n",
      "[RankICScorer] Fold Rank IC = 0.113878\n",
      "[CV] END model__bagging_fraction=0.817361227076125, model__feature_fraction=0.9680036905749265, model__lambda_l1=0.00029390050504238995, model__lambda_l2=0.34586604961698086, model__learning_rate=0.010544597008879638, model__n_estimators=577, model__num_leaves=94; total time= 1.2min\n",
      "[RankICScorer] Fold Rank IC = 0.091010\n",
      "[CV] END model__bagging_fraction=0.817361227076125, model__feature_fraction=0.9680036905749265, model__lambda_l1=0.00029390050504238995, model__lambda_l2=0.34586604961698086, model__learning_rate=0.010544597008879638, model__n_estimators=577, model__num_leaves=94; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.074740\n",
      "[CV] END model__bagging_fraction=0.9821911945239713, model__feature_fraction=0.8802485778485464, model__lambda_l1=0.6996282803033609, model__lambda_l2=5.525731625462062e-05, model__learning_rate=0.012023606904247704, model__n_estimators=817, model__num_leaves=20; total time=  34.1s\n",
      "[RankICScorer] Fold Rank IC = 0.115588\n",
      "[CV] END model__bagging_fraction=0.9821911945239713, model__feature_fraction=0.8802485778485464, model__lambda_l1=0.6996282803033609, model__lambda_l2=5.525731625462062e-05, model__learning_rate=0.012023606904247704, model__n_estimators=817, model__num_leaves=20; total time=  36.6s\n",
      "[RankICScorer] Fold Rank IC = 0.098257\n",
      "[CV] END model__bagging_fraction=0.9821911945239713, model__feature_fraction=0.8802485778485464, model__lambda_l1=0.6996282803033609, model__lambda_l2=5.525731625462062e-05, model__learning_rate=0.012023606904247704, model__n_estimators=817, model__num_leaves=20; total time=  36.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.078450\n",
      "[CV] END model__bagging_fraction=0.6014521229018973, model__feature_fraction=0.9271320078655007, model__lambda_l1=0.04694017445221059, model__lambda_l2=1.95428689959168e-06, model__learning_rate=0.018951096390644438, model__n_estimators=912, model__num_leaves=61; total time= 1.2min\n",
      "[RankICScorer] Fold Rank IC = 0.113528\n",
      "[CV] END model__bagging_fraction=0.6014521229018973, model__feature_fraction=0.9271320078655007, model__lambda_l1=0.04694017445221059, model__lambda_l2=1.95428689959168e-06, model__learning_rate=0.018951096390644438, model__n_estimators=912, model__num_leaves=61; total time= 1.2min\n",
      "[RankICScorer] Fold Rank IC = 0.087197\n",
      "[CV] END model__bagging_fraction=0.6014521229018973, model__feature_fraction=0.9271320078655007, model__lambda_l1=0.04694017445221059, model__lambda_l2=1.95428689959168e-06, model__learning_rate=0.018951096390644438, model__n_estimators=912, model__num_leaves=61; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.075621\n",
      "[CV] END model__bagging_fraction=0.9265593603518726, model__feature_fraction=0.6174105803317927, model__lambda_l1=10.0, model__lambda_l2=1.1247946196538077, model__learning_rate=0.005, model__n_estimators=1724, model__num_leaves=20; total time= 1.4min\n",
      "[RankICScorer] Fold Rank IC = 0.119200\n",
      "[CV] END model__bagging_fraction=0.9265593603518726, model__feature_fraction=0.6174105803317927, model__lambda_l1=10.0, model__lambda_l2=1.1247946196538077, model__learning_rate=0.005, model__n_estimators=1724, model__num_leaves=20; total time= 1.5min\n",
      "[RankICScorer] Fold Rank IC = 0.100438\n",
      "[CV] END model__bagging_fraction=0.9265593603518726, model__feature_fraction=0.6174105803317927, model__lambda_l1=10.0, model__lambda_l2=1.1247946196538077, model__learning_rate=0.005, model__n_estimators=1724, model__num_leaves=20; total time= 1.5min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.078894\n",
      "[CV] END model__bagging_fraction=0.8679175431143602, model__feature_fraction=0.9975907113114686, model__lambda_l1=0.0008369613065580144, model__lambda_l2=2.0718099560492877, model__learning_rate=0.005535768108877343, model__n_estimators=1983, model__num_leaves=149; total time= 5.5min\n",
      "[RankICScorer] Fold Rank IC = 0.111081\n",
      "[CV] END model__bagging_fraction=0.8679175431143602, model__feature_fraction=0.9975907113114686, model__lambda_l1=0.0008369613065580144, model__lambda_l2=2.0718099560492877, model__learning_rate=0.005535768108877343, model__n_estimators=1983, model__num_leaves=149; total time= 5.5min\n",
      "[RankICScorer] Fold Rank IC = 0.087104\n",
      "[CV] END model__bagging_fraction=0.8679175431143602, model__feature_fraction=0.9975907113114686, model__lambda_l1=0.0008369613065580144, model__lambda_l2=2.0718099560492877, model__learning_rate=0.005535768108877343, model__n_estimators=1983, model__num_leaves=149; total time= 5.5min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.066213\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=4.3250181484642555e-08, model__learning_rate=0.005, model__n_estimators=500, model__num_leaves=20; total time=  24.7s\n",
      "[RankICScorer] Fold Rank IC = 0.111336\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=4.3250181484642555e-08, model__learning_rate=0.005, model__n_estimators=500, model__num_leaves=20; total time=  25.1s\n",
      "[RankICScorer] Fold Rank IC = 0.103277\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=4.3250181484642555e-08, model__learning_rate=0.005, model__n_estimators=500, model__num_leaves=20; total time=  25.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.073814\n",
      "[CV] END model__bagging_fraction=0.8348616479108815, model__feature_fraction=0.6, model__lambda_l1=1e-08, model__lambda_l2=1e-08, model__learning_rate=0.005, model__n_estimators=2000, model__num_leaves=20; total time= 1.5min\n",
      "[RankICScorer] Fold Rank IC = 0.116719\n",
      "[CV] END model__bagging_fraction=0.8348616479108815, model__feature_fraction=0.6, model__lambda_l1=1e-08, model__lambda_l2=1e-08, model__learning_rate=0.005, model__n_estimators=2000, model__num_leaves=20; total time= 1.5min\n",
      "[RankICScorer] Fold Rank IC = 0.097477\n",
      "[CV] END model__bagging_fraction=0.8348616479108815, model__feature_fraction=0.6, model__lambda_l1=1e-08, model__lambda_l2=1e-08, model__learning_rate=0.005, model__n_estimators=2000, model__num_leaves=20; total time= 1.5min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.078965\n",
      "[CV] END model__bagging_fraction=0.9302400187486589, model__feature_fraction=0.8719585867994377, model__lambda_l1=2.2285317145978714, model__lambda_l2=6.121330105743085e-05, model__learning_rate=0.010264539633363103, model__n_estimators=1926, model__num_leaves=21; total time= 1.4min\n",
      "[RankICScorer] Fold Rank IC = 0.117039\n",
      "[CV] END model__bagging_fraction=0.9302400187486589, model__feature_fraction=0.8719585867994377, model__lambda_l1=2.2285317145978714, model__lambda_l2=6.121330105743085e-05, model__learning_rate=0.010264539633363103, model__n_estimators=1926, model__num_leaves=21; total time= 1.4min\n",
      "[RankICScorer] Fold Rank IC = 0.089924\n",
      "[CV] END model__bagging_fraction=0.9302400187486589, model__feature_fraction=0.8719585867994377, model__lambda_l1=2.2285317145978714, model__lambda_l2=6.121330105743085e-05, model__learning_rate=0.010264539633363103, model__n_estimators=1926, model__num_leaves=21; total time= 1.5min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.075829\n",
      "[CV] END model__bagging_fraction=0.7008332941303874, model__feature_fraction=0.6165808174253007, model__lambda_l1=0.4637375773436086, model__lambda_l2=6.458812449872504e-05, model__learning_rate=0.005016259740001992, model__n_estimators=964, model__num_leaves=139; total time= 2.7min\n",
      "[RankICScorer] Fold Rank IC = 0.116553\n",
      "[CV] END model__bagging_fraction=0.7008332941303874, model__feature_fraction=0.6165808174253007, model__lambda_l1=0.4637375773436086, model__lambda_l2=6.458812449872504e-05, model__learning_rate=0.005016259740001992, model__n_estimators=964, model__num_leaves=139; total time= 2.7min\n",
      "[RankICScorer] Fold Rank IC = 0.089543\n",
      "[CV] END model__bagging_fraction=0.7008332941303874, model__feature_fraction=0.6165808174253007, model__lambda_l1=0.4637375773436086, model__lambda_l2=6.458812449872504e-05, model__learning_rate=0.005016259740001992, model__n_estimators=964, model__num_leaves=139; total time= 2.7min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.077619\n",
      "[CV] END model__bagging_fraction=0.6029141317717479, model__feature_fraction=0.8342938750132884, model__lambda_l1=1.0829174418179786, model__lambda_l2=0.0001129788895260049, model__learning_rate=0.04935469198846786, model__n_estimators=551, model__num_leaves=138; total time= 1.3min\n",
      "[RankICScorer] Fold Rank IC = 0.108034\n",
      "[CV] END model__bagging_fraction=0.6029141317717479, model__feature_fraction=0.8342938750132884, model__lambda_l1=1.0829174418179786, model__lambda_l2=0.0001129788895260049, model__learning_rate=0.04935469198846786, model__n_estimators=551, model__num_leaves=138; total time= 1.3min\n",
      "[RankICScorer] Fold Rank IC = 0.075827\n",
      "[CV] END model__bagging_fraction=0.6029141317717479, model__feature_fraction=0.8342938750132884, model__lambda_l1=1.0829174418179786, model__lambda_l2=0.0001129788895260049, model__learning_rate=0.04935469198846786, model__n_estimators=551, model__num_leaves=138; total time= 1.4min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.077079\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=10.0, model__learning_rate=0.007624167098566579, model__n_estimators=1411, model__num_leaves=20; total time= 1.1min\n",
      "[RankICScorer] Fold Rank IC = 0.119938\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=10.0, model__learning_rate=0.007624167098566579, model__n_estimators=1411, model__num_leaves=20; total time= 1.2min\n",
      "[RankICScorer] Fold Rank IC = 0.099345\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=10.0, model__learning_rate=0.007624167098566579, model__n_estimators=1411, model__num_leaves=20; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.074558\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=10.0, model__learning_rate=0.005108683550944975, model__n_estimators=1376, model__num_leaves=20; total time= 1.1min\n",
      "[RankICScorer] Fold Rank IC = 0.118086\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=10.0, model__learning_rate=0.005108683550944975, model__n_estimators=1376, model__num_leaves=20; total time= 1.2min\n",
      "[RankICScorer] Fold Rank IC = 0.102986\n",
      "[CV] END model__bagging_fraction=0.6, model__feature_fraction=0.6, model__lambda_l1=10.0, model__lambda_l2=10.0, model__learning_rate=0.005108683550944975, model__n_estimators=1376, model__num_leaves=20; total time= 1.2min\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[RankICScorer] Fold Rank IC = 0.074968\n",
      "[CV] END model__bagging_fraction=0.787285037192588, model__feature_fraction=0.6666004924084658, model__lambda_l1=9.824329639479371, model__lambda_l2=1.867339644513464e-07, model__learning_rate=0.015822651281056116, model__n_estimators=1990, model__num_leaves=140; total time= 5.7min\n",
      "[RankICScorer] Fold Rank IC = 0.108607\n",
      "[CV] END model__bagging_fraction=0.787285037192588, model__feature_fraction=0.6666004924084658, model__lambda_l1=9.824329639479371, model__lambda_l2=1.867339644513464e-07, model__learning_rate=0.015822651281056116, model__n_estimators=1990, model__num_leaves=140; total time= 5.8min\n",
      "[RankICScorer] Fold Rank IC = 0.074159\n",
      "[CV] END model__bagging_fraction=0.787285037192588, model__feature_fraction=0.6666004924084658, model__lambda_l1=9.824329639479371, model__lambda_l2=1.867339644513464e-07, model__learning_rate=0.015822651281056116, model__n_estimators=1990, model__num_leaves=140; total time= 5.9min\n",
      "--- LGBM 调优完成, 最佳CV得分: 0.098787 ---\n",
      "最佳参数: {'bagging_fraction': 0.6, 'feature_fraction': 0.6, 'lambda_l1': 10.0, 'lambda_l2': 10.0, 'learning_rate': 0.007624167098566579, 'n_estimators': 1411, 'num_leaves': 20}\n",
      "\n",
      "--- 5. 使用最优参数在最终训练集上训练模型 ---\n",
      "正在训练并预测 XGB 模型...\n",
      "XGB 预测完成。\n",
      "正在训练并预测 CATBOOST 模型...\n",
      "CATBOOST 预测完成。\n",
      "正在训练并预测 LGBM 模型...\n",
      "LGBM 预测完成。\n",
      "\n",
      "--- 6. 使用简单平均法集成并生成最终提交文件 ---\n",
      "提交文件 'submission_pipeline_v22_fix.csv' 已生成.\n",
      "   id    code  date    y_pred\n",
      "0   0     s_0  1691  0.014404\n",
      "1   1     s_1  1691 -0.034684\n",
      "2   2    s_10  1691  0.010922\n",
      "3   3   s_100  1691  0.008763\n",
      "4   4  s_1001  1691  0.009156\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:16:12.260606Z",
     "start_time": "2025-07-30T10:37:45.009325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === 模型训练管道 v23.4 (已修复XGBoost早停) ===\n",
    "# 核心变更:\n",
    "# 1. 在贝叶斯优化中移除了对 n_estimators/iterations 的搜索，因为最终轮数由早停机制确定。\n",
    "# 2. 最终训练窗口为300天。\n",
    "# 3. 交叉验证为2折，每折训练期300天。\n",
    "# 4. 引入早停机制：在最近300天数据中，用前200天训练、后100天验证来找到最佳迭代次数，然后用此轮数在完整的300天数据上重新训练。\n",
    "# 5. [修正] 使用 XGBoost 的 callback 接口实现早停，以解决 TypeError。\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import os\n",
    "import gc\n",
    "import polars as pl\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn & Scikit-optimize Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import BayesSearchCV\n",
    "from xgboost.callback import EarlyStopping # <--- 修正: 导入XGBoost的EarlyStopping回调\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def calculate_rank_ic_polars(y_true, y_pred, dates):\n",
    "    \"\"\"使用Polars高效计算Rank IC\"\"\"\n",
    "    if isinstance(y_true, pd.Series): y_true = y_true.to_numpy()\n",
    "    if isinstance(y_pred, pd.Series): y_pred = y_pred.to_numpy()\n",
    "    if isinstance(dates, pd.Series): dates = dates.to_numpy()\n",
    "\n",
    "    df = pl.DataFrame({'y_true': y_true, 'y_pred': y_pred, 'date': dates})\n",
    "    daily_ic = df.group_by('date', maintain_order=True).agg(\n",
    "        pl.corr('y_true', 'y_pred', method='spearman').fill_nan(0.0).alias('ic')\n",
    "    )\n",
    "    return daily_ic['ic'].mean()\n",
    "\n",
    "class RankICScorer:\n",
    "    \"\"\"一个与scikit-learn兼容的自定义评分器\"\"\"\n",
    "    def __init__(self, dates: pd.Series):\n",
    "        self.dates = dates.reset_index(drop=True)\n",
    "\n",
    "    def __call__(self, estimator, X, y_true) -> float:\n",
    "        fold_dates = self.dates.iloc[X.index]\n",
    "        y_pred = estimator.predict(X)\n",
    "        rank_ic = calculate_rank_ic_polars(y_true, y_pred, fold_dates)\n",
    "        print(f\"[RankICScorer] Fold Rank IC = {rank_ic:.6f}\")\n",
    "        return rank_ic if np.isfinite(rank_ic) else 0.0\n",
    "\n",
    "# --- 自定义重叠滑动窗口交叉验证 ---\n",
    "def sliding_window_cv(dates, n_splits=5, train_days=300, test_days=150, step_days=100):\n",
    "    \"\"\"生成重叠的、向前滚动的滑动窗口交叉验证索引\"\"\"\n",
    "    unique_dates = sorted(dates.unique())\n",
    "    last_split_test_end_idx = (n_splits - 1) * step_days + train_days + test_days\n",
    "\n",
    "    if len(unique_dates) < last_split_test_end_idx:\n",
    "        raise ValueError(\n",
    "            f\"数据不足以创建{n_splits}个重叠滑动窗口。\"\n",
    "            f\"需要 {last_split_test_end_idx} 天, 但只有 {len(unique_dates)} 天。\"\n",
    "        )\n",
    "\n",
    "    print(f\"--- 创建重叠滑动窗口 (训练={train_days}天, 验证={test_days}天, 步长={step_days}天, 共{n_splits}折) ---\")\n",
    "    for i in range(n_splits):\n",
    "        train_start_idx = i * step_days\n",
    "        train_end_idx = train_start_idx + train_days\n",
    "        test_start_idx = train_end_idx\n",
    "        test_end_idx = test_start_idx + test_days\n",
    "        train_dates = unique_dates[train_start_idx : train_end_idx]\n",
    "        test_dates = unique_dates[test_start_idx : test_end_idx]\n",
    "        print(f\"Fold {i+1}: Train on {train_dates[0]} to {train_dates[-1]}, \"\n",
    "              f\"Validate on {test_dates[0]} to {test_dates[-1]}\")\n",
    "        train_mask = dates.isin(train_dates)\n",
    "        test_mask = dates.isin(test_dates)\n",
    "        yield dates[train_mask].index.to_numpy(), dates[test_mask].index.to_numpy()\n",
    "\n",
    "# --- 1. 核心特征工程 ---\n",
    "def preprocess_and_rank(df):\n",
    "    \"\"\"截面排名特征\"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ['code', 'date']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    float_cols = [c for c in df.columns if df[c].dtype == 'float64']\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    pl_df = pl.from_pandas(df)\n",
    "    feature_cols = [col for col in df.columns if col.startswith('f_')]\n",
    "    pl_df = pl_df.with_columns([\n",
    "        ((pl.col(feature).rank(method='ordinal').over('date') - 1) / (pl.col(feature).count().over('date') - 1)).alias(feature)\n",
    "        for feature in feature_cols\n",
    "    ])\n",
    "    final_df = pl_df.to_pandas()\n",
    "    final_df.fillna(0.5, inplace=True)\n",
    "    return final_df\n",
    "\n",
    "# --- 2. 主执行流程 ---\n",
    "def main():\n",
    "    print(\"--- 正在加载数据 ---\")\n",
    "    DATA_PATH = './stocks-return-prediction'\n",
    "    train_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'train_data9.pkl'))\n",
    "    test_df_raw = pd.read_pickle(os.path.join(DATA_PATH, 'test_data9.pkl'))\n",
    "\n",
    "    print(\"\\n--- 1. 核心特征工程 (仅截面排名) ---\")\n",
    "    train_df = preprocess_and_rank(train_df_raw.copy())\n",
    "    test_df = preprocess_and_rank(test_df_raw.copy())\n",
    "    train_df.sort_values(by=['date', 'code'], inplace=True, ignore_index=True)\n",
    "    test_df.sort_values(by=['date', 'code'], inplace=True, ignore_index=True)\n",
    "    del train_df_raw\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"\\n--- 2. 数据集划分 ---\")\n",
    "    unique_dates = sorted(train_df['date'].unique())\n",
    "\n",
    "    # 最终训练集：最新的300天\n",
    "    train_final_start_date = unique_dates[-300]\n",
    "    train_final_df = train_df[train_df['date'] >= train_final_start_date].copy()\n",
    "\n",
    "    # 超参数搜索集：最新的700天 (4*100步长 + 200训练 + 100验证 = 700天)\n",
    "    search_start_date = unique_dates[-700]\n",
    "    search_df = train_df[train_df['date'] >= search_start_date].copy()\n",
    "\n",
    "    print(f\"超参数搜索集: {search_df['date'].min()} - {search_df['date'].max()} ({search_df['date'].nunique()} 天)\")\n",
    "    print(f\"最终训练集: {train_final_df['date'].min()} - {train_final_df['date'].max()} ({train_final_df['date'].nunique()} 天)\")\n",
    "\n",
    "    features = [col for col in train_df.columns if col.startswith('f_')]\n",
    "    print(f\"\\n--- 3. 使用全部 {len(features)} 个初始特征进行训练 ---\")\n",
    "\n",
    "    # --- 4. 独立调优三驾马车模型 ---\n",
    "    search_df.reset_index(drop=True, inplace=True)\n",
    "    X_search, y_search = search_df[features], search_df['y']\n",
    "\n",
    "    custom_cv = list(sliding_window_cv(search_df['date'], n_splits=2, train_days=300, test_days=150, step_days=150))\n",
    "    rank_ic_scorer = RankICScorer(dates=search_df['date'])\n",
    "\n",
    "    models_to_tune = ['xgb', 'catboost', 'lgbm']\n",
    "    best_params_all = {}\n",
    "\n",
    "    for model_name in models_to_tune:\n",
    "        print(f\"\\n--- 4.{models_to_tune.index(model_name)+1} 开始为 {model_name.upper()} 进行贝叶斯优化 ---\")\n",
    "        # 为模型设置一个固定的、足够大的迭代次数，让优化器专注于其他参数\n",
    "        fixed_iterations = 2000\n",
    "\n",
    "        if model_name == 'xgb':\n",
    "            model = xgb.XGBRegressor(n_estimators=fixed_iterations, random_state=42, tree_method='gpu_hist', n_jobs=-1)\n",
    "            search_spaces = {\n",
    "                'learning_rate': (0.005, 0.05, 'log-uniform'), 'max_depth': (3, 10),\n",
    "                'subsample': (0.6, 1.0, 'uniform'), 'colsample_bytree': (0.6, 1.0, 'uniform'), 'min_child_weight': (1, 20)\n",
    "            }\n",
    "        elif model_name == 'catboost':\n",
    "            model = cb.CatBoostRegressor(iterations=fixed_iterations, random_state=42, verbose=0, allow_writing_files=False, task_type='GPU', bootstrap_type='MVS')\n",
    "            search_spaces = {\n",
    "                'learning_rate': (0.005, 0.05, 'log-uniform'), 'depth': (4, 10),\n",
    "                'l2_leaf_reg': (1, 10, 'uniform'), 'subsample': (0.6, 1.0, 'uniform')\n",
    "            }\n",
    "        elif model_name == 'lgbm':\n",
    "            model = lgb.LGBMRegressor(n_estimators=fixed_iterations, random_state=42, device='gpu', n_jobs=-1, verbose=-1)\n",
    "            search_spaces = {\n",
    "                'learning_rate': (0.005, 0.05, 'log-uniform'), 'num_leaves': (20, 150),\n",
    "                'feature_fraction': (0.6, 1.0, 'uniform'), 'bagging_fraction': (0.6, 1.0, 'uniform'),\n",
    "                'lambda_l1': (1e-8, 10.0, 'log-uniform'), 'lambda_l2': (1e-8, 10.0, 'log-uniform')\n",
    "            }\n",
    "\n",
    "        pipeline = Pipeline([('scaler', MinMaxScaler()), ('model', model)])\n",
    "        prefixed_search_spaces = {f'model__{k}': v for k, v in search_spaces.items()}\n",
    "        search = BayesSearchCV(\n",
    "            estimator=pipeline, search_spaces=prefixed_search_spaces,\n",
    "            n_iter=10, scoring=rank_ic_scorer, cv=custom_cv,\n",
    "            random_state=42, n_jobs=1, verbose=2\n",
    "        )\n",
    "        search.fit(X_search, y_search)\n",
    "        best_params_all[model_name] = {k.replace('model__', ''): v for k, v in search.best_params_.items()}\n",
    "        print(f\"--- {model_name.upper()} 调优完成, 最佳CV得分: {search.best_score_:.6f} ---\")\n",
    "        print(f\"最佳参数: {best_params_all[model_name]}\")\n",
    "\n",
    "    # --- 5. 使用最优参数和早停机制训练最终模型 ---\n",
    "    print(\"\\n--- 5. 使用最优参数和早停机制在最终训练集上训练模型 ---\")\n",
    "    X_train_final, y_train_final = train_final_df[features], train_final_df['y']\n",
    "    X_test_final = test_df[features]\n",
    "\n",
    "    # 为早停机制划分数据：在最近300天的数据中，用前200天训练，后100天验证\n",
    "    es_split_date = unique_dates[-100]\n",
    "    train_es_mask = train_final_df['date'] < es_split_date\n",
    "    eval_es_mask = train_final_df['date'] >= es_split_date\n",
    "\n",
    "    X_train_es, y_train_es = X_train_final[train_es_mask], y_train_final[train_es_mask]\n",
    "    X_eval_es, y_eval_es = X_train_final[eval_es_mask], y_train_final[eval_es_mask]\n",
    "\n",
    "    print(f\"早停训练集: {train_final_df[train_es_mask]['date'].min()} - {train_final_df[train_es_mask]['date'].max()} ({train_final_df[train_es_mask]['date'].nunique()} 天)\")\n",
    "    print(f\"早停验证集: {train_final_df[eval_es_mask]['date'].min()} - {train_final_df[eval_es_mask]['date'].max()} ({train_final_df[eval_es_mask]['date'].nunique()} 天)\")\n",
    "\n",
    "    test_predictions = []\n",
    "\n",
    "    for model_name in models_to_tune:\n",
    "        print(f\"\\n--- 正在为 {model_name.upper()} 模型寻找最佳迭代次数 ---\")\n",
    "        params = best_params_all[model_name].copy()\n",
    "\n",
    "        # scaler需要单独fit和transform，以便正确准备eval_set\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_es_scaled = scaler.fit_transform(X_train_es)\n",
    "        X_eval_es_scaled = scaler.transform(X_eval_es)\n",
    "\n",
    "        best_iteration = 0\n",
    "\n",
    "        if model_name == 'xgb':\n",
    "            # 这里的n_estimators也设置为一个大数，让早停来决定最终值\n",
    "            model = xgb.XGBRegressor(n_estimators=fixed_iterations, random_state=42, tree_method='gpu_hist', n_jobs=-1, **params)\n",
    "\n",
    "            # --- 修正: 使用回调函数进行早停 ---\n",
    "            model.fit(X_train_es_scaled, y_train_es,\n",
    "                      eval_set=[(X_eval_es_scaled, y_eval_es)],\n",
    "                      callbacks=[EarlyStopping(rounds=50, save_best=True)],\n",
    "                      verbose=False)\n",
    "\n",
    "            # --- 修正: 使用 model.best_ntree_limit 获取最佳迭代次数 ---\n",
    "            best_iteration = model.best_ntree_limit\n",
    "            params['n_estimators'] = best_iteration\n",
    "            final_model = xgb.XGBRegressor(random_state=42, tree_method='gpu_hist', n_jobs=-1, **params)\n",
    "\n",
    "        elif model_name == 'catboost':\n",
    "            model = cb.CatBoostRegressor(iterations=fixed_iterations, random_state=42, allow_writing_files=False, task_type='GPU', bootstrap_type='MVS', **params)\n",
    "            model.fit(X_train_es_scaled, y_train_es,\n",
    "                      eval_set=[(X_eval_es_scaled, y_eval_es)],\n",
    "                      early_stopping_rounds=50, verbose=0)\n",
    "            best_iteration = model.get_best_iteration()\n",
    "            params['iterations'] = best_iteration\n",
    "            final_model = cb.CatBoostRegressor(random_state=42, verbose=0, allow_writing_files=False, task_type='GPU', bootstrap_type='MVS', **params)\n",
    "\n",
    "        elif model_name == 'lgbm':\n",
    "            model = lgb.LGBMRegressor(n_estimators=fixed_iterations, random_state=42, device='gpu', n_jobs=-1, verbose=-1, **params)\n",
    "            # 假设使用 lightgbm >= 4.0.0，回调是推荐方式\n",
    "            model.fit(X_train_es_scaled, y_train_es,\n",
    "                      eval_set=[(X_eval_es_scaled, y_eval_es)],\n",
    "                      callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "            best_iteration = model.best_iteration_\n",
    "            params['n_estimators'] = best_iteration\n",
    "            final_model = lgb.LGBMRegressor(random_state=42, device='gpu', n_jobs=-1, verbose=-1, **params)\n",
    "\n",
    "        print(f\"找到最佳迭代次数: {best_iteration}\")\n",
    "        print(f\"--- 使用 {best_iteration} 轮在完整的300天数据上重新训练 {model_name.upper()} ---\")\n",
    "        final_pipeline = Pipeline([('scaler', MinMaxScaler()), ('model', final_model)])\n",
    "        final_pipeline.fit(X_train_final, y_train_final)\n",
    "\n",
    "        test_predictions.append(final_pipeline.predict(X_test_final))\n",
    "        print(f\"{model_name.upper()} 预测完成。\")\n",
    "\n",
    "    # --- 6. 生成最终提交文件 (简单平均集成) ---\n",
    "    print(\"\\n--- 6. 使用简单平均法集成并生成最终提交文件 ---\")\n",
    "    ensemble_prediction = np.mean(test_predictions, axis=0)\n",
    "\n",
    "    submission_df = test_df[['code', 'date']].copy()\n",
    "    submission_df['y_pred'] = ensemble_prediction\n",
    "    submission_df.reset_index(inplace=True)\n",
    "    submission_df.rename(columns={'index': 'id'}, inplace=True)\n",
    "    submission_df = submission_df[['id', 'code', 'date', 'y_pred']]\n",
    "\n",
    "    submission_df.to_csv('submission_pipeline_v23_es_fix.csv', index=False)\n",
    "    print(\"提交文件 'submission_pipeline_v23_es_fix.csv' 已生成.\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "7252fb54d3d7f5ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在加载数据 ---\n",
      "\n",
      "--- 1. 核心特征工程 (仅截面排名) ---\n",
      "\n",
      "--- 2. 数据集划分 ---\n",
      "超参数搜索集: 991 - 1690 (700 天)\n",
      "最终训练集: 1391 - 1690 (300 天)\n",
      "\n",
      "--- 3. 使用全部 28 个初始特征进行训练 ---\n",
      "--- 创建重叠滑动窗口 (训练=300天, 验证=150天, 步长=150天, 共2折) ---\n",
      "Fold 1: Train on 991 to 1290, Validate on 1291 to 1440\n",
      "Fold 2: Train on 1141 to 1440, Validate on 1441 to 1590\n",
      "\n",
      "--- 4.1 开始为 XGB 进行贝叶斯优化 ---\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.076353\n",
      "[CV] END model__colsample_bytree=0.7640415835413256, model__learning_rate=0.026711344437355546, model__max_depth=10, model__min_child_weight=7, model__subsample=0.8680591793075738; total time= 1.2min\n",
      "[RankICScorer] Fold Rank IC = 0.100175\n",
      "[CV] END model__colsample_bytree=0.7640415835413256, model__learning_rate=0.026711344437355546, model__max_depth=10, model__min_child_weight=7, model__subsample=0.8680591793075738; total time= 1.2min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.081712\n",
      "[CV] END model__colsample_bytree=0.9349553422213137, model__learning_rate=0.03821952468883263, model__max_depth=5, model__min_child_weight=19, model__subsample=0.9456511661859803; total time=  22.1s\n",
      "[RankICScorer] Fold Rank IC = 0.110251\n",
      "[CV] END model__colsample_bytree=0.9349553422213137, model__learning_rate=0.03821952468883263, model__max_depth=5, model__min_child_weight=19, model__subsample=0.9456511661859803; total time=  25.1s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.084926\n",
      "[CV] END model__colsample_bytree=0.7779330049204607, model__learning_rate=0.0414660365353187, model__max_depth=4, model__min_child_weight=9, model__subsample=0.6751820745469395; total time=  25.5s\n",
      "[RankICScorer] Fold Rank IC = 0.116892\n",
      "[CV] END model__colsample_bytree=0.7779330049204607, model__learning_rate=0.0414660365353187, model__max_depth=4, model__min_child_weight=9, model__subsample=0.6751820745469395; total time=  26.0s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.089455\n",
      "[CV] END model__colsample_bytree=0.9249583953429453, model__learning_rate=0.007427481277233235, model__max_depth=7, model__min_child_weight=16, model__subsample=0.8092209312217534; total time=  36.5s\n",
      "[RankICScorer] Fold Rank IC = 0.122923\n",
      "[CV] END model__colsample_bytree=0.9249583953429453, model__learning_rate=0.007427481277233235, model__max_depth=7, model__min_child_weight=16, model__subsample=0.8092209312217534; total time=  36.6s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.084807\n",
      "[CV] END model__colsample_bytree=0.9198213766428692, model__learning_rate=0.013708792117964526, model__max_depth=7, model__min_child_weight=15, model__subsample=0.9615408290026747; total time=  37.6s\n",
      "[RankICScorer] Fold Rank IC = 0.115911\n",
      "[CV] END model__colsample_bytree=0.9198213766428692, model__learning_rate=0.013708792117964526, model__max_depth=7, model__min_child_weight=15, model__subsample=0.9615408290026747; total time=  34.7s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.082887\n",
      "[CV] END model__colsample_bytree=0.8936112071942273, model__learning_rate=0.04348502678703971, model__max_depth=4, model__min_child_weight=5, model__subsample=0.920201292582698; total time=  24.5s\n",
      "[RankICScorer] Fold Rank IC = 0.115799\n",
      "[CV] END model__colsample_bytree=0.8936112071942273, model__learning_rate=0.04348502678703971, model__max_depth=4, model__min_child_weight=5, model__subsample=0.920201292582698; total time=  25.6s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.080623\n",
      "[CV] END model__colsample_bytree=0.8468317434009265, model__learning_rate=0.029808106083955625, model__max_depth=6, model__min_child_weight=18, model__subsample=0.8370478701222271; total time=  29.5s\n",
      "[RankICScorer] Fold Rank IC = 0.109750\n",
      "[CV] END model__colsample_bytree=0.8468317434009265, model__learning_rate=0.029808106083955625, model__max_depth=6, model__min_child_weight=18, model__subsample=0.8370478701222271; total time=  28.9s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.078572\n",
      "[CV] END model__colsample_bytree=0.817361227076125, model__learning_rate=0.04158907209132091, model__max_depth=6, model__min_child_weight=17, model__subsample=0.7296239929137495; total time=  29.1s\n",
      "[RankICScorer] Fold Rank IC = 0.105446\n",
      "[CV] END model__colsample_bytree=0.817361227076125, model__learning_rate=0.04158907209132091, model__max_depth=6, model__min_child_weight=17, model__subsample=0.7296239929137495; total time=  30.1s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.077494\n",
      "[CV] END model__colsample_bytree=0.9821911945239713, model__learning_rate=0.025095245519245572, model__max_depth=9, model__min_child_weight=9, model__subsample=0.7524259059189972; total time=  55.1s\n",
      "[RankICScorer] Fold Rank IC = 0.101442\n",
      "[CV] END model__colsample_bytree=0.9821911945239713, model__learning_rate=0.025095245519245572, model__max_depth=9, model__min_child_weight=9, model__subsample=0.7524259059189972; total time=  55.2s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.076428\n",
      "[CV] END model__colsample_bytree=0.6014521229018973, model__learning_rate=0.03287002421332476, model__max_depth=8, model__min_child_weight=6, model__subsample=0.831465734491354; total time=  41.5s\n",
      "[RankICScorer] Fold Rank IC = 0.101724\n",
      "[CV] END model__colsample_bytree=0.6014521229018973, model__learning_rate=0.03287002421332476, model__max_depth=8, model__min_child_weight=6, model__subsample=0.831465734491354; total time=  42.2s\n",
      "--- XGB 调优完成, 最佳CV得分: 0.106189 ---\n",
      "最佳参数: {'colsample_bytree': 0.9249583953429453, 'learning_rate': 0.007427481277233235, 'max_depth': 7, 'min_child_weight': 16, 'subsample': 0.8092209312217534}\n",
      "\n",
      "--- 4.2 开始为 CATBOOST 进行贝叶斯优化 ---\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.085137\n",
      "[CV] END model__depth=6, model__l2_leaf_reg=8, model__learning_rate=0.04283886967006358, model__subsample=0.7263198373948194; total time=  48.7s\n",
      "[RankICScorer] Fold Rank IC = 0.110210\n",
      "[CV] END model__depth=6, model__l2_leaf_reg=8, model__learning_rate=0.04283886967006358, model__subsample=0.7263198373948194; total time=  48.1s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.081254\n",
      "[CV] END model__depth=9, model__l2_leaf_reg=9, model__learning_rate=0.010054954604718277, model__subsample=0.9804895626373318; total time= 1.1min\n",
      "[RankICScorer] Fold Rank IC = 0.101655\n",
      "[CV] END model__depth=9, model__l2_leaf_reg=9, model__learning_rate=0.010054954604718277, model__subsample=0.9804895626373318; total time= 1.1min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.086482\n",
      "[CV] END model__depth=7, model__l2_leaf_reg=9, model__learning_rate=0.006365450758349532, model__subsample=0.77333312074809; total time=  53.8s\n",
      "[RankICScorer] Fold Rank IC = 0.114253\n",
      "[CV] END model__depth=7, model__l2_leaf_reg=9, model__learning_rate=0.006365450758349532, model__subsample=0.77333312074809; total time=  49.9s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.078191\n",
      "[CV] END model__depth=9, model__l2_leaf_reg=3, model__learning_rate=0.019816049655691, model__subsample=0.9211059124625243; total time=  59.0s\n",
      "[RankICScorer] Fold Rank IC = 0.093630\n",
      "[CV] END model__depth=9, model__l2_leaf_reg=3, model__learning_rate=0.019816049655691, model__subsample=0.9211059124625243; total time= 1.2min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.077450\n",
      "[CV] END model__depth=9, model__l2_leaf_reg=5, model__learning_rate=0.016810872002582168, model__subsample=0.8862853048428132; total time=  55.0s\n",
      "[RankICScorer] Fold Rank IC = 0.097100\n",
      "[CV] END model__depth=9, model__l2_leaf_reg=5, model__learning_rate=0.016810872002582168, model__subsample=0.8862853048428132; total time=  51.9s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.085895\n",
      "[CV] END model__depth=8, model__l2_leaf_reg=9, model__learning_rate=0.007287476763095815, model__subsample=0.6753701167061721; total time=  55.7s\n",
      "[RankICScorer] Fold Rank IC = 0.114023\n",
      "[CV] END model__depth=8, model__l2_leaf_reg=9, model__learning_rate=0.007287476763095815, model__subsample=0.6753701167061721; total time=  51.8s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.081929\n",
      "[CV] END model__depth=8, model__l2_leaf_reg=8, model__learning_rate=0.01142859746175277, model__subsample=0.9497301181337832; total time=  49.5s\n",
      "[RankICScorer] Fold Rank IC = 0.105494\n",
      "[CV] END model__depth=8, model__l2_leaf_reg=8, model__learning_rate=0.01142859746175277, model__subsample=0.9497301181337832; total time=  57.6s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.082841\n",
      "[CV] END model__depth=7, model__l2_leaf_reg=9, model__learning_rate=0.015683273202615675, model__subsample=0.9350625748242107; total time=  59.9s\n",
      "[RankICScorer] Fold Rank IC = 0.106689\n",
      "[CV] END model__depth=7, model__l2_leaf_reg=9, model__learning_rate=0.015683273202615675, model__subsample=0.9350625748242107; total time= 1.1min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.066614\n",
      "[CV] END model__depth=10, model__l2_leaf_reg=7, model__learning_rate=0.037206766845782564, model__subsample=0.7663284350317814; total time= 1.4min\n",
      "[RankICScorer] Fold Rank IC = 0.077602\n",
      "[CV] END model__depth=10, model__l2_leaf_reg=7, model__learning_rate=0.037206766845782564, model__subsample=0.7663284350317814; total time= 1.3min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.090494\n",
      "[CV] END model__depth=4, model__l2_leaf_reg=8, model__learning_rate=0.027558320631972947, model__subsample=0.701821703145618; total time=  37.2s\n",
      "[RankICScorer] Fold Rank IC = 0.112619\n",
      "[CV] END model__depth=4, model__l2_leaf_reg=8, model__learning_rate=0.027558320631972947, model__subsample=0.701821703145618; total time=  38.7s\n",
      "--- CATBOOST 调优完成, 最佳CV得分: 0.101556 ---\n",
      "最佳参数: {'depth': 4, 'l2_leaf_reg': 8, 'learning_rate': 0.027558320631972947, 'subsample': 0.701821703145618}\n",
      "\n",
      "--- 4.3 开始为 LGBM 进行贝叶斯优化 ---\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.083688\n",
      "[CV] END model__bagging_fraction=0.7640415835413256, model__feature_fraction=0.89109029727093, model__lambda_l1=2.4877801005599336, model__lambda_l2=6.9533860407670616e-06, model__learning_rate=0.02339472543556369, model__num_leaves=74; total time= 3.7min\n",
      "[RankICScorer] Fold Rank IC = 0.110945\n",
      "[CV] END model__bagging_fraction=0.7640415835413256, model__feature_fraction=0.89109029727093, model__lambda_l1=2.4877801005599336, model__lambda_l2=6.9533860407670616e-06, model__learning_rate=0.02339472543556369, model__num_leaves=74; total time= 3.7min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.084815\n",
      "[CV] END model__bagging_fraction=0.9349553422213137, model__feature_fraction=0.9533261109523449, model__lambda_l1=5.3788692675093665e-06, model__lambda_l2=3.6392773904714772, model__learning_rate=0.03656772310794284, model__num_leaves=28; total time= 1.6min\n",
      "[RankICScorer] Fold Rank IC = 0.112670\n",
      "[CV] END model__bagging_fraction=0.9349553422213137, model__feature_fraction=0.9533261109523449, model__lambda_l1=5.3788692675093665e-06, model__lambda_l2=3.6392773904714772, model__learning_rate=0.03656772310794284, model__num_leaves=28; total time= 1.7min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.084994\n",
      "[CV] END model__bagging_fraction=0.7779330049204607, model__feature_fraction=0.9674890086677508, model__lambda_l1=8.784811093670505e-08, model__lambda_l2=7.943194863182842e-05, model__learning_rate=0.007707706887000696, model__num_leaves=79; total time= 3.7min\n",
      "[RankICScorer] Fold Rank IC = 0.120076\n",
      "[CV] END model__bagging_fraction=0.7779330049204607, model__feature_fraction=0.9674890086677508, model__lambda_l1=8.784811093670505e-08, model__lambda_l2=7.943194863182842e-05, model__learning_rate=0.007707706887000696, model__num_leaves=79; total time= 3.8min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.089038\n",
      "[CV] END model__bagging_fraction=0.9249583953429453, model__feature_fraction=0.6687486245586243, model__lambda_l1=0.002412257679178859, model__lambda_l2=0.16783519226220392, model__learning_rate=0.01667332948323755, model__num_leaves=32; total time= 1.9min\n",
      "[RankICScorer] Fold Rank IC = 0.124666\n",
      "[CV] END model__bagging_fraction=0.9249583953429453, model__feature_fraction=0.6687486245586243, model__lambda_l1=0.002412257679178859, model__lambda_l2=0.16783519226220392, model__learning_rate=0.01667332948323755, model__num_leaves=32; total time= 2.0min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.082935\n",
      "[CV] END model__bagging_fraction=0.9198213766428692, model__feature_fraction=0.7752116745763693, model__lambda_l1=0.0005490123754862843, model__lambda_l2=0.027632447843676397, model__learning_rate=0.04007025228999773, model__num_leaves=113; total time= 4.7min\n",
      "[RankICScorer] Fold Rank IC = 0.103115\n",
      "[CV] END model__bagging_fraction=0.9198213766428692, model__feature_fraction=0.7752116745763693, model__lambda_l1=0.0005490123754862843, model__lambda_l2=0.027632447843676397, model__learning_rate=0.04007025228999773, model__num_leaves=113; total time= 4.7min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.084068\n",
      "[CV] END model__bagging_fraction=0.8936112071942273, model__feature_fraction=0.9757478950411087, model__lambda_l1=2.96800485998608e-07, model__lambda_l2=4.963952600592636e-07, model__learning_rate=0.03158444397400415, model__num_leaves=68; total time= 3.2min\n",
      "[RankICScorer] Fold Rank IC = 0.110103\n",
      "[CV] END model__bagging_fraction=0.8936112071942273, model__feature_fraction=0.9757478950411087, model__lambda_l1=2.96800485998608e-07, model__lambda_l2=4.963952600592636e-07, model__learning_rate=0.03158444397400415, model__num_leaves=68; total time= 3.3min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.084712\n",
      "[CV] END model__bagging_fraction=0.8468317434009265, model__feature_fraction=0.9101457515311531, model__lambda_l1=1.702967607722994e-05, model__lambda_l2=0.739482086614497, model__learning_rate=0.019569948358746023, model__num_leaves=97; total time= 4.3min\n",
      "[RankICScorer] Fold Rank IC = 0.112318\n",
      "[CV] END model__bagging_fraction=0.8468317434009265, model__feature_fraction=0.9101457515311531, model__lambda_l1=1.702967607722994e-05, model__lambda_l2=0.739482086614497, model__learning_rate=0.019569948358746023, model__num_leaves=97; total time= 4.4min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.086250\n",
      "[CV] END model__bagging_fraction=0.817361227076125, model__feature_fraction=0.9680036905749265, model__lambda_l1=0.00029390050504238995, model__lambda_l2=0.34586604961698086, model__learning_rate=0.010544597008879638, model__num_leaves=27; total time= 1.9min\n",
      "[RankICScorer] Fold Rank IC = 0.123948\n",
      "[CV] END model__bagging_fraction=0.817361227076125, model__feature_fraction=0.9680036905749265, model__lambda_l1=0.00029390050504238995, model__lambda_l2=0.34586604961698086, model__learning_rate=0.010544597008879638, model__num_leaves=27; total time= 2.0min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.089049\n",
      "[CV] END model__bagging_fraction=0.9821911945239713, model__feature_fraction=0.8802485778485464, model__lambda_l1=0.6996282803033609, model__lambda_l2=5.525731625462062e-05, model__learning_rate=0.012023606904247704, model__num_leaves=47; total time= 2.6min\n",
      "[RankICScorer] Fold Rank IC = 0.120337\n",
      "[CV] END model__bagging_fraction=0.9821911945239713, model__feature_fraction=0.8802485778485464, model__lambda_l1=0.6996282803033609, model__lambda_l2=5.525731625462062e-05, model__learning_rate=0.012023606904247704, model__num_leaves=47; total time= 2.7min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[RankICScorer] Fold Rank IC = 0.085816\n",
      "[CV] END model__bagging_fraction=0.6014521229018973, model__feature_fraction=0.9271320078655007, model__lambda_l1=0.04694017445221059, model__lambda_l2=1.95428689959168e-06, model__learning_rate=0.018951096390644438, model__num_leaves=56; total time= 2.7min\n",
      "[RankICScorer] Fold Rank IC = 0.114760\n",
      "[CV] END model__bagging_fraction=0.6014521229018973, model__feature_fraction=0.9271320078655007, model__lambda_l1=0.04694017445221059, model__lambda_l2=1.95428689959168e-06, model__learning_rate=0.018951096390644438, model__num_leaves=56; total time= 2.7min\n",
      "--- LGBM 调优完成, 最佳CV得分: 0.106852 ---\n",
      "最佳参数: {'bagging_fraction': 0.9249583953429453, 'feature_fraction': 0.6687486245586243, 'lambda_l1': 0.002412257679178859, 'lambda_l2': 0.16783519226220392, 'learning_rate': 0.01667332948323755, 'num_leaves': 32}\n",
      "\n",
      "--- 5. 使用最优参数和早停机制在最终训练集上训练模型 ---\n",
      "早停训练集: 1391 - 1590 (200 天)\n",
      "早停验证集: 1591 - 1690 (100 天)\n",
      "\n",
      "--- 正在为 XGB 模型寻找最佳迭代次数 ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "XGBModel.fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 255\u001B[0m\n\u001B[0;32m    252\u001B[0m     \u001B[38;5;28mprint\u001B[39m(submission_df\u001B[38;5;241m.\u001B[39mhead())\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 255\u001B[0m     main()\n",
      "Cell \u001B[1;32mIn[1], line 207\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mxgb\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;66;03m# 这里的n_estimators也设置为一个大数，让早停来决定最终值\u001B[39;00m\n\u001B[0;32m    206\u001B[0m     model \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mXGBRegressor(n_estimators\u001B[38;5;241m=\u001B[39mfixed_iterations, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, tree_method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpu_hist\u001B[39m\u001B[38;5;124m'\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m--> 207\u001B[0m     model\u001B[38;5;241m.\u001B[39mfit(X_train_es_scaled, y_train_es,\n\u001B[0;32m    208\u001B[0m               eval_set\u001B[38;5;241m=\u001B[39m[(X_eval_es_scaled, y_eval_es)],\n\u001B[0;32m    209\u001B[0m               early_stopping_rounds\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    210\u001B[0m     best_iteration \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mbest_iteration\n\u001B[0;32m    211\u001B[0m     params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m best_iteration\n",
      "File \u001B[1;32mD:\\Program Files\\Anaconda\\envs\\py312\\Lib\\site-packages\\xgboost\\core.py:729\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    728\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 729\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mTypeError\u001B[0m: XGBModel.fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py312] *",
   "language": "python",
   "name": "conda-env-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
